{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73642a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the libraries are not yet installed, they can be installed in this notebook using commands similar to the below\n",
    "# %conda install numpy\n",
    "# %conda install pandas\n",
    "# %conda install matplotlib\n",
    "# %conda install scikit-learn\n",
    "# %conda install -c conda-forge lightgbm \n",
    "# %conda install -c conda-forge bayesian-optimization \n",
    "# %conda install -c conda-forge scipy\n",
    "# %conda install joblib\n",
    "# %conda install tdqm\n",
    "\n",
    "# Something like the following may also work if the above does not\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} numpy\n",
    "# !conda install --yes --prefix {sys.prefix} pandas\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} lightgbm\n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} bayesian-optimization \n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} scipy \n",
    "# !conda install --yes --prefix {sys.prefix} joblib\n",
    "# !conda install --yes --prefix {sys.prefix} tdqm\n",
    "\n",
    "# To install a specific version, add the version to the install command\n",
    "# E.g., %conda install numpy=1.20.3\n",
    "\n",
    "# If all else fails, use pip or follow additional advice such as found at\n",
    "# https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "\n",
    "# If your plan to use pip (especially if you are not working within a specified conda environment), \n",
    "# the pip commands might look like:\n",
    "# pip install numpy\n",
    "# pip install pandas\n",
    "# pip install scikit-learn\n",
    "# pip install lightgbm\n",
    "# pip install bayesian-optimization \n",
    "# pip install scipy\n",
    "# pip install joblib\n",
    "# pip install tdqm\n",
    "\n",
    "# To install a specific version, add the version to the pip install command\n",
    "# E.g., pip install numpy==1.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05a769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import glob\n",
    "from lightgbm import LGBMRegressor\n",
    "import random\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import scipy\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "import contextlib\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc2a7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(54321)\n",
    "random.seed(54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f65f0d",
   "metadata": {},
   "source": [
    "# Read in Data and Prepare for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f363c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Unseen Sensor/Processed/A19-9336-1_Northbound_2019_Processed.csv\n",
      "Reading Data/Unseen Sensor/Processed/A66-9521-1_Westbound_Processed.csv\n",
      "Reading Data/Unseen Sensor/Processed/M40-7048-2_Southbound_Processed.csv\n",
      "Reading Data/Unseen Sensor/Processed/M62-2056A_Eastbound_Processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to hold the dataframes of highways england data\n",
    "total_df_list = list()\n",
    "\n",
    "# Loop through the files, sorted in alphabetical order\n",
    "# Read them into a df, make sure they are sorted by timestamp, and append to the list\n",
    "for fname in sorted(glob.glob(\"Data/Unseen Sensor/Processed/*.csv\")):\n",
    "    print(\"Reading {}\".format(fname))\n",
    "    df = pd.read_csv(fname) #, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "    df = df.sort_values(by=\"timestamp\")\n",
    "    total_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682ccd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the start and end points csv, and subtract 1 to deal with index differences between R and python\n",
    "start_end = pd.read_csv(\"start_end_points_unseen.csv\")\n",
    "start_end[\"start\"] = start_end[\"start\"] - 1\n",
    "start_end[\"end\"] = start_end[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba78be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to hold the subset data frames (those with only 12 weeks of data per highway)\n",
    "subset_df_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c312dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each df in our original total df list\n",
    "for idx, df in enumerate(total_df_list):\n",
    "        \n",
    "    # Filter the timeframe based on the start_end_points csv files\n",
    "    subset_df = df.iloc[start_end.iloc[idx,0]:start_end.iloc[idx,1], ]\\\n",
    "    .reset_index(drop=True).reset_index(drop=False)\\\n",
    "    .rename(columns={\"index\":\"rn\"})\n",
    "    \n",
    "    # Create a new field called train_val_test to differentiate each set of data\n",
    "    subset_df[\"train_val_test\"] = np.where(subset_df[\"rn\"]<(96*7*8),\n",
    "                                           \"train\",\n",
    "                                           np.where(subset_df[\"rn\"]<(96*7*10),\n",
    "                                                    \"val\",\n",
    "                                                    \"test\"\n",
    "                                                   )\n",
    "                                       )\n",
    "    \n",
    "    # Append to list\n",
    "    subset_df_list.append(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64246820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of df's with only fields we need\n",
    "\n",
    "# Initialize empty list\n",
    "model_df_list = list()\n",
    "\n",
    "# For df in subset list\n",
    "for df in subset_df_list:\n",
    "       \n",
    "    # Extract the timestamp, the volume, and the train_val_test assignment\n",
    "    model_df = df[['timestamp', 'total_volume', \"train_val_test\"]]\\\n",
    "    .rename(columns={'timestamp':'start', 'total_volume':'target'})\n",
    "    \n",
    "    # Append this df to the new list\n",
    "    model_df_list.append(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1e1df",
   "metadata": {},
   "source": [
    "## Create Lag Emebedded Matrices for each TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542676fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_n = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56463d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5801/3230010149.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = df['target'].shift(n)\n"
     ]
    }
   ],
   "source": [
    "# # Lag embed the data frames and save to a list\n",
    "lag_embed_df_list = list()\n",
    "\n",
    "for df in model_df_list:\n",
    "    # For each df in our list\n",
    "    for n in range(1, (lag_n+1)):\n",
    "        # For each lag level, up to 960\n",
    "        # Create a new column called target-n\n",
    "        name = f\"target-{n}\"\n",
    "        # Save the target shifted n values into this colume\n",
    "        df[name] = df['target'].shift(n)\n",
    "    # Append to list\n",
    "    lag_embed_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca89cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the lag embedded list into train, val, and test lists\n",
    "\n",
    "# First, initialize empty lists for each train, val, and test\n",
    "train_df_list = list()\n",
    "val_df_list = list()\n",
    "test_df_list = list()\n",
    "\n",
    "for i in range(len(lag_embed_df_list)):\n",
    "    # For each df in our list\n",
    "    df = lag_embed_df_list[i].copy()\n",
    "\n",
    "    # Add a ts_index of i+1 to join with clustering data from R\n",
    "    df['ts_index'] = i + 1\n",
    "    \n",
    "    # Subset into train, val, and test df's based on the train_val_test_field\n",
    "    train_df = df.query(\"train_val_test == 'train'\").copy()\n",
    "    val_df = df.query(\"train_val_test=='val'\").copy()\n",
    "    test_df = df.query(\"train_val_test=='test'\").copy()\n",
    "    \n",
    "    # Append to appropriate lists\n",
    "    train_df_list.append(train_df)\n",
    "    val_df_list.append(val_df)\n",
    "    test_df_list.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be8da73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all dfs from the lists together to create one full train, val, and test df\n",
    "train_df_full = pd.concat(train_df_list)\n",
    "val_df_full = pd.concat(val_df_list)\n",
    "test_df_full = pd.concat(test_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67472300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "train_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "val_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "test_df_full.drop(columns=['start', 'train_val_test'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffe73801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the training and validation data together for later use\n",
    "train_val_df_full = train_df_full.append(val_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0546bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused variables to free up memory\n",
    "del train_df_list\n",
    "del val_df_list \n",
    "del test_df_list\n",
    "del lag_embed_df_list\n",
    "del model_df_list\n",
    "del subset_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "644f1ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force garbage collection to free up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f85558bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_sen_clust = pd.read_csv(\"Results/Unseen Sensor/clust_assign.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e787b689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rand</th>\n",
       "      <th>catch22</th>\n",
       "      <th>tsfeat</th>\n",
       "      <th>dtw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rand  catch22  tsfeat  dtw\n",
       "0           1     3        1       1    2\n",
       "1           2     2        1       1    2\n",
       "2           3     1        4       1    1\n",
       "3           4     4        4       1    1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4684068c",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ffc66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file to use later\n",
    "filename = 'Results/Global/LightGBM Bayes/Full/model'\n",
    "mod = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61acb290",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('Results/Global/LightGBM Bayes/Full/residual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e42b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute test preds\n",
    "def compute_lgbm_test_preds(mod, data, lag_n):\n",
    "    \"\"\"Function which takes in: a model, test data, and the lag embedding to use, and returns a df of forecasts\"\"\"\n",
    "\n",
    "    # Initialize an empty data frame to store preds\n",
    "    pred_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop through each individual time series index in the data set\n",
    "    for ts_idx in data.ts_index.unique():\n",
    "        # Create the X matrix for each one\n",
    "        X = data.query(\"ts_index==@ts_idx\").iloc[:,1:(lag_n+1)].copy()\n",
    "\n",
    "        # Forecast for that X matrix\n",
    "        preds = mod.predict(X)\n",
    "        \n",
    "        # Save the results to a temp data frame\n",
    "        pred_df_sub = pd.DataFrame({\"ts_index\": ts_idx, \"test_preds\": preds})\n",
    "        \n",
    "        # Append to primary data frame\n",
    "        pred_df = pred_df.append(pred_df_sub)\n",
    "    \n",
    "    # Return df of all preds with corresponding ts_index column\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0814a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds = compute_lgbm_test_preds(mod, test_df_full, lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0709287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute performance metrics on test data\n",
    "def compute_lgbm_test_perf(preds, data):\n",
    "    \"\"\"Function which takes inputs: a data frame of test predictions, and a test data df,\n",
    "    and which returns a data frame of model performance\"\"\"\n",
    "    \n",
    "    # Create an empty list to store model performance\n",
    "    perf_ls = list()\n",
    "    \n",
    "    # For each time series index in our data set\n",
    "    for ts_idx in data.ts_index.unique():\n",
    "        # Get the target (actual) for that index\n",
    "        y_sub = data.query(\"ts_index==@ts_idx\").iloc[:,0]\n",
    "        # Extract the corresponding forecasts\n",
    "        preds_sub = preds.query(\"ts_index==@ts_idx\").test_preds\n",
    "        \n",
    "        # Compute rmse, mae, and the mean of the true target value for those preds\n",
    "        rmse_sub = mean_squared_error(y_sub, preds_sub, squared=False)\n",
    "        mae_sub = mean_absolute_error(y_sub, preds_sub)\n",
    "        mean_sub = np.mean(y_sub)\n",
    "        \n",
    "        # Save those metrics to a dictionary\n",
    "        pred_dict = {\"rmse\": rmse_sub, \"mae\": mae_sub, \"mean\": mean_sub}\n",
    "        \n",
    "        # Append the dictionary to the list\n",
    "        perf_ls.append(pred_dict)\n",
    "        \n",
    "    # Return a data frame of model performance created from the list of dictionaries\n",
    "    return pd.DataFrame(perf_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ccc5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model perf metrics using above function\n",
    "full_mod_test_perf = compute_lgbm_test_perf(unseen_test_preds, test_df_full)\n",
    "\n",
    "# Compute scaled performance metrics in new columns\n",
    "full_mod_test_perf['nrmse'] = full_mod_test_perf['rmse']/full_mod_test_perf['mean']\n",
    "full_mod_test_perf['smae'] = full_mod_test_perf['mae']/full_mod_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6cdb7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      38.058841\n",
       "mae       25.287789\n",
       "mean     377.058594\n",
       "nrmse      0.122584\n",
       "smae       0.082148\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of model perf metrics\n",
    "full_mod_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e057d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute pred intervals with bootstrap method\n",
    "def compute_lgbm_boostrap_int(preds, resid, n_boot):\n",
    "    \"\"\"Function which takes in a model's predictions and residuals, and a number of bootstrap resamples to use,\n",
    "    and which outputs a df with pred intervals at 80% and 95%\"\"\"\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    random.seed(54321)\n",
    "    np.random.seed(54321)\n",
    "    \n",
    "    # Create empty columns in the pred df to store the PIs\n",
    "    preds['lo_95'] = np.nan\n",
    "    preds['hi_95'] = np.nan\n",
    "    preds['lo_80'] = np.nan\n",
    "    preds['hi_80'] = np.nan\n",
    "    \n",
    "    # For each row in the pred df\n",
    "    for n in range(preds.shape[0]):\n",
    "        # Sample with replacement n_boot times from the residuals\n",
    "        resid_boot = np.random.choice(resid, size=n_boot, replace=True)\n",
    "        # Extract the forecast value for that row\n",
    "        pred_n = preds.iloc[n, :].test_preds\n",
    "        # Add the residual vector to the forecast value\n",
    "        pred_n_boot = resid_boot + pred_n\n",
    "        \n",
    "        # Compute quantiles of this residual+forecast vector\n",
    "        percent_95_lo = np.percentile(pred_n_boot, 2.5)\n",
    "        percent_95_hi = np.percentile(pred_n_boot, 97.5)\n",
    "        \n",
    "        percent_80_lo = np.percentile(pred_n_boot, 10)\n",
    "        percent_80_hi = np.percentile(pred_n_boot, 90)\n",
    "        \n",
    "        # Save these quantiles to the appropriate df column\n",
    "        preds.iloc[n, 2] = percent_95_lo\n",
    "        preds.iloc[n, 3] = percent_95_hi\n",
    "        preds.iloc[n, 4] = percent_80_lo\n",
    "        preds.iloc[n, 5] = percent_80_hi\n",
    "    \n",
    "    # Return the updated preds data frame\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10188018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PIs with 1000 bootstrap samples\n",
    "nboot = 1000\n",
    "full_mod_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds, \n",
    "                                               res.residual.values, \n",
    "                                               nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa9e11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the true values into their own df column\n",
    "full_mod_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f8176f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_index</th>\n",
       "      <th>test_preds</th>\n",
       "      <th>lo_95</th>\n",
       "      <th>hi_95</th>\n",
       "      <th>lo_80</th>\n",
       "      <th>hi_80</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>246.485289</td>\n",
       "      <td>195.983314</td>\n",
       "      <td>305.558795</td>\n",
       "      <td>222.563419</td>\n",
       "      <td>275.585662</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>240.022395</td>\n",
       "      <td>184.141914</td>\n",
       "      <td>302.085650</td>\n",
       "      <td>210.253851</td>\n",
       "      <td>267.699421</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>283.329092</td>\n",
       "      <td>225.566530</td>\n",
       "      <td>347.911164</td>\n",
       "      <td>253.318823</td>\n",
       "      <td>309.824978</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>289.137922</td>\n",
       "      <td>228.730568</td>\n",
       "      <td>349.433583</td>\n",
       "      <td>261.975540</td>\n",
       "      <td>317.719134</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>287.392703</td>\n",
       "      <td>227.063650</td>\n",
       "      <td>345.162505</td>\n",
       "      <td>256.256476</td>\n",
       "      <td>315.235074</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_index  test_preds       lo_95       hi_95       lo_80       hi_80  \\\n",
       "0         1  246.485289  195.983314  305.558795  222.563419  275.585662   \n",
       "1         1  240.022395  184.141914  302.085650  210.253851  267.699421   \n",
       "2         1  283.329092  225.566530  347.911164  253.318823  309.824978   \n",
       "3         1  289.137922  228.730568  349.433583  261.975540  317.719134   \n",
       "4         1  287.392703  227.063650  345.162505  256.256476  315.235074   \n",
       "\n",
       "   actual  \n",
       "0   221.0  \n",
       "1   323.0  \n",
       "2   298.0  \n",
       "3   305.0  \n",
       "4   238.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mod_boot_ints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7655ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to compute the interval score\n",
    "def interval_score(true_values, lower, upper, interval_range):\n",
    "    \"\"\" Function which takes in the true values, the upper and lower bounds of PIs, and the PI level (e.g., 90%)\n",
    "        and from these inputs, computes the interval score for each prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute alpha from the interval range\n",
    "    alpha = 1-interval_range\n",
    "    \n",
    "    # Save the upper, lower, and true_values as numpy arrays for computation purposes\n",
    "    upper = np.array(upper)\n",
    "    lower = np.array(lower)\n",
    "    true_values = np.array(true_values)\n",
    "    \n",
    "    # Compute the lower component of the interval score - just a boolean for true below interval\n",
    "    def lower_ind(true,low):\n",
    "        if true<low:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the upper component of the interval score - similar boolean for true above interval\n",
    "    def upper_ind(true,up):\n",
    "        if true>up:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the actual score for each obsveration - formula here: https://epiforecasts.io/scoringutils/reference/interval_score.html\n",
    "    scores = (upper-lower) + (2/alpha)*(lower-true_values)*(lower > true_values) + (2/alpha)*(true_values-upper)*(true_values > upper)\n",
    "    \n",
    "    # Return the scores array\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79ff7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 95% and 80% PI scores using the above function as new data frame columns\n",
    "full_mod_boot_ints['int_95_score'] = interval_score(full_mod_boot_ints.actual, \n",
    "                                                    full_mod_boot_ints.lo_95,\n",
    "                                                    full_mod_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "full_mod_boot_ints['int_80_score'] = interval_score(full_mod_boot_ints.actual, \n",
    "                                                    full_mod_boot_ints.lo_80,\n",
    "                                                    full_mod_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bb00c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      377.539545\n",
       "lo_95           316.929484\n",
       "hi_95           440.369775\n",
       "lo_80           348.905650\n",
       "hi_80           407.135720\n",
       "actual          377.058594\n",
       "int_95_score    306.083380\n",
       "int_80_score    157.330588\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of the interval scores\n",
    "full_mod_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adef6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mod_boot_ints_group = full_mod_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "full_mod_boot_ints_group['mean'] = full_mod_test_perf['mean'].values\n",
    "full_mod_boot_ints_group['int_95_score_scaled'] = full_mod_boot_ints_group['int_95_score']/full_mod_boot_ints_group['mean']\n",
    "full_mod_boot_ints_group['int_80_score_scaled'] = full_mod_boot_ints_group['int_80_score']/full_mod_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0144793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    0.882222\n",
       "int_80_score_scaled    0.488217\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mod_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f2643",
   "metadata": {},
   "source": [
    "# Random Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f29e87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    1\n",
       "3    4\n",
       "Name: rand, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba3304c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clust_mod3 = joblib.load(\"Results/Global/LightGBM Bayes/Random Cluster/model_2\")\n",
    "rand_clust_mod2 = joblib.load(\"Results/Global/LightGBM Bayes/Random Cluster/model_1\")\n",
    "rand_clust_mod1 = joblib.load(\"Results/Global/LightGBM Bayes/Random Cluster/model_0\")\n",
    "rand_clust_mod4 = joblib.load(\"Results/Global/LightGBM Bayes/Random Cluster/model_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b15aed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clust_res = pd.read_csv(\"Results/Global/LightGBM Bayes/Random Cluster/residual.csv\")\n",
    "rand_clust_res['residual'] = rand_clust_res['residual'].apply(eval)\n",
    "\n",
    "res_rand_clust_3 = rand_clust_res.query(\"cluster==3\")['residual'].values[0]\n",
    "res_rand_clust_2 = rand_clust_res.query(\"cluster==2\")['residual'].values[0]\n",
    "res_rand_clust_1 = rand_clust_res.query(\"cluster==1\")['residual'].values[0]\n",
    "res_rand_clust_4 = rand_clust_res.query(\"cluster==4\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ac860dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_rand_clust3 = compute_lgbm_test_preds(rand_clust_mod3, \n",
    "                                                        test_df_full.query(\"ts_index==1\"), \n",
    "                                                        lag_n)\n",
    "\n",
    "unseen_test_preds_rand_clust2 = compute_lgbm_test_preds(rand_clust_mod2, \n",
    "                                                        test_df_full.query(\"ts_index==2\"), \n",
    "                                                        lag_n)\n",
    "\n",
    "unseen_test_preds_rand_clust1 = compute_lgbm_test_preds(rand_clust_mod1, \n",
    "                                                        test_df_full.query(\"ts_index==3\"), \n",
    "                                                        lag_n)\n",
    "\n",
    "unseen_test_preds_rand_clust4 = compute_lgbm_test_preds(rand_clust_mod4, \n",
    "                                                        test_df_full.query(\"ts_index==4\"), \n",
    "                                                        lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "deb9bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model perf metrics using above function\n",
    "rand_clust3_test_perf = compute_lgbm_test_perf(unseen_test_preds_rand_clust3, test_df_full.query(\"ts_index==1\"))\n",
    "rand_clust2_test_perf = compute_lgbm_test_perf(unseen_test_preds_rand_clust2, test_df_full.query(\"ts_index==2\"))\n",
    "rand_clust1_test_perf = compute_lgbm_test_perf(unseen_test_preds_rand_clust1, test_df_full.query(\"ts_index==3\"))\n",
    "rand_clust4_test_perf = compute_lgbm_test_perf(unseen_test_preds_rand_clust4, test_df_full.query(\"ts_index==4\"))\n",
    "\n",
    "rand_clust_test_perf = rand_clust3_test_perf.append(rand_clust2_test_perf).append(rand_clust1_test_perf).append(rand_clust4_test_perf)\n",
    "\n",
    "# Compute scaled performance metrics in new columns\n",
    "rand_clust_test_perf['nrmse'] = rand_clust_test_perf['rmse']/rand_clust_test_perf['mean']\n",
    "rand_clust_test_perf['smae'] = rand_clust_test_perf['mae']/rand_clust_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88a8f8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      39.494879\n",
       "mae       26.728996\n",
       "mean     377.058594\n",
       "nrmse      0.126755\n",
       "smae       0.086209\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_clust_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aab8ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PIs with 1000 bootstrap samples\n",
    "rand3_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_rand_clust3,\n",
    "                                            res_rand_clust_3, \n",
    "                                            nboot)\n",
    "\n",
    "\n",
    "rand2_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_rand_clust2,\n",
    "                                            res_rand_clust_2, \n",
    "                                            nboot)\n",
    "\n",
    "rand1_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_rand_clust1,\n",
    "                                            res_rand_clust_1, \n",
    "                                            nboot)\n",
    "\n",
    "rand4_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_rand_clust4,\n",
    "                                            res_rand_clust_4, \n",
    "                                            nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04398977",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_boot_ints = rand3_boot_ints.append(rand2_boot_ints).append(rand1_boot_ints).append(rand4_boot_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2787b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the true values into their own df column\n",
    "rand_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4e64302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 95% and 80% PI scores using the above function as new data frame columns\n",
    "rand_boot_ints['int_95_score'] = interval_score(rand_boot_ints.actual, \n",
    "                                                    rand_boot_ints.lo_95,\n",
    "                                                    rand_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "rand_boot_ints['int_80_score'] = interval_score(rand_boot_ints.actual, \n",
    "                                                    rand_boot_ints.lo_80,\n",
    "                                                    rand_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6cd9580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      374.865837\n",
       "lo_95           321.235825\n",
       "hi_95           430.300318\n",
       "lo_80           347.598643\n",
       "hi_80           403.010866\n",
       "actual          377.058594\n",
       "int_95_score    332.400729\n",
       "int_80_score    167.309605\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8a972a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_boot_ints_group = rand_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "rand_boot_ints_group['mean'] = rand_clust_test_perf['mean'].values\n",
    "rand_boot_ints_group['int_95_score_scaled'] = rand_boot_ints_group['int_95_score']/rand_boot_ints_group['mean']\n",
    "rand_boot_ints_group['int_80_score_scaled'] = rand_boot_ints_group['int_80_score']/rand_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4d1b6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    0.902971\n",
       "int_80_score_scaled    0.507723\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f430da8",
   "metadata": {},
   "source": [
    "# Highway System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2882c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_mod = joblib.load(\"Results/Global/LightGBM Bayes/Highway System/model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73c6f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_res = pd.read_csv(\"Results/Global/LightGBM Bayes/Highway System/residual.csv\")\n",
    "highway_res['residual'] = highway_res['residual'].apply(eval)\n",
    "\n",
    "eng_res = highway_res.query(\"cluster==1\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a03fe340",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_highway = compute_lgbm_test_preds(eng_mod, \n",
    "                                                    test_df_full,\n",
    "                                                    lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "636ee37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_test_perf = compute_lgbm_test_perf(unseen_test_preds_highway, test_df_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eeaefe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_test_perf['nrmse'] = highway_test_perf['rmse']/highway_test_perf['mean']\n",
    "highway_test_perf['smae'] = highway_test_perf['mae']/highway_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f63d4274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      38.569299\n",
       "mae       25.925766\n",
       "mean     377.058594\n",
       "nrmse      0.125855\n",
       "smae       0.084882\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4883b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_highway,\n",
    "                                              eng_res,\n",
    "                                              nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a5a413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10ae79ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_boot_ints['int_95_score'] = interval_score(highway_boot_ints.actual, \n",
    "                                                    highway_boot_ints.lo_95,\n",
    "                                                    highway_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "highway_boot_ints['int_80_score'] = interval_score(highway_boot_ints.actual, \n",
    "                                                    highway_boot_ints.lo_80,\n",
    "                                                    highway_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78a82ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      377.848202\n",
       "lo_95           304.159550\n",
       "hi_95           455.688278\n",
       "lo_80           342.259909\n",
       "hi_80           414.967104\n",
       "actual          377.058594\n",
       "int_95_score    287.655857\n",
       "int_80_score    157.130132\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "793d7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_boot_ints_group = highway_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "highway_boot_ints_group['mean'] = highway_test_perf['mean'].values\n",
    "highway_boot_ints_group['int_95_score_scaled'] = highway_boot_ints_group['int_95_score']/highway_boot_ints_group['mean']\n",
    "highway_boot_ints_group['int_80_score_scaled'] = highway_boot_ints_group['int_80_score']/highway_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "737ec285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    0.931228\n",
       "int_80_score_scaled    0.516865\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05838517",
   "metadata": {},
   "source": [
    "# Catch22 KMeans Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "44724adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    4\n",
       "3    4\n",
       "Name: catch22, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.catch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f03b1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_mod1 = joblib.load(\"Results/Global/LightGBM Bayes/Catch22 KMeans/model_0\")\n",
    "catch22_mod4 = joblib.load(\"Results/Global/LightGBM Bayes/Catch22 KMeans/model_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a41c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_res = pd.read_csv(\"Results/Global/LightGBM Bayes/Catch22 KMeans/residual.csv\")\n",
    "catch22_res['residual'] = catch22_res['residual'].apply(eval)\n",
    "\n",
    "catch22_res1 = catch22_res.query(\"cluster==1\")['residual'].values[0]\n",
    "catch22_res4 = catch22_res.query(\"cluster==4\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c90b5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_catch22_clust1 = compute_lgbm_test_preds(catch22_mod1, \n",
    "                                                           test_df_full.query(\"ts_index in [1,2]\"),\n",
    "                                                           lag_n)\n",
    "\n",
    "unseen_test_preds_catch22_clust4 = compute_lgbm_test_preds(catch22_mod4, \n",
    "                                                           test_df_full.query(\"ts_index in [3,4]\"),\n",
    "                                                           lag_n)\n",
    "\n",
    "unseen_test_preds_catch22 = unseen_test_preds_catch22_clust1.append(unseen_test_preds_catch22_clust4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88c2fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_test_perf = compute_lgbm_test_perf(unseen_test_preds_catch22, test_df_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0050f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_test_perf['nrmse'] = catch22_test_perf['rmse']/catch22_test_perf['mean']\n",
    "catch22_test_perf['smae'] = catch22_test_perf['mae']/catch22_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6743af99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      38.981098\n",
       "mae       26.282849\n",
       "mean     377.058594\n",
       "nrmse      0.124918\n",
       "smae       0.084733\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch22_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9560729",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_boot_ints_clust1 = compute_lgbm_boostrap_int(unseen_test_preds_catch22_clust1,\n",
    "                                                     catch22_res1,\n",
    "                                                     nboot)\n",
    "\n",
    "catch22_boot_ints_clust4 = compute_lgbm_boostrap_int(unseen_test_preds_catch22_clust4,\n",
    "                                                     catch22_res4,\n",
    "                                                     nboot)\n",
    "\n",
    "catch22_boot_ints = catch22_boot_ints_clust1.append(catch22_boot_ints_clust4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8af571c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "152b753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_boot_ints['int_95_score'] = interval_score(catch22_boot_ints.actual, \n",
    "                                                    catch22_boot_ints.lo_95,\n",
    "                                                    catch22_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "catch22_boot_ints['int_80_score'] = interval_score(catch22_boot_ints.actual, \n",
    "                                                    catch22_boot_ints.lo_80,\n",
    "                                                    catch22_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74a8b265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      377.406667\n",
       "lo_95           317.048464\n",
       "hi_95           440.852390\n",
       "lo_80           346.044561\n",
       "hi_80           409.335424\n",
       "actual          377.058594\n",
       "int_95_score    284.131847\n",
       "int_80_score    154.229379\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch22_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8011dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_boot_ints_group = catch22_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "catch22_boot_ints_group['mean'] = catch22_test_perf['mean'].values\n",
    "catch22_boot_ints_group['int_95_score_scaled'] = catch22_boot_ints_group['int_95_score']/catch22_boot_ints_group['mean']\n",
    "catch22_boot_ints_group['int_80_score_scaled'] = catch22_boot_ints_group['int_80_score']/catch22_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41f3a169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    0.810287\n",
       "int_80_score_scaled    0.478301\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch22_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02f9a0",
   "metadata": {},
   "source": [
    "# TSFeat KMeans Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae5d5442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "Name: tsfeat, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.tsfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc54a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_mod1 = joblib.load(\"Results/Global/LightGBM Bayes/TSFeat KMeans/model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27beebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_res = pd.read_csv(\"Results/Global/LightGBM Bayes/TSFeat KMeans/residual.csv\")\n",
    "tsfeat_res['residual'] = tsfeat_res['residual'].apply(eval)\n",
    "\n",
    "tsfeat_res1 = tsfeat_res.query(\"cluster==1\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "930a95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_tsfeat1 = compute_lgbm_test_preds(tsfeat_mod1, \n",
    "                                                    test_df_full,\n",
    "                                                    lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2190db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_test_perf = compute_lgbm_test_perf(unseen_test_preds_tsfeat1, test_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92b85b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_test_perf['nrmse'] = tsfeat_test_perf['rmse']/tsfeat_test_perf['mean']\n",
    "tsfeat_test_perf['smae'] = tsfeat_test_perf['mae']/tsfeat_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ff716f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      38.460395\n",
       "mae       25.785030\n",
       "mean     377.058594\n",
       "nrmse      0.125117\n",
       "smae       0.084456\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsfeat_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ec505b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_tsfeat1,\n",
    "                                             tsfeat_res1,\n",
    "                                             nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7ffb6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ba84c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_boot_ints['int_95_score'] = interval_score(tsfeat_boot_ints.actual, \n",
    "                                                    tsfeat_boot_ints.lo_95,\n",
    "                                                    tsfeat_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "tsfeat_boot_ints['int_80_score'] = interval_score(tsfeat_boot_ints.actual, \n",
    "                                                    tsfeat_boot_ints.lo_80,\n",
    "                                                    tsfeat_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8f9759d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      377.615412\n",
       "lo_95           311.815116\n",
       "hi_95           446.136497\n",
       "lo_80           344.509566\n",
       "hi_80           411.506543\n",
       "actual          377.058594\n",
       "int_95_score    298.728097\n",
       "int_80_score    157.504571\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsfeat_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "963d8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_boot_ints_group = tsfeat_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "tsfeat_boot_ints_group['mean'] = tsfeat_test_perf['mean'].values\n",
    "tsfeat_boot_ints_group['int_95_score_scaled'] = tsfeat_boot_ints_group['int_95_score']/tsfeat_boot_ints_group['mean']\n",
    "tsfeat_boot_ints_group['int_80_score_scaled'] = tsfeat_boot_ints_group['int_80_score']/tsfeat_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3db9393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    0.900324\n",
       "int_80_score_scaled    0.505944\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsfeat_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43452e",
   "metadata": {},
   "source": [
    "# Train and Test - DTW Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea6b1b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    1\n",
       "3    1\n",
       "Name: dtw, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e80d8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_mod2 = joblib.load(\"Results/Global/LightGBM Bayes/DTW/model_1\")\n",
    "dtw_mod1 = joblib.load(\"Results/Global/LightGBM Bayes/DTW/model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c2cdca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_res = pd.read_csv(\"Results/Global/LightGBM Bayes/DTW/residual.csv\")\n",
    "dtw_res['residual'] = dtw_res['residual'].apply(eval)\n",
    "\n",
    "dtw_res2 = dtw_res.query(\"cluster==2\")['residual'].values[0]\n",
    "dtw_res1 = dtw_res.query(\"cluster==1\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2eebed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_dtw2 = compute_lgbm_test_preds(dtw_mod2, \n",
    "                                                 test_df_full.query(\"ts_index in [1,2]\"),\n",
    "                                                 lag_n)\n",
    "\n",
    "unseen_test_preds_dtw1 = compute_lgbm_test_preds(dtw_mod1, \n",
    "                                                 test_df_full.query(\"ts_index in [3,4]\"),\n",
    "                                                 lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c93a60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_test_perf2 = compute_lgbm_test_perf(unseen_test_preds_dtw2, test_df_full.query(\"ts_index in [1,2]\"))\n",
    "\n",
    "dtw_test_perf1 = compute_lgbm_test_perf(unseen_test_preds_dtw1, test_df_full.query(\"ts_index in [3,4]\"))\n",
    "\n",
    "dtw_test_perf = dtw_test_perf2.append(dtw_test_perf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12c39608",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_test_perf['nrmse'] = dtw_test_perf['rmse']/dtw_test_perf['mean']\n",
    "dtw_test_perf['smae'] = dtw_test_perf['mae']/dtw_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "910a8912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      37.798783\n",
       "mae       25.323766\n",
       "mean     377.058594\n",
       "nrmse      0.121270\n",
       "smae       0.081587\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d8bf9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_boot_ints2 = compute_lgbm_boostrap_int(unseen_test_preds_dtw2,\n",
    "                                           dtw_res2,\n",
    "                                           nboot)\n",
    "\n",
    "dtw_boot_ints1 = compute_lgbm_boostrap_int(unseen_test_preds_dtw1,\n",
    "                                           dtw_res1,\n",
    "                                           nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa52dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_boot_ints = dtw_boot_ints2.append(dtw_boot_ints1)\n",
    "dtw_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7af05a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_boot_ints['int_95_score'] = interval_score(dtw_boot_ints.actual, \n",
    "                                               dtw_boot_ints.lo_95,\n",
    "                                               dtw_boot_ints.hi_95,\n",
    "                                               0.95)\n",
    "                                                    \n",
    "dtw_boot_ints['int_80_score'] = interval_score(dtw_boot_ints.actual, \n",
    "                                               dtw_boot_ints.lo_80,\n",
    "                                               dtw_boot_ints.hi_80,\n",
    "                                               0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "756950d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      376.987037\n",
       "lo_95           318.666677\n",
       "hi_95           437.309461\n",
       "lo_80           345.554877\n",
       "hi_80           409.303636\n",
       "actual          377.058594\n",
       "int_95_score    260.576473\n",
       "int_80_score    144.497565\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3630371",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_boot_ints_group = dtw_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "dtw_boot_ints_group['mean'] = dtw_test_perf['mean'].values\n",
    "dtw_boot_ints_group['int_95_score_scaled'] = dtw_boot_ints_group['int_95_score']/dtw_boot_ints_group['mean']\n",
    "dtw_boot_ints_group['int_80_score_scaled'] = dtw_boot_ints_group['int_80_score']/dtw_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e05d6367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    0.771050\n",
       "int_80_score_scaled    0.455168\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57500a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
