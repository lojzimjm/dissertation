{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73642a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::tqdm==4.62.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::black==21.11b1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda-package-handling==1.7.3=py38h497a2fe_1\n",
      "  - conda-forge/noarch::dask-core==2021.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::imageio==2.9.0=py_0\n",
      "  - conda-forge/linux-64::pytest==6.2.5=py38h578d9bd_1\n",
      "  - conda-forge/linux-64::watchdog==2.1.6=py38h578d9bd_1\n",
      "  - conda-forge/linux-64::aiohttp==3.8.1=py38h497a2fe_0\n",
      "  - conda-forge/linux-64::astropy==5.0=py38h6c62de6_0\n",
      "  - conda-forge/linux-64::bokeh==2.4.2=py38h578d9bd_0\n",
      "  - conda-forge/linux-64::distributed==2021.11.2=py38h578d9bd_0\n",
      "  - conda-forge/noarch::flask==2.0.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib-base==3.5.0=py38hf4fb855_0\n",
      "  - conda-forge/noarch::nbformat==5.1.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pylint==2.12.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::dask==2021.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclient==0.5.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::networkx==2.6.3=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::python-lsp-server==1.3.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn-base==0.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::nbconvert==6.3.0=py38h578d9bd_1\n",
      "  - conda-forge/noarch::pyls-spyder==0.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::python-lsp-black==1.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::requests==2.26.0=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::seaborn==0.11.2=hd8ed1ab_0\n",
      "  - conda-forge/noarch::anaconda-client==1.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda==4.11.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::cookiecutter==1.7.0=py_0\n",
      "  - conda-forge/noarch::jupyter_server==1.12.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib==3.5.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::pooch==1.5.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::anaconda-project==0.10.2=pyhd8ed1ab_0\n",
      "  - defaults/noarch::conda-token==0.3.0=pyhd3eb1b0_0\n",
      "  - conda-forge/noarch::ipyparallel==8.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.8.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook==6.4.6=pyha770c72_0\n",
      "  - conda-forge/linux-64::scikit-image==0.18.3=py38h43a58ef_0\n",
      "  - conda-forge/linux-64::nb_conda==2.2.1=py38h578d9bd_4\n",
      "  - conda-forge/noarch::nbclassic==0.3.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::widgetsnbextension==3.5.2=py38h578d9bd_1\n",
      "  - conda-forge/noarch::ipywidgets==7.6.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab==3.2.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::jupyter==1.0.0=py38h578d9bd_7\n",
      "  - conda-forge/noarch::numpydoc==1.1.0=py_1\n",
      "  - conda-forge/linux-64::spyder==5.2.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::sphinxcontrib-serializinghtml==1.1.5=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::sphinxcontrib-websupport==1.2.4=pyhd8ed1ab_1\n",
      "  - defaults/linux-64::_anaconda_depends==2021.11=py38_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.11.0\n",
      "  latest version: 4.12.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - lightgbm\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2021.10.8          |   py38h578d9bd_2         145 KB  conda-forge\n",
      "    colorama-0.4.4             |     pyh9f0ad1d_0          18 KB  conda-forge\n",
      "    dataclasses-0.8            |     pyhc8e2a94_3          10 KB  conda-forge\n",
      "    docutils-0.15.2            |   py38h578d9bd_3         739 KB  conda-forge\n",
      "    fsspec-2022.3.0            |     pyhd8ed1ab_0          93 KB  conda-forge\n",
      "    jsonschema-4.5.1           |     pyhd8ed1ab_0          57 KB  conda-forge\n",
      "    lightgbm-3.3.2             |   py38h709712a_0         1.8 MB  conda-forge\n",
      "    lxml-4.8.0                 |   py38h0a891b7_2         1.4 MB  conda-forge\n",
      "    openssl-1.1.1o             |       h166bdaf_0         2.1 MB  conda-forge\n",
      "    pillow-8.4.0               |   py38h8e6f84c_0         704 KB  conda-forge\n",
      "    pyyaml-6.0                 |   py38h0a891b7_4         182 KB  conda-forge\n",
      "    sphinx-4.5.0               |     pyh6c4a22f_0         1.6 MB  conda-forge\n",
      "    websocket-client-1.3.2     |     pyhd8ed1ab_0          41 KB  conda-forge\n",
      "    werkzeug-2.1.2             |     pyhd8ed1ab_1         237 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  attrs              conda-forge/noarch::attrs-21.4.0-pyhd8ed1ab_0\n",
      "  colorama           conda-forge/noarch::colorama-0.4.4-pyh9f0ad1d_0\n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3\n",
      "  docutils           conda-forge/linux-64::docutils-0.15.2-py38h578d9bd_3\n",
      "  fsspec             conda-forge/noarch::fsspec-2022.3.0-pyhd8ed1ab_0\n",
      "  jsonschema         conda-forge/noarch::jsonschema-4.5.1-pyhd8ed1ab_0\n",
      "  lightgbm           conda-forge/linux-64::lightgbm-3.3.2-py38h709712a_0\n",
      "  lxml               conda-forge/linux-64::lxml-4.8.0-py38h0a891b7_2\n",
      "  nltk               conda-forge/noarch::nltk-3.6.7-pyhd8ed1ab_0\n",
      "  pillow             conda-forge/linux-64::pillow-8.4.0-py38h8e6f84c_0\n",
      "  pip                conda-forge/noarch::pip-22.0.4-pyhd8ed1ab_0\n",
      "  pyyaml             conda-forge/linux-64::pyyaml-6.0-py38h0a891b7_4\n",
      "  sphinx             conda-forge/noarch::sphinx-4.5.0-pyh6c4a22f_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.26.9-pyhd8ed1ab_0\n",
      "  websocket-client   conda-forge/noarch::websocket-client-1.3.2-pyhd8ed1ab_0\n",
      "  werkzeug           conda-forge/noarch::werkzeug-2.1.2-pyhd8ed1ab_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                          2021.10.8-py38h578d9bd_1 --> 2021.10.8-py38h578d9bd_2\n",
      "  openssl                                 1.1.1l-h7f98852_0 --> 1.1.1o-h166bdaf_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2021.10.8    | 145 KB    | ##################################### | 100% \n",
      "lxml-4.8.0           | 1.4 MB    | ##################################### | 100% \n",
      "lightgbm-3.3.2       | 1.8 MB    | ##################################### | 100% \n",
      "openssl-1.1.1o       | 2.1 MB    | ##################################### | 100% \n",
      "fsspec-2022.3.0      | 93 KB     | ##################################### | 100% \n",
      "werkzeug-2.1.2       | 237 KB    | ##################################### | 100% \n",
      "sphinx-4.5.0         | 1.6 MB    | ##################################### | 100% \n",
      "pillow-8.4.0         | 704 KB    | ##################################### | 100% \n",
      "jsonschema-4.5.1     | 57 KB     | ##################################### | 100% \n",
      "pyyaml-6.0           | 182 KB    | ##################################### | 100% \n",
      "dataclasses-0.8      | 10 KB     | ##################################### | 100% \n",
      "colorama-0.4.4       | 18 KB     | ##################################### | 100% \n",
      "websocket-client-1.3 | 41 KB     | ##################################### | 100% \n",
      "docutils-0.15.2      | 739 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install -c conda-forge lightgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05a769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import glob\n",
    "from lightgbm import LGBMRegressor\n",
    "import random\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import scipy\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "import contextlib\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2a7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(54321)\n",
    "random.seed(54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f65f0d",
   "metadata": {},
   "source": [
    "# Read in Data and Prepare for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f363c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Unseen Sensor/Processed/A19-9336-1_Northbound_2019_Processed.csv\n",
      "Reading Data/Unseen Sensor/Processed/A66-9521-1_Westbound_Processed.csv\n",
      "Reading Data/Unseen Sensor/Processed/M40-7048-2_Southbound_Processed.csv\n",
      "Reading Data/Unseen Sensor/Processed/M62-2056A_Eastbound_Processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to hold the dataframes of highways england data\n",
    "total_df_list = list()\n",
    "\n",
    "# Loop through the files, sorted in alphabetical order\n",
    "# Read them into a df, make sure they are sorted by timestamp, and append to the list\n",
    "for fname in sorted(glob.glob(\"Data/Unseen Sensor/Processed/*.csv\")):\n",
    "    print(\"Reading {}\".format(fname))\n",
    "    df = pd.read_csv(fname) #, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "    df = df.sort_values(by=\"timestamp\")\n",
    "    total_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682ccd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the start and end points csv, and subtract 1 to deal with index differences between R and python\n",
    "start_end = pd.read_csv(\"unseen_sensor_start_end_points.csv\")\n",
    "start_end[\"start\"] = start_end[\"start\"] - 1\n",
    "start_end[\"end\"] = start_end[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba78be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to hold the subset data frames (those with only 12 weeks of data per highway)\n",
    "subset_df_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c312dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each df in our original total df list\n",
    "for idx, df in enumerate(total_df_list):\n",
    "        \n",
    "    # Filter the timeframe based on the start_end_points csv files\n",
    "    subset_df = df.iloc[start_end.iloc[idx,1]:start_end.iloc[idx,2], ]\\\n",
    "    .reset_index(drop=True).reset_index(drop=False)\\\n",
    "    .rename(columns={\"index\":\"rn\"})\n",
    "    \n",
    "    # Create a new field called train_val_test to differentiate each set of data\n",
    "    subset_df[\"train_val_test\"] = np.where(subset_df[\"rn\"]<(96*7*8),\n",
    "                                           \"train\",\n",
    "                                           np.where(subset_df[\"rn\"]<(96*7*10),\n",
    "                                                    \"val\",\n",
    "                                                    \"test\"\n",
    "                                                   )\n",
    "                                       )\n",
    "    \n",
    "    # Append to list\n",
    "    subset_df_list.append(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64246820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of df's with only fields we need\n",
    "\n",
    "# Initialize empty list\n",
    "model_df_list = list()\n",
    "\n",
    "# For df in subset list\n",
    "for df in subset_df_list:\n",
    "       \n",
    "    # Extract the timestamp, the volume, and the train_val_test assignment\n",
    "    model_df = df[['timestamp', 'total_volume', \"train_val_test\"]]\\\n",
    "    .rename(columns={'timestamp':'start', 'total_volume':'target'})\n",
    "    \n",
    "    # Append this df to the new list\n",
    "    model_df_list.append(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1e1df",
   "metadata": {},
   "source": [
    "## Create Lag Emebedded Matrices for each TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542676fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_n = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56463d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8605/3230010149.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = df['target'].shift(n)\n"
     ]
    }
   ],
   "source": [
    "# # Lag embed the data frames and save to a list\n",
    "lag_embed_df_list = list()\n",
    "\n",
    "for df in model_df_list:\n",
    "    # For each df in our list\n",
    "    for n in range(1, (lag_n+1)):\n",
    "        # For each lag level, up to 960\n",
    "        # Create a new column called target-n\n",
    "        name = f\"target-{n}\"\n",
    "        # Save the target shifted n values into this colume\n",
    "        df[name] = df['target'].shift(n)\n",
    "    # Append to list\n",
    "    lag_embed_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca89cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the lag embedded list into train, val, and test lists\n",
    "\n",
    "# First, initialize empty lists for each train, val, and test\n",
    "train_df_list = list()\n",
    "val_df_list = list()\n",
    "test_df_list = list()\n",
    "\n",
    "for i in range(len(lag_embed_df_list)):\n",
    "    # For each df in our list\n",
    "    df = lag_embed_df_list[i].copy()\n",
    "\n",
    "    # Add a ts_index of i+1 to join with clustering data from R\n",
    "    df['ts_index'] = i + 1\n",
    "    \n",
    "    # Subset into train, val, and test df's based on the train_val_test_field\n",
    "    train_df = df.query(\"train_val_test == 'train'\").copy()\n",
    "    val_df = df.query(\"train_val_test=='val'\").copy()\n",
    "    test_df = df.query(\"train_val_test=='test'\").copy()\n",
    "    \n",
    "    # Append to appropriate lists\n",
    "    train_df_list.append(train_df)\n",
    "    val_df_list.append(val_df)\n",
    "    test_df_list.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be8da73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all dfs from the lists together to create one full train, val, and test df\n",
    "train_df_full = pd.concat(train_df_list)\n",
    "val_df_full = pd.concat(val_df_list)\n",
    "test_df_full = pd.concat(test_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67472300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "train_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "val_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "test_df_full.drop(columns=['start', 'train_val_test'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe73801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the training and validation data together for later use\n",
    "train_val_df_full = train_df_full.append(val_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0546bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused variables to free up memory\n",
    "del train_df_list\n",
    "del val_df_list \n",
    "del test_df_list\n",
    "del lag_embed_df_list\n",
    "del model_df_list\n",
    "del subset_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "644f1ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force garbage collection to free up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f85558bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_sen_clust = pd.read_csv(\"Results/Unseen Sensor/clust_assign.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e787b689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rand</th>\n",
       "      <th>catch22</th>\n",
       "      <th>tsfeat</th>\n",
       "      <th>dtw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rand  catch22  tsfeat  dtw\n",
       "0           1     3        1       2    2\n",
       "1           2     2        1       2    1\n",
       "2           3     1        1       2    1\n",
       "3           4     4        1       1    1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4684068c",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffc66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file to use later\n",
    "filename = 'Results/Global/LightGBM Bayes/Full/model'\n",
    "mod = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61acb290",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('Results/Global/LightGBM Bayes/Full/residual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e42b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute test preds\n",
    "def compute_lgbm_test_preds(mod, data, lag_n):\n",
    "    \"\"\"Function which takes in: a model, test data, and the lag embedding to use, and returns a df of forecasts\"\"\"\n",
    "\n",
    "    # Initialize an empty data frame to store preds\n",
    "    pred_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop through each individual time series index in the data set\n",
    "    for ts_idx in data.ts_index.unique():\n",
    "        # Create the X matrix for each one\n",
    "        X = data.query(\"ts_index==@ts_idx\").iloc[:,1:(lag_n+1)].copy()\n",
    "\n",
    "        # Forecast for that X matrix\n",
    "        preds = mod.predict(X)\n",
    "        \n",
    "        # Save the results to a temp data frame\n",
    "        pred_df_sub = pd.DataFrame({\"ts_index\": ts_idx, \"test_preds\": preds})\n",
    "        \n",
    "        # Append to primary data frame\n",
    "        pred_df = pred_df.append(pred_df_sub)\n",
    "    \n",
    "    # Return df of all preds with corresponding ts_index column\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0814a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds = compute_lgbm_test_preds(mod, test_df_full, lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0709287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute performance metrics on test data\n",
    "def compute_lgbm_test_perf(preds, data):\n",
    "    \"\"\"Function which takes inputs: a data frame of test predictions, and a test data df,\n",
    "    and which returns a data frame of model performance\"\"\"\n",
    "    \n",
    "    # Create an empty list to store model performance\n",
    "    perf_ls = list()\n",
    "    \n",
    "    # For each time series index in our data set\n",
    "    for ts_idx in data.ts_index.unique():\n",
    "        # Get the target (actual) for that index\n",
    "        y_sub = data.query(\"ts_index==@ts_idx\").iloc[:,0]\n",
    "        # Extract the corresponding forecasts\n",
    "        preds_sub = preds.query(\"ts_index==@ts_idx\").test_preds\n",
    "        \n",
    "        # Compute rmse, mae, and the mean of the true target value for those preds\n",
    "        rmse_sub = mean_squared_error(y_sub, preds_sub, squared=False)\n",
    "        mae_sub = mean_absolute_error(y_sub, preds_sub)\n",
    "        mean_sub = np.mean(y_sub)\n",
    "        \n",
    "        # Save those metrics to a dictionary\n",
    "        pred_dict = {\"rmse\": rmse_sub, \"mae\": mae_sub, \"mean\": mean_sub}\n",
    "        \n",
    "        # Append the dictionary to the list\n",
    "        perf_ls.append(pred_dict)\n",
    "        \n",
    "    # Return a data frame of model performance created from the list of dictionaries\n",
    "    return pd.DataFrame(perf_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ccc5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model perf metrics using above function\n",
    "full_mod_test_perf = compute_lgbm_test_perf(unseen_test_preds, test_df_full)\n",
    "\n",
    "# Compute scaled performance metrics in new columns\n",
    "full_mod_test_perf['nrmse'] = full_mod_test_perf['rmse']/full_mod_test_perf['mean']\n",
    "full_mod_test_perf['smae'] = full_mod_test_perf['mae']/full_mod_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6cdb7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      41.851829\n",
       "mae       27.121187\n",
       "mean     377.001860\n",
       "nrmse      0.120557\n",
       "smae       0.082307\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of model perf metrics\n",
    "full_mod_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e057d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute pred intervals with bootstrap method\n",
    "def compute_lgbm_boostrap_int(preds, resid, n_boot):\n",
    "    \"\"\"Function which takes in a model's predictions and residuals, and a number of bootstrap resamples to use,\n",
    "    and which outputs a df with pred intervals at 80% and 95%\"\"\"\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    random.seed(54321)\n",
    "    np.random.seed(54321)\n",
    "    \n",
    "    # Create empty columns in the pred df to store the PIs\n",
    "    preds['lo_95'] = np.nan\n",
    "    preds['hi_95'] = np.nan\n",
    "    preds['lo_80'] = np.nan\n",
    "    preds['hi_80'] = np.nan\n",
    "    \n",
    "    # For each row in the pred df\n",
    "    for n in range(preds.shape[0]):\n",
    "        # Sample with replacement n_boot times from the residuals\n",
    "        resid_boot = np.random.choice(resid, size=n_boot, replace=True)\n",
    "        # Extract the forecast value for that row\n",
    "        pred_n = preds.iloc[n, :].test_preds\n",
    "        # Add the residual vector to the forecast value\n",
    "        pred_n_boot = resid_boot + pred_n\n",
    "        \n",
    "        # Compute quantiles of this residual+forecast vector\n",
    "        percent_95_lo = np.percentile(pred_n_boot, 2.5)\n",
    "        percent_95_hi = np.percentile(pred_n_boot, 97.5)\n",
    "        \n",
    "        percent_80_lo = np.percentile(pred_n_boot, 10)\n",
    "        percent_80_hi = np.percentile(pred_n_boot, 90)\n",
    "        \n",
    "        # Save these quantiles to the appropriate df column\n",
    "        preds.iloc[n, 2] = percent_95_lo\n",
    "        preds.iloc[n, 3] = percent_95_hi\n",
    "        preds.iloc[n, 4] = percent_80_lo\n",
    "        preds.iloc[n, 5] = percent_80_hi\n",
    "    \n",
    "    # Return the updated preds data frame\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10188018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PIs with 1000 bootstrap samples\n",
    "nboot = 1000\n",
    "full_mod_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds, \n",
    "                                               res.residual.values, \n",
    "                                               nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa9e11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the true values into their own df column\n",
    "full_mod_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f8176f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_index</th>\n",
       "      <th>test_preds</th>\n",
       "      <th>lo_95</th>\n",
       "      <th>hi_95</th>\n",
       "      <th>lo_80</th>\n",
       "      <th>hi_80</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>305.268213</td>\n",
       "      <td>254.766238</td>\n",
       "      <td>364.341719</td>\n",
       "      <td>281.346342</td>\n",
       "      <td>334.368586</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>255.700589</td>\n",
       "      <td>199.820108</td>\n",
       "      <td>317.763844</td>\n",
       "      <td>225.932045</td>\n",
       "      <td>283.377616</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>223.922536</td>\n",
       "      <td>166.159973</td>\n",
       "      <td>288.504607</td>\n",
       "      <td>193.912266</td>\n",
       "      <td>250.418422</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>211.703889</td>\n",
       "      <td>151.296535</td>\n",
       "      <td>271.999550</td>\n",
       "      <td>184.541507</td>\n",
       "      <td>240.285101</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>179.286284</td>\n",
       "      <td>118.957231</td>\n",
       "      <td>237.056086</td>\n",
       "      <td>148.150057</td>\n",
       "      <td>207.128656</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_index  test_preds       lo_95       hi_95       lo_80       hi_80  \\\n",
       "0         1  305.268213  254.766238  364.341719  281.346342  334.368586   \n",
       "1         1  255.700589  199.820108  317.763844  225.932045  283.377616   \n",
       "2         1  223.922536  166.159973  288.504607  193.912266  250.418422   \n",
       "3         1  211.703889  151.296535  271.999550  184.541507  240.285101   \n",
       "4         1  179.286284  118.957231  237.056086  148.150057  207.128656   \n",
       "\n",
       "   actual  \n",
       "0   263.0  \n",
       "1   242.0  \n",
       "2   234.0  \n",
       "3   188.0  \n",
       "4   170.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mod_boot_ints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7655ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to compute the interval score\n",
    "def interval_score(true_values, lower, upper, interval_range):\n",
    "    \"\"\" Function which takes in the true values, the upper and lower bounds of PIs, and the PI level (e.g., 90%)\n",
    "        and from these inputs, computes the interval score for each prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute alpha from the interval range\n",
    "    alpha = 1-interval_range\n",
    "    \n",
    "    # Save the upper, lower, and true_values as numpy arrays for computation purposes\n",
    "    upper = np.array(upper)\n",
    "    lower = np.array(lower)\n",
    "    true_values = np.array(true_values)\n",
    "    \n",
    "    # Compute the lower component of the interval score - just a boolean for true below interval\n",
    "    def lower_ind(true,low):\n",
    "        if true<low:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the upper component of the interval score - similar boolean for true above interval\n",
    "    def upper_ind(true,up):\n",
    "        if true>up:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the actual score for each obsveration - formula here: https://epiforecasts.io/scoringutils/reference/interval_score.html\n",
    "    scores = (upper-lower) + (2/alpha)*(lower-true_values)*(lower > true_values) + (2/alpha)*(true_values-upper)*(true_values > upper)\n",
    "    \n",
    "    # Return the scores array\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79ff7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 95% and 80% PI scores using the above function as new data frame columns\n",
    "full_mod_boot_ints['int_95_score'] = interval_score(full_mod_boot_ints.actual, \n",
    "                                                    full_mod_boot_ints.lo_95,\n",
    "                                                    full_mod_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "full_mod_boot_ints['int_80_score'] = interval_score(full_mod_boot_ints.actual, \n",
    "                                                    full_mod_boot_ints.lo_80,\n",
    "                                                    full_mod_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bb00c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      377.200035\n",
       "lo_95           316.589974\n",
       "hi_95           440.030265\n",
       "lo_80           348.566140\n",
       "hi_80           406.796210\n",
       "actual          377.001860\n",
       "int_95_score    373.881683\n",
       "int_80_score    174.792619\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of the interval scores\n",
    "full_mod_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "adef6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mod_boot_ints_group = full_mod_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "full_mod_boot_ints_group['mean'] = full_mod_test_perf['mean'].values\n",
    "full_mod_boot_ints_group['int_95_score_scaled'] = full_mod_boot_ints_group['int_95_score']/full_mod_boot_ints_group['mean']\n",
    "full_mod_boot_ints_group['int_80_score_scaled'] = full_mod_boot_ints_group['int_80_score']/full_mod_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d0144793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    0.977406\n",
       "int_80_score_scaled    0.504571\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mod_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f2643",
   "metadata": {},
   "source": [
    "# Random Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f29e87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    1\n",
       "3    4\n",
       "Name: rand, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba3304c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clust_mod3 = joblib.load(\"Results/Global/LightGBM Bayes/Random Cluster/model_2\")\n",
    "rand_clust_mod2 = joblib.load(\"Results/Global/LightGBM Bayes/Random Cluster/model_1\")\n",
    "rand_clust_mod1 = joblib.load(\"Results/Global/LightGBM Bayes/Random Cluster/model_0\")\n",
    "rand_clust_mod4 = joblib.load(\"Results/Global/LightGBM Bayes/Random Cluster/model_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b15aed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clust_res = pd.read_csv(\"Results/Global/LightGBM Bayes/Random Cluster/residual.csv\")\n",
    "rand_clust_res['residual'] = rand_clust_res['residual'].apply(eval)\n",
    "\n",
    "res_rand_clust_3 = rand_clust_res.query(\"cluster==3\")['residual'].values[0]\n",
    "res_rand_clust_2 = rand_clust_res.query(\"cluster==2\")['residual'].values[0]\n",
    "res_rand_clust_1 = rand_clust_res.query(\"cluster==1\")['residual'].values[0]\n",
    "res_rand_clust_4 = rand_clust_res.query(\"cluster==4\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ac860dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_rand_clust3 = compute_lgbm_test_preds(rand_clust_mod3, \n",
    "                                                        test_df_full.query(\"ts_index==1\"), \n",
    "                                                        lag_n)\n",
    "\n",
    "unseen_test_preds_rand_clust2 = compute_lgbm_test_preds(rand_clust_mod2, \n",
    "                                                        test_df_full.query(\"ts_index==2\"), \n",
    "                                                        lag_n)\n",
    "\n",
    "unseen_test_preds_rand_clust1 = compute_lgbm_test_preds(rand_clust_mod1, \n",
    "                                                        test_df_full.query(\"ts_index==3\"), \n",
    "                                                        lag_n)\n",
    "\n",
    "unseen_test_preds_rand_clust4 = compute_lgbm_test_preds(rand_clust_mod4, \n",
    "                                                        test_df_full.query(\"ts_index==4\"), \n",
    "                                                        lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "deb9bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model perf metrics using above function\n",
    "rand_clust3_test_perf = compute_lgbm_test_perf(unseen_test_preds_rand_clust3, test_df_full.query(\"ts_index==1\"))\n",
    "rand_clust2_test_perf = compute_lgbm_test_perf(unseen_test_preds_rand_clust2, test_df_full.query(\"ts_index==2\"))\n",
    "rand_clust1_test_perf = compute_lgbm_test_perf(unseen_test_preds_rand_clust1, test_df_full.query(\"ts_index==3\"))\n",
    "rand_clust4_test_perf = compute_lgbm_test_perf(unseen_test_preds_rand_clust4, test_df_full.query(\"ts_index==4\"))\n",
    "\n",
    "rand_clust_test_perf = rand_clust3_test_perf.append(rand_clust2_test_perf).append(rand_clust1_test_perf).append(rand_clust4_test_perf)\n",
    "\n",
    "# Compute scaled performance metrics in new columns\n",
    "rand_clust_test_perf['nrmse'] = rand_clust_test_perf['rmse']/rand_clust_test_perf['mean']\n",
    "rand_clust_test_perf['smae'] = rand_clust_test_perf['mae']/rand_clust_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88a8f8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      43.554114\n",
       "mae       29.037834\n",
       "mean     377.001860\n",
       "nrmse      0.126193\n",
       "smae       0.087433\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_clust_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aab8ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PIs with 1000 bootstrap samples\n",
    "rand3_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_rand_clust3,\n",
    "                                            res_rand_clust_3, \n",
    "                                            nboot)\n",
    "\n",
    "\n",
    "rand2_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_rand_clust2,\n",
    "                                            res_rand_clust_2, \n",
    "                                            nboot)\n",
    "\n",
    "rand1_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_rand_clust1,\n",
    "                                            res_rand_clust_1, \n",
    "                                            nboot)\n",
    "\n",
    "rand4_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_rand_clust4,\n",
    "                                            res_rand_clust_4, \n",
    "                                            nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04398977",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_boot_ints = rand3_boot_ints.append(rand2_boot_ints).append(rand1_boot_ints).append(rand4_boot_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2787b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the true values into their own df column\n",
    "rand_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4e64302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 95% and 80% PI scores using the above function as new data frame columns\n",
    "rand_boot_ints['int_95_score'] = interval_score(rand_boot_ints.actual, \n",
    "                                                    rand_boot_ints.lo_95,\n",
    "                                                    rand_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "rand_boot_ints['int_80_score'] = interval_score(rand_boot_ints.actual, \n",
    "                                                    rand_boot_ints.lo_80,\n",
    "                                                    rand_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6cd9580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      374.756530\n",
       "lo_95           328.684062\n",
       "hi_95           422.503904\n",
       "lo_80           350.424005\n",
       "hi_80           399.815557\n",
       "actual          377.001860\n",
       "int_95_score    500.655999\n",
       "int_80_score    198.306081\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e8a972a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_boot_ints_group = rand_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "rand_boot_ints_group['mean'] = rand_clust_test_perf['mean'].values\n",
    "rand_boot_ints_group['int_95_score_scaled'] = rand_boot_ints_group['int_95_score']/rand_boot_ints_group['mean']\n",
    "rand_boot_ints_group['int_80_score_scaled'] = rand_boot_ints_group['int_80_score']/rand_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a4d1b6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    1.102840\n",
       "int_80_score_scaled    0.535848\n",
       "dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f430da8",
   "metadata": {},
   "source": [
    "# Highway System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2882c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_mod = joblib.load(\"Results/Global/LightGBM Bayes/Highway System/model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73c6f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_res = pd.read_csv(\"Results/Global/LightGBM Bayes/Highway System/residual.csv\")\n",
    "highway_res['residual'] = highway_res['residual'].apply(eval)\n",
    "\n",
    "eng_res = highway_res.query(\"cluster==1\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a03fe340",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_highway = compute_lgbm_test_preds(eng_mod, \n",
    "                                                    test_df_full,\n",
    "                                                    lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "636ee37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_test_perf = compute_lgbm_test_perf(unseen_test_preds_highway, test_df_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eeaefe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_test_perf['nrmse'] = highway_test_perf['rmse']/highway_test_perf['mean']\n",
    "highway_test_perf['smae'] = highway_test_perf['mae']/highway_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f63d4274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      42.395630\n",
       "mae       27.745831\n",
       "mean     377.001860\n",
       "nrmse      0.122915\n",
       "smae       0.084693\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4883b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_highway,\n",
    "                                              eng_res,\n",
    "                                              nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a5a413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10ae79ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_boot_ints['int_95_score'] = interval_score(highway_boot_ints.actual, \n",
    "                                                    highway_boot_ints.lo_95,\n",
    "                                                    highway_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "highway_boot_ints['int_80_score'] = interval_score(highway_boot_ints.actual, \n",
    "                                                    highway_boot_ints.lo_80,\n",
    "                                                    highway_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78a82ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      377.409187\n",
       "lo_95           309.365376\n",
       "hi_95           449.023181\n",
       "lo_80           343.296052\n",
       "hi_80           412.867392\n",
       "actual          377.001860\n",
       "int_95_score    363.019542\n",
       "int_80_score    174.773428\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "793d7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_boot_ints_group = highway_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "highway_boot_ints_group['mean'] = highway_test_perf['mean'].values\n",
    "highway_boot_ints_group['int_95_score_scaled'] = highway_boot_ints_group['int_95_score']/highway_boot_ints_group['mean']\n",
    "highway_boot_ints_group['int_80_score_scaled'] = highway_boot_ints_group['int_80_score']/highway_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "737ec285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    1.013325\n",
       "int_80_score_scaled    0.531538\n",
       "dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05838517",
   "metadata": {},
   "source": [
    "# Catch22 KMeans Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44724adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "Name: catch22, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.catch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f03b1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_mod1 = joblib.load(\"Results/Global/LightGBM Bayes/Catch22 KMeans/model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a41c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_res = pd.read_csv(\"Results/Global/LightGBM Bayes/Catch22 KMeans/residual.csv\")\n",
    "catch22_res['residual'] = catch22_res['residual'].apply(eval)\n",
    "\n",
    "catch22_res1 = catch22_res.query(\"cluster==1\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c90b5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_catch22 = compute_lgbm_test_preds(catch22_mod1, \n",
    "                                                    test_df_full,\n",
    "                                                    lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88c2fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_test_perf = compute_lgbm_test_perf(unseen_test_preds_catch22, test_df_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0050f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_test_perf['nrmse'] = catch22_test_perf['rmse']/catch22_test_perf['mean']\n",
    "catch22_test_perf['smae'] = catch22_test_perf['mae']/catch22_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6743af99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      42.264104\n",
       "mae       27.956650\n",
       "mean     377.001860\n",
       "nrmse      0.121633\n",
       "smae       0.084240\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch22_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9560729",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_boot_ints = compute_lgbm_boostrap_int(unseen_test_preds_catch22,\n",
    "                                               catch22_res1,\n",
    "                                               nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8af571c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "152b753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_boot_ints['int_95_score'] = interval_score(catch22_boot_ints.actual, \n",
    "                                                    catch22_boot_ints.lo_95,\n",
    "                                                    catch22_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "catch22_boot_ints['int_80_score'] = interval_score(catch22_boot_ints.actual, \n",
    "                                                    catch22_boot_ints.lo_80,\n",
    "                                                    catch22_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74a8b265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      376.880176\n",
       "lo_95           325.234952\n",
       "hi_95           430.400636\n",
       "lo_80           348.812294\n",
       "hi_80           405.534113\n",
       "actual          377.001860\n",
       "int_95_score    407.694767\n",
       "int_80_score    180.634133\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch22_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d8011dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_boot_ints_group = catch22_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "catch22_boot_ints_group['mean'] = catch22_test_perf['mean'].values\n",
    "catch22_boot_ints_group['int_95_score_scaled'] = catch22_boot_ints_group['int_95_score']/catch22_boot_ints_group['mean']\n",
    "catch22_boot_ints_group['int_80_score_scaled'] = catch22_boot_ints_group['int_80_score']/catch22_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "41f3a169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    0.972671\n",
       "int_80_score_scaled    0.509896\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch22_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02f9a0",
   "metadata": {},
   "source": [
    "# TSFeat KMeans Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae5d5442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    1\n",
       "Name: tsfeat, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.tsfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc54a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_mod2 = joblib.load(\"Results/Global/LightGBM Bayes/TSFeat KMeans/model_1\")\n",
    "tsfeat_mod1 = joblib.load(\"Results/Global/LightGBM Bayes/TSFeat KMeans/model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27beebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_res = pd.read_csv(\"Results/Global/LightGBM Bayes/TSFeat KMeans/residual.csv\")\n",
    "tsfeat_res['residual'] = tsfeat_res['residual'].apply(eval)\n",
    "\n",
    "tsfeat_res2 = tsfeat_res.query(\"cluster==2\")['residual'].values[0]\n",
    "tsfeat_res1 = tsfeat_res.query(\"cluster==1\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "930a95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_tsfeat2 = compute_lgbm_test_preds(tsfeat_mod2, \n",
    "                                                    test_df_full.query(\"ts_index!=4\"),\n",
    "                                                    lag_n)\n",
    "\n",
    "unseen_test_preds_tsfeat1 = compute_lgbm_test_preds(tsfeat_mod1, \n",
    "                                                    test_df_full.query(\"ts_index==4\"),\n",
    "                                                    lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2190db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_test_perf2 = compute_lgbm_test_perf(unseen_test_preds_tsfeat2, test_df_full.query(\"ts_index!=4\"))\n",
    "tsfeat_test_perf1 = compute_lgbm_test_perf(unseen_test_preds_tsfeat1, test_df_full.query(\"ts_index==4\"))\n",
    "\n",
    "tsfeat_test_perf = tsfeat_test_perf2.append(tsfeat_test_perf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92b85b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_test_perf['nrmse'] = tsfeat_test_perf['rmse']/tsfeat_test_perf['mean']\n",
    "tsfeat_test_perf['smae'] = tsfeat_test_perf['mae']/tsfeat_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ff716f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      42.200990\n",
       "mae       28.080535\n",
       "mean     377.001860\n",
       "nrmse      0.121487\n",
       "smae       0.083932\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsfeat_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec505b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_boot_ints2 = compute_lgbm_boostrap_int(unseen_test_preds_tsfeat2,\n",
    "                                              tsfeat_res2,\n",
    "                                              nboot)\n",
    "\n",
    "tsfeat_boot_ints1 = compute_lgbm_boostrap_int(unseen_test_preds_tsfeat1,\n",
    "                                              tsfeat_res1,\n",
    "                                              nboot)\n",
    "\n",
    "tsfeat_boot_ints = tsfeat_boot_ints2.append(tsfeat_boot_ints1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ffb6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3ba84c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_boot_ints['int_95_score'] = interval_score(tsfeat_boot_ints.actual, \n",
    "                                                    tsfeat_boot_ints.lo_95,\n",
    "                                                    tsfeat_boot_ints.hi_95,\n",
    "                                                    0.95)\n",
    "                                                    \n",
    "tsfeat_boot_ints['int_80_score'] = interval_score(tsfeat_boot_ints.actual, \n",
    "                                                    tsfeat_boot_ints.lo_80,\n",
    "                                                    tsfeat_boot_ints.hi_80,\n",
    "                                                    0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8f9759d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      376.273824\n",
       "lo_95           318.735205\n",
       "hi_95           435.248455\n",
       "lo_80           347.461421\n",
       "hi_80           405.873810\n",
       "actual          377.001860\n",
       "int_95_score    386.593020\n",
       "int_80_score    180.505476\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsfeat_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "963d8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_boot_ints_group = tsfeat_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "tsfeat_boot_ints_group['mean'] = tsfeat_test_perf['mean'].values\n",
    "tsfeat_boot_ints_group['int_95_score_scaled'] = tsfeat_boot_ints_group['int_95_score']/tsfeat_boot_ints_group['mean']\n",
    "tsfeat_boot_ints_group['int_80_score_scaled'] = tsfeat_boot_ints_group['int_80_score']/tsfeat_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3db9393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    0.965833\n",
       "int_80_score_scaled    0.509641\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsfeat_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43452e",
   "metadata": {},
   "source": [
    "# Train and Test - DTW Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ea6b1b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "Name: dtw, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sen_clust.dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e80d8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_mod2 = joblib.load(\"Results/Global/LightGBM Bayes/DTW/model_1\")\n",
    "dtw_mod1 = joblib.load(\"Results/Global/LightGBM Bayes/DTW/model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c2cdca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_res = pd.read_csv(\"Results/Global/LightGBM Bayes/DTW/residual.csv\")\n",
    "dtw_res['residual'] = dtw_res['residual'].apply(eval)\n",
    "\n",
    "dtw_res2 = dtw_res.query(\"cluster==2\")['residual'].values[0]\n",
    "dtw_res1 = dtw_res.query(\"cluster==1\")['residual'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2eebed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_preds_dtw2 = compute_lgbm_test_preds(dtw_mod2, \n",
    "                                                 test_df_full.query(\"ts_index==1\"),\n",
    "                                                 lag_n)\n",
    "\n",
    "unseen_test_preds_dtw1 = compute_lgbm_test_preds(dtw_mod1, \n",
    "                                                 test_df_full.query(\"ts_index!=1\"),\n",
    "                                                 lag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c93a60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_test_perf2 = compute_lgbm_test_perf(unseen_test_preds_dtw2, test_df_full.query(\"ts_index==1\"))\n",
    "\n",
    "dtw_test_perf1 = compute_lgbm_test_perf(unseen_test_preds_dtw1, test_df_full.query(\"ts_index!=1\"))\n",
    "\n",
    "dtw_test_perf = dtw_test_perf2.append(dtw_test_perf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "12c39608",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_test_perf['nrmse'] = dtw_test_perf['rmse']/dtw_test_perf['mean']\n",
    "dtw_test_perf['smae'] = dtw_test_perf['mae']/dtw_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "910a8912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      42.581503\n",
       "mae       28.182318\n",
       "mean     377.001860\n",
       "nrmse      0.129566\n",
       "smae       0.092134\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d8bf9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_boot_ints2 = compute_lgbm_boostrap_int(unseen_test_preds_dtw2,\n",
    "                                           dtw_res2,\n",
    "                                           nboot)\n",
    "\n",
    "dtw_boot_ints1 = compute_lgbm_boostrap_int(unseen_test_preds_dtw1,\n",
    "                                           dtw_res1,\n",
    "                                           nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa52dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_boot_ints = dtw_boot_ints2.append(dtw_boot_ints1)\n",
    "dtw_boot_ints['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7af05a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_boot_ints['int_95_score'] = interval_score(dtw_boot_ints.actual, \n",
    "                                               dtw_boot_ints.lo_95,\n",
    "                                               dtw_boot_ints.hi_95,\n",
    "                                               0.95)\n",
    "                                                    \n",
    "dtw_boot_ints['int_80_score'] = interval_score(dtw_boot_ints.actual, \n",
    "                                               dtw_boot_ints.lo_80,\n",
    "                                               dtw_boot_ints.hi_80,\n",
    "                                               0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "756950d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "test_preds      376.809457\n",
       "lo_95           306.006473\n",
       "hi_95           450.046898\n",
       "lo_80           338.793128\n",
       "hi_80           415.929342\n",
       "actual          377.001860\n",
       "int_95_score    334.566780\n",
       "int_80_score    169.128788\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_boot_ints.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f3630371",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_boot_ints_group = dtw_boot_ints.groupby(\"ts_index\").mean().reset_index()\n",
    "dtw_boot_ints_group['mean'] = dtw_test_perf['mean'].values\n",
    "dtw_boot_ints_group['int_95_score_scaled'] = dtw_boot_ints_group['int_95_score']/dtw_boot_ints_group['mean']\n",
    "dtw_boot_ints_group['int_80_score_scaled'] = dtw_boot_ints_group['int_80_score']/dtw_boot_ints_group['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e05d6367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_95_score_scaled    1.016889\n",
       "int_80_score_scaled    0.561006\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_boot_ints_group[['int_95_score_scaled', 'int_80_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57500a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
