{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install lightgbm and swifter modules and then load all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e73696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::tqdm==4.62.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::black==21.11b1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda-package-handling==1.7.3=py38h497a2fe_1\n",
      "  - conda-forge/noarch::dask-core==2021.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::imageio==2.9.0=py_0\n",
      "  - conda-forge/linux-64::pytest==6.2.5=py38h578d9bd_1\n",
      "  - conda-forge/linux-64::watchdog==2.1.6=py38h578d9bd_1\n",
      "  - conda-forge/linux-64::aiohttp==3.8.1=py38h497a2fe_0\n",
      "  - conda-forge/linux-64::astropy==5.0=py38h6c62de6_0\n",
      "  - conda-forge/linux-64::bokeh==2.4.2=py38h578d9bd_0\n",
      "  - conda-forge/linux-64::distributed==2021.11.2=py38h578d9bd_0\n",
      "  - conda-forge/noarch::flask==2.0.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib-base==3.5.0=py38hf4fb855_0\n",
      "  - conda-forge/noarch::nbformat==5.1.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pylint==2.12.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::dask==2021.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclient==0.5.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::networkx==2.6.3=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::python-lsp-server==1.3.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn-base==0.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::nbconvert==6.3.0=py38h578d9bd_1\n",
      "  - conda-forge/noarch::pyls-spyder==0.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::python-lsp-black==1.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::requests==2.26.0=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::seaborn==0.11.2=hd8ed1ab_0\n",
      "  - conda-forge/noarch::anaconda-client==1.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda==4.11.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::cookiecutter==1.7.0=py_0\n",
      "  - conda-forge/noarch::jupyter_server==1.12.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib==3.5.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::pooch==1.5.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::anaconda-project==0.10.2=pyhd8ed1ab_0\n",
      "  - defaults/noarch::conda-token==0.3.0=pyhd3eb1b0_0\n",
      "  - conda-forge/noarch::ipyparallel==8.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.8.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook==6.4.6=pyha770c72_0\n",
      "  - conda-forge/linux-64::scikit-image==0.18.3=py38h43a58ef_0\n",
      "  - conda-forge/linux-64::nb_conda==2.2.1=py38h578d9bd_4\n",
      "  - conda-forge/noarch::nbclassic==0.3.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::widgetsnbextension==3.5.2=py38h578d9bd_1\n",
      "  - conda-forge/noarch::ipywidgets==7.6.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab==3.2.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::jupyter==1.0.0=py38h578d9bd_7\n",
      "  - conda-forge/noarch::numpydoc==1.1.0=py_1\n",
      "  - conda-forge/linux-64::spyder==5.2.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::sphinxcontrib-serializinghtml==1.1.5=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::sphinxcontrib-websupport==1.2.4=pyhd8ed1ab_1\n",
      "  - defaults/linux-64::_anaconda_depends==2021.11=py38_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.11.0\n",
      "  latest version: 4.12.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - lightgbm\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2021.10.8          |   py38h578d9bd_2         145 KB  conda-forge\n",
      "    colorama-0.4.4             |     pyh9f0ad1d_0          18 KB  conda-forge\n",
      "    dataclasses-0.8            |     pyhc8e2a94_3          10 KB  conda-forge\n",
      "    docutils-0.15.2            |   py38h578d9bd_3         739 KB  conda-forge\n",
      "    fsspec-2022.3.0            |     pyhd8ed1ab_0          93 KB  conda-forge\n",
      "    jsonschema-4.5.1           |     pyhd8ed1ab_0          57 KB  conda-forge\n",
      "    lightgbm-3.3.2             |   py38h709712a_0         1.8 MB  conda-forge\n",
      "    lxml-4.8.0                 |   py38h0a891b7_2         1.4 MB  conda-forge\n",
      "    openssl-1.1.1o             |       h166bdaf_0         2.1 MB  conda-forge\n",
      "    pillow-8.4.0               |   py38h8e6f84c_0         704 KB  conda-forge\n",
      "    pyyaml-6.0                 |   py38h0a891b7_4         182 KB  conda-forge\n",
      "    sphinx-4.5.0               |     pyh6c4a22f_0         1.6 MB  conda-forge\n",
      "    websocket-client-1.3.2     |     pyhd8ed1ab_0          41 KB  conda-forge\n",
      "    werkzeug-2.1.2             |     pyhd8ed1ab_1         237 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  attrs              conda-forge/noarch::attrs-21.4.0-pyhd8ed1ab_0\n",
      "  colorama           conda-forge/noarch::colorama-0.4.4-pyh9f0ad1d_0\n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3\n",
      "  docutils           conda-forge/linux-64::docutils-0.15.2-py38h578d9bd_3\n",
      "  fsspec             conda-forge/noarch::fsspec-2022.3.0-pyhd8ed1ab_0\n",
      "  jsonschema         conda-forge/noarch::jsonschema-4.5.1-pyhd8ed1ab_0\n",
      "  lightgbm           conda-forge/linux-64::lightgbm-3.3.2-py38h709712a_0\n",
      "  lxml               conda-forge/linux-64::lxml-4.8.0-py38h0a891b7_2\n",
      "  nltk               conda-forge/noarch::nltk-3.6.7-pyhd8ed1ab_0\n",
      "  pillow             conda-forge/linux-64::pillow-8.4.0-py38h8e6f84c_0\n",
      "  pip                conda-forge/noarch::pip-22.0.4-pyhd8ed1ab_0\n",
      "  pyyaml             conda-forge/linux-64::pyyaml-6.0-py38h0a891b7_4\n",
      "  sphinx             conda-forge/noarch::sphinx-4.5.0-pyh6c4a22f_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.26.9-pyhd8ed1ab_0\n",
      "  websocket-client   conda-forge/noarch::websocket-client-1.3.2-pyhd8ed1ab_0\n",
      "  werkzeug           conda-forge/noarch::werkzeug-2.1.2-pyhd8ed1ab_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                          2021.10.8-py38h578d9bd_1 --> 2021.10.8-py38h578d9bd_2\n",
      "  openssl                                 1.1.1l-h7f98852_0 --> 1.1.1o-h166bdaf_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2021.10.8    | 145 KB    | ##################################### | 100% \n",
      "lxml-4.8.0           | 1.4 MB    | ##################################### | 100% \n",
      "lightgbm-3.3.2       | 1.8 MB    | ##################################### | 100% \n",
      "openssl-1.1.1o       | 2.1 MB    | ##################################### | 100% \n",
      "fsspec-2022.3.0      | 93 KB     | ##################################### | 100% \n",
      "werkzeug-2.1.2       | 237 KB    | ##################################### | 100% \n",
      "sphinx-4.5.0         | 1.6 MB    | ##################################### | 100% \n",
      "pillow-8.4.0         | 704 KB    | ##################################### | 100% \n",
      "jsonschema-4.5.1     | 57 KB     | ##################################### | 100% \n",
      "pyyaml-6.0           | 182 KB    | ##################################### | 100% \n",
      "dataclasses-0.8      | 10 KB     | ##################################### | 100% \n",
      "colorama-0.4.4       | 18 KB     | ##################################### | 100% \n",
      "websocket-client-1.3 | 41 KB     | ##################################### | 100% \n",
      "docutils-0.15.2      | 739 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install -c conda-forge lightgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install -c conda-forge swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install -c conda-forge bayesian-optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d63b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import glob\n",
    "from lightgbm import LGBMRegressor\n",
    "import random\n",
    "import boto3\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import scipy\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "import contextlib\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from bayes_opt import BayesianOptimization\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42941012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37bf83",
   "metadata": {},
   "source": [
    "# Read in Data and Prepare for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab2a0284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Processed/Highways_England/A11-6310-1_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A11-6312-2_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A14-1107A_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A14-1144B_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A1M-9842B_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A1M-9847a_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A46-7636-1_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A46-7636-2_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A47-6337-1_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A47-6337-2_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A5-6847-2_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A5-7572-1-Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A590-9531-1_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A590-9634-1_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A64-9251-1_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A64-9252-1_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A69-9784-1_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A69-9785-1_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M1-2148L_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M1-2633A_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M11-6400B_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M11-6747A_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M18-7569B_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M18-7578A_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M20-6552A2_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M20-6572B2_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M25-4490B_Counterclockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M25-4565A_Clockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M3-1524A_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M3-1537L_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M4-2156A_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M4-3434B_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M5-7650B_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M5-8291A_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M6-5441A_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M6-7036B_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M60-9327B_Counterclockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M60-9374A_Clockwise_2019_Processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to hold the dataframes of highways england data\n",
    "england_df_list = list()\n",
    "\n",
    "# Loop through the files, sorted in alphabetical order\n",
    "# Read them into a df, make sure they are sorted by timestamp, and append to the list\n",
    "for fname in sorted(glob.glob(\"Data/Processed/Highways_England/*.csv\")):\n",
    "    print(\"Reading {}\".format(fname))\n",
    "    df = pd.read_csv(fname) #, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "    df = df.sort_values(by=\"timestamp\")\n",
    "    england_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af4ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Processed/Portland/I205-101068_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I205-101073_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I405-100395_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I405-100527_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I5-100688_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I5-100703_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I84-101108_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I84-101161_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/OR217-100300_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/OR217-100314_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/R2 Delta Hwy-101745_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/R2 OR18-102111_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/R2 OR18-102113_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/SR 14-102001_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/SR 14-102003_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/SR 500-1000022_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/SR 500-1000104_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/US26-100627_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/US26-100650_Westbound_2019_Processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Follow the same process in this cell and the next as was done above, just for other highway systems\n",
    "portland_df_list = list()\n",
    "\n",
    "for fname in sorted(glob.glob(\"Data/Processed/Portland/*.csv\")):\n",
    "    print(\"Reading {}\".format(fname))\n",
    "    df = pd.read_csv(fname) #, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "    df = df.sort_values(by=\"timestamp\")\n",
    "    portland_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3babec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Processed/Utah/I15-3103178_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I15-749_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I215-134_Counterclockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I215-31_Clockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I70-3103400_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I70-3103401_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I80-600_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I80-667_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I84-451_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I84-482_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/LegacyParkway-810_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/LegacyParkway-890_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US189-260_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US189-470_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US40-634_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US40-635_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US6-3103114_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US6-3103115_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US89-483_Northbound_2019_Processed.csv\n"
     ]
    }
   ],
   "source": [
    "utah_df_list = list()\n",
    "\n",
    "for fname in sorted(glob.glob(\"Data/Processed/Utah/*.csv\")):\n",
    "    print(\"Reading {}\".format(fname))\n",
    "    df = pd.read_csv(fname) #, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "    df = df.sort_values(by=\"timestamp\")\n",
    "    utah_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195069f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all df lists together into one\n",
    "total_df_list = england_df_list + portland_df_list + utah_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116c3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the start and end points csv, and subtract 1 to deal with index differences between R and python\n",
    "start_end = pd.read_csv(\"start_end_points.csv\")\n",
    "start_end[\"start\"] = start_end[\"start\"] - 1\n",
    "start_end[\"end\"] = start_end[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8708700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to hold the subset data frames (those with only 12 weeks of data per highway)\n",
    "subset_df_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da2b4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each df in our original total df list\n",
    "for idx, df in enumerate(total_df_list):\n",
    "        \n",
    "    # Filter the timeframe based on the start_end_points csv files\n",
    "    subset_df = df.iloc[start_end.iloc[idx,0]:start_end.iloc[idx,1], ]\\\n",
    "    .reset_index(drop=True).reset_index(drop=False)\\\n",
    "    .rename(columns={\"index\":\"rn\"})\n",
    "    \n",
    "    # Create a new field called train_val_test to differentiate each set of data\n",
    "    subset_df[\"train_val_test\"] = np.where(subset_df[\"rn\"]<(96*7*8),\n",
    "                                           \"train\",\n",
    "                                           np.where(subset_df[\"rn\"]<(96*7*10),\n",
    "                                                    \"val\",\n",
    "                                                    \"test\"\n",
    "                                                   )\n",
    "                                       )\n",
    "    \n",
    "    # Append to list\n",
    "    subset_df_list.append(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8feeaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of df's with only fields we need\n",
    "\n",
    "# Initialize empty list\n",
    "model_df_list = list()\n",
    "\n",
    "# For df in subset list\n",
    "for df in subset_df_list:\n",
    "       \n",
    "    # Extract the timestamp, the volume, and the train_val_test assignment\n",
    "    model_df = df[['timestamp', 'total_volume', \"train_val_test\"]]\\\n",
    "    .rename(columns={'timestamp':'start', 'total_volume':'target'})\n",
    "    \n",
    "    # Append this df to the new list\n",
    "    model_df_list.append(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8241c",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab8e7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for progress bar:\n",
    "# https://stackoverflow.com/questions/24983493/tracking-progress-of-joblib-parallel-execution\n",
    "# This allows us to print a progress bar while running parallel loops using joblib \n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312bd295",
   "metadata": {},
   "source": [
    "## Create Lag Emebedded Matrices for each TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfe4561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the final lag value to be used for all lag embedding\n",
    "lag_n = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eac3e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8497/1739749478.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = df['target'].shift(n)\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to save lag embedded data into\n",
    "lag_embed_df_list = list()\n",
    "\n",
    "# For each data frame\n",
    "for df in model_df_list:\n",
    "    for n in range(1, (lag_n+1)):\n",
    "        # For each lag level, up to lag_n + 1 (we add 1 to preserve the target value correctly)\n",
    "        # Create a new column called target-n\n",
    "        name = f\"target-{n}\"\n",
    "        # Save the target shifted n values into this column\n",
    "        df[name] = df['target'].shift(n)\n",
    "    # Append the lag embedded df to the list\n",
    "    lag_embed_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e575bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the lag embedded list into train, val, and test lists\n",
    "\n",
    "# First, initialize empty lists for each train, val, and test\n",
    "train_df_list = list()\n",
    "val_df_list = list()\n",
    "test_df_list = list()\n",
    "\n",
    "# For each df in our list\n",
    "for i in range(len(lag_embed_df_list)):\n",
    "    \n",
    "    # Create a copy of just the data frame of interest\n",
    "    df = lag_embed_df_list[i].copy()\n",
    "    # Add a field to it for ts_index, this is for joining with cluster data later and is equal to i+1 due to \n",
    "    # differences in indexing between R and Python\n",
    "    df['ts_index'] = i + 1\n",
    "    \n",
    "    # Subset into train, val, and test df's based on the train_val_test_field\n",
    "    train_df = df.query(\"train_val_test == 'train'\").copy()\n",
    "    val_df = df.query(\"train_val_test=='val'\").copy()\n",
    "    test_df = df.query(\"train_val_test=='test'\").copy()\n",
    "   \n",
    "    # Append to appropriate lists\n",
    "    train_df_list.append(train_df)\n",
    "    val_df_list.append(val_df)\n",
    "    test_df_list.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f290bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all dfs from the lists together to create one full train, val, and test df\n",
    "train_df_full = pd.concat(train_df_list)\n",
    "val_df_full = pd.concat(val_df_list)\n",
    "test_df_full = pd.concat(test_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "354add84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "train_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "val_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "test_df_full.drop(columns=['start', 'train_val_test'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d25d464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the training and validation data together for later use\n",
    "train_val_df_full = train_df_full.append(val_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "981788b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused variables to free up memory\n",
    "del train_df_list\n",
    "del val_df_list \n",
    "del test_df_list\n",
    "del lag_embed_df_list\n",
    "del model_df_list\n",
    "del subset_df_list\n",
    "del total_df_list\n",
    "del england_df_list\n",
    "del portland_df_list\n",
    "del utah_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c20f309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b21b7a",
   "metadata": {},
   "source": [
    "# Full Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "f7c3a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y training and validation data frames\n",
    "# y is always the first column of the data frame, and X is the remaining columns up to lag_n+1\n",
    "# For train, we use dropna to ensure that the first lag_n row, which have null values in them,\n",
    "# are not included in the training data. This is not necessary for validation as there are no null values\n",
    "X_train_full = train_df_full.iloc[:,0:(lag_n+1)].dropna().iloc[:,1:]\n",
    "y_train_full = train_df_full.iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "\n",
    "X_val_full = val_df_full.iloc[:,1:(lag_n+1)]\n",
    "y_val_full = val_df_full.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5364c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to optimize a light gbm model using Bayesian optimization\n",
    "\n",
    "def optimize_lgbm_w_bayes(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Function takes in four inputs: the training and validation X and y data frames\n",
    "    and returns the model params found by the Bayesian optimizer to have the best performance\"\"\"\n",
    "    \n",
    "    # Set the X_train, y_train, X_val, and y_val variables inside the function\n",
    "    X_train = X_train\n",
    "    y_train = y_train\n",
    "    \n",
    "    X_val = X_val\n",
    "    y_val = y_val\n",
    "    \n",
    "    # Set up the min and max of the parameter space to explore for each parameter\n",
    "    bayes_param_ss = {\n",
    "    \"n_estimators\": (100, 1000),\n",
    "    \"max_depth\": (2, 25),\n",
    "    \"lambda_l1\": (0, 1),\n",
    "    \"lambda_l2\": (0, 1),\n",
    "    \"num_leaves\": (10, 150),\n",
    "    \"colsample_bytree\": (0.1, 1),\n",
    "    \"learning_rate\": (0.00001, 0.5)\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Define a function to compute validation set predictions\n",
    "    def val_predict(model, X_val, y_val):\n",
    "        \"\"\"Function which takes a trained model and X and y for validation set \n",
    "        and returns the scaled rmse for the validation set predictions\"\"\"\n",
    "        \n",
    "        # Compute the mean of the target values\n",
    "        val_mean = np.mean(y_val)\n",
    "        \n",
    "        # Compute predictions with the validation X data frame\n",
    "        val_preds = model.predict(X_val)\n",
    "        \n",
    "        # Compute validation rmse and scaled rmse by dividing by the mean\n",
    "        val_rmse = mean_squared_error(y_val, val_preds, squared=False)\n",
    "        val_nrmse = val_rmse/val_mean\n",
    "            \n",
    "        # Return scaled rmse\n",
    "        return val_nrmse\n",
    "    \n",
    "    \n",
    "    # Define a function to perform the Bayesian optimization\n",
    "    def lgbm_eval_for_bayes(n_estimators,\n",
    "                        max_depth,\n",
    "                        lambda_l1, \n",
    "                        lambda_l2,\n",
    "                        num_leaves,\n",
    "                        colsample_bytree,\n",
    "                        learning_rate\n",
    "                       ):\n",
    "    \n",
    "        \"\"\"Function which takes in parameter values as inputs and returns a value to be maximized by the\n",
    "        Bayesian optimizer. In this case, we return -1*validation_nrmse as this allows us to minimize the\n",
    "        validation nrmse\"\"\"\n",
    "        \n",
    "        # Set the proper boosting type\n",
    "        params = {\"boosting_type\": \"goss\"\n",
    "                 }\n",
    "\n",
    "        # Set the params dictionary to include all input params\n",
    "        # For n_estimators, max_depth, and num_leaves, round and cast as int - this is what the lgbm model requires\n",
    "        params[\"n_estimators\"] = int(round(n_estimators))\n",
    "        params[\"max_depth\"] = int(round(max_depth))\n",
    "        params[\"reg_alpha\"] = max(lambda_l1, 0)\n",
    "        params[\"reg_lambda\"] = max(lambda_l2, 0)\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params[\"colsample_bytree\"] = colsample_bytree\n",
    "        params[\"learning_rate\"] = learning_rate\n",
    "\n",
    "        # Create the model given these params\n",
    "        mod = LGBMRegressor(**params, random_state=54321)  \n",
    "        # Fit the model to the X and y training data defined earlier in the overall function\n",
    "        mod.fit(X_train, y_train)\n",
    "\n",
    "        # Compute validation performance using the data passed to the main function and the previously\n",
    "        # defined function to compute val performance. Note that we multiply by -1 here as the optimizer\n",
    "        # is expecting a value to be maximized, not minimized\n",
    "        val_perf = -1*np.mean(val_predict(mod, X_val, y_val))\n",
    "\n",
    "        # Return the negative validation nrmse\n",
    "        return val_perf\n",
    "\n",
    "    # Create an optimizer object    \n",
    "    optimizer = BayesianOptimization(lgbm_eval_for_bayes,\n",
    "                                     bayes_param_ss,\n",
    "                                     random_state=54321)\n",
    "    # Maximize the optimizer with 5 random initialization points and 25 further iterations\n",
    "    optimizer.maximize(init_points=5, n_iter=25)\n",
    "    \n",
    "    # Return the best param set found by the optimizer\n",
    "    return optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "7ee71b11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1318  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1319  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1428  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1558  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1387  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1415  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1346  \u001b[0m | \u001b[0m 0.1823  \u001b[0m | \u001b[0m 0.2334  \u001b[0m | \u001b[0m 0.3629  \u001b[0m | \u001b[0m 0.06587 \u001b[0m | \u001b[0m 17.26   \u001b[0m | \u001b[0m 859.2   \u001b[0m | \u001b[0m 141.3   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1295  \u001b[0m | \u001b[95m 0.5977  \u001b[0m | \u001b[95m 0.2829  \u001b[0m | \u001b[95m 0.9203  \u001b[0m | \u001b[95m 0.08668 \u001b[0m | \u001b[95m 8.428   \u001b[0m | \u001b[95m 942.3   \u001b[0m | \u001b[95m 106.7   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1514  \u001b[0m | \u001b[0m 0.6154  \u001b[0m | \u001b[0m 0.5809  \u001b[0m | \u001b[0m 0.5974  \u001b[0m | \u001b[0m 0.3896  \u001b[0m | \u001b[0m 23.0    \u001b[0m | \u001b[0m 433.1   \u001b[0m | \u001b[0m 83.41   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1406  \u001b[0m | \u001b[0m 0.2707  \u001b[0m | \u001b[0m 0.3919  \u001b[0m | \u001b[0m 0.8713  \u001b[0m | \u001b[0m 0.2398  \u001b[0m | \u001b[0m 21.29   \u001b[0m | \u001b[0m 182.6   \u001b[0m | \u001b[0m 128.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1339  \u001b[0m | \u001b[0m 0.5174  \u001b[0m | \u001b[0m 0.2394  \u001b[0m | \u001b[0m 0.01523 \u001b[0m | \u001b[0m 0.3594  \u001b[0m | \u001b[0m 2.433   \u001b[0m | \u001b[0m 593.3   \u001b[0m | \u001b[0m 126.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1315  \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 0.517   \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 0.09298 \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 583.4   \u001b[0m | \u001b[0m 123.1   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1346  \u001b[0m | \u001b[0m 0.957   \u001b[0m | \u001b[0m 0.5047  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.2706  \u001b[0m | \u001b[0m 8.573   \u001b[0m | \u001b[0m 757.1   \u001b[0m | \u001b[0m 17.0    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1417  \u001b[0m | \u001b[0m 0.2656  \u001b[0m | \u001b[0m 0.04668 \u001b[0m | \u001b[0m 0.03001 \u001b[0m | \u001b[0m 0.1727  \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 861.6   \u001b[0m | \u001b[0m 139.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.138   \u001b[0m | \u001b[0m 0.8199  \u001b[0m | \u001b[0m 0.4933  \u001b[0m | \u001b[0m 0.7328  \u001b[0m | \u001b[0m 0.2643  \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 398.9   \u001b[0m | \u001b[0m 92.87   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1724  \u001b[0m | \u001b[0m 0.5136  \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 0.06973 \u001b[0m | \u001b[0m 0.4773  \u001b[0m | \u001b[0m 10.62   \u001b[0m | \u001b[0m 642.0   \u001b[0m | \u001b[0m 97.73   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1424  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.371   \u001b[0m | \u001b[0m 9.194   \u001b[0m | \u001b[0m 969.5   \u001b[0m | \u001b[0m 23.1    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1356  \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.0695  \u001b[0m | \u001b[0m 0.3948  \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 27.02   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.137   \u001b[0m | \u001b[0m 0.9134  \u001b[0m | \u001b[0m 0.3416  \u001b[0m | \u001b[0m 0.2057  \u001b[0m | \u001b[0m 0.2121  \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 418.8   \u001b[0m | \u001b[0m 120.2   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1296  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.5603  \u001b[0m | \u001b[0m 0.4809  \u001b[0m | \u001b[0m 0.09778 \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 351.6   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1335  \u001b[0m | \u001b[0m 0.5316  \u001b[0m | \u001b[0m 0.3662  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.377   \u001b[0m | \u001b[0m 2.832   \u001b[0m | \u001b[0m 855.2   \u001b[0m | \u001b[0m 24.01   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1516  \u001b[0m | \u001b[0m 0.3696  \u001b[0m | \u001b[0m 0.9666  \u001b[0m | \u001b[0m 0.0882  \u001b[0m | \u001b[0m 0.3123  \u001b[0m | \u001b[0m 22.58   \u001b[0m | \u001b[0m 694.0   \u001b[0m | \u001b[0m 115.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1324  \u001b[0m | \u001b[0m 0.2374  \u001b[0m | \u001b[0m 0.5845  \u001b[0m | \u001b[0m 0.6013  \u001b[0m | \u001b[0m 0.06929 \u001b[0m | \u001b[0m 24.59   \u001b[0m | \u001b[0m 646.7   \u001b[0m | \u001b[0m 126.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1309  \u001b[0m | \u001b[0m 0.6942  \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.7711  \u001b[0m | \u001b[0m 0.1554  \u001b[0m | \u001b[0m 16.79   \u001b[0m | \u001b[0m 331.1   \u001b[0m | \u001b[0m 40.78   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.144   \u001b[0m | \u001b[0m 0.1268  \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 0.7912  \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 18.31   \u001b[0m | \u001b[0m 255.6   \u001b[0m | \u001b[0m 68.42   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1432  \u001b[0m | \u001b[0m 0.7789  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.5176  \u001b[0m | \u001b[0m 0.2534  \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 925.9   \u001b[0m | \u001b[0m 114.4   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1316  \u001b[0m | \u001b[0m 0.5703  \u001b[0m | \u001b[0m 0.1937  \u001b[0m | \u001b[0m 0.677   \u001b[0m | \u001b[0m 0.2474  \u001b[0m | \u001b[0m 2.781   \u001b[0m | \u001b[0m 583.6   \u001b[0m | \u001b[0m 123.5   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1303  \u001b[0m | \u001b[0m 0.5409  \u001b[0m | \u001b[0m 0.5363  \u001b[0m | \u001b[0m 0.4746  \u001b[0m | \u001b[0m 0.1094  \u001b[0m | \u001b[0m 5.482   \u001b[0m | \u001b[0m 820.7   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m-0.1287  \u001b[0m | \u001b[95m 0.5727  \u001b[0m | \u001b[95m 0.5147  \u001b[0m | \u001b[95m 0.3481  \u001b[0m | \u001b[95m 0.01791 \u001b[0m | \u001b[95m 6.203   \u001b[0m | \u001b[95m 946.5   \u001b[0m | \u001b[95m 100.4   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1702  \u001b[0m | \u001b[0m 0.3398  \u001b[0m | \u001b[0m 0.8271  \u001b[0m | \u001b[0m 0.04637 \u001b[0m | \u001b[0m 0.4301  \u001b[0m | \u001b[0m 13.4    \u001b[0m | \u001b[0m 945.7   \u001b[0m | \u001b[0m 100.1   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Call the optimizer defined above\n",
    "bayes_full_model = optimize_lgbm_w_bayes(X_train_full,\n",
    "                                         y_train_full,\n",
    "                                         X_val_full,\n",
    "                                         y_val_full\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "c0c7e8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5726978820897191,\n",
       " 'lambda_l1': 0.514735973118135,\n",
       " 'lambda_l2': 0.34808264544051104,\n",
       " 'learning_rate': 0.017905362936323412,\n",
       " 'max_depth': 6.203116045410376,\n",
       " 'n_estimators': 946.4600324511604,\n",
       " 'num_leaves': 100.383333212035}"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inpsect the params found by the optimizer\n",
    "bayes_full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "307f7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round and cast to int the model params which must be integers\n",
    "bayes_full_model['max_depth'] = int(round(bayes_full_model['max_depth']))\n",
    "bayes_full_model['n_estimators'] = int(round(bayes_full_model['n_estimators']))\n",
    "bayes_full_model['num_leaves'] = int(round(bayes_full_model['num_leaves']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "5b041914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model using the params found by the optimizer\n",
    "lgbm_full_model_bayes = LGBMRegressor(boosting_type=\"goss\", **bayes_full_model, random_state=54321)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "0fb1ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y for the training and validation data together to fit the final model to this full set\n",
    "X_train_val_full = train_val_df_full.iloc[:,0:(lag_n+1)].dropna().iloc[:,1:]\n",
    "y_train_val_full = train_val_df_full.iloc[:,0:(lag_n+1)].dropna().iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "cd85f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.514735973118135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.514735973118135\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34808264544051104, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.34808264544051104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='goss', colsample_bytree=0.5726978820897191,\n",
       "              lambda_l1=0.514735973118135, lambda_l2=0.34808264544051104,\n",
       "              learning_rate=0.017905362936323412, max_depth=6, n_estimators=946,\n",
       "              num_leaves=100, random_state=54321)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "lgbm_full_model_bayes.fit(X_train_val_full, y_train_val_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "6634f1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Results/Global/LightGBM Bayes/Full/model']"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to file to use later\n",
    "filename = 'Results/Global/LightGBM Bayes/Full/model'\n",
    "joblib.dump(lgbm_full_model_bayes, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "ea6c6a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from file using joblib.load\n",
    "lgbm_full_model_bayes = joblib.load(\"Results/Global/LightGBM Bayes/Full/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f230f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute model residuals\n",
    "def compute_lgbm_residuals(mod, X, y):\n",
    "    \"\"\"Function takes in a trained model and X and y on which the model was trained, \n",
    "    and compute residuals. Residuals are returned as a list\"\"\"\n",
    "    \n",
    "    # Compute model predicitons from the provided X\n",
    "    pred = mod.predict(X)\n",
    "    \n",
    "    # Compute residuals as y - predictions, and convert to list\n",
    "    resid = (y - pred).to_list()\n",
    "    \n",
    "    # Return list of residuals\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "53d73252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model residuals using above function\n",
    "lgbm_full_model_bayes_residuals = compute_lgbm_residuals(lgbm_full_model_bayes, \n",
    "                                                         X_train_val_full,\n",
    "                                                         y_train_val_full\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a22107d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute test preds\n",
    "def compute_lgbm_test_preds(mod, data, lag_n):\n",
    "    \"\"\"Function takes in a trained model, test data frame, and lag_n used for lag embedding, and\n",
    "    returns a data frame of predictions for the provided data\"\"\"\n",
    "\n",
    "    # Create an empty data frame to store predictions in\n",
    "    pred_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop through each time series index in the data set\n",
    "    for ts_idx in data.ts_index.unique():\n",
    "        # For each time series index, grab X by eliminating the first column and any columns past (lag_n+1)\n",
    "        X = data.query(\"ts_index==@ts_idx\").iloc[:,1:(lag_n+1)].copy()\n",
    "        # Compute model preds from X\n",
    "        preds = mod.predict(X)\n",
    "        \n",
    "        # Save the preds, along with the time series index, to a temp data frame\n",
    "        pred_df_sub = pd.DataFrame({\"ts_index\": ts_idx, \"test_preds\": preds})\n",
    "        \n",
    "        # Append the temp df to the full df\n",
    "        pred_df = pred_df.append(pred_df_sub)\n",
    "    \n",
    "    # Return the full data frame of test set predictions\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "313b6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test set predictions using the above function\n",
    "lgbm_full_model_bayes_test_preds = compute_lgbm_test_preds(lgbm_full_model_bayes,\n",
    "                                                           test_df_full,\n",
    "                                                           lag_n\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "068869bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute test prediction performance metrics\n",
    "def compute_lgbm_test_perf(preds, data):\n",
    "    \"\"\"Function which takes in a data frame of predictions and a test data frame and computes model performance\"\"\"\n",
    "    \n",
    "    # Create an empty list to store performance data\n",
    "    perf_ls = list()\n",
    "    \n",
    "    # Loop through the time series indexes in our data\n",
    "    for ts_idx in data.ts_index.unique():\n",
    "        # For each time series index\n",
    "        # Extract the true target value (first column of the data frame)\n",
    "        y_sub = data.query(\"ts_index==@ts_idx\").iloc[:,0]\n",
    "        # Extract the preds for that ts_idx\n",
    "        preds_sub = preds.query(\"ts_index==@ts_idx\").test_preds\n",
    "        \n",
    "        # Compute rmse, mae, and the mean of the true target data using numpy and sklearn functions\n",
    "        rmse_sub = mean_squared_error(y_sub, preds_sub, squared=False)\n",
    "        mae_sub = mean_absolute_error(y_sub, preds_sub)\n",
    "        mean_sub = np.mean(y_sub)\n",
    "        \n",
    "        # Create a dictionary to hold these metrics\n",
    "        pred_dict = {\"rmse\": rmse_sub, \"mae\": mae_sub, \"mean\": mean_sub}\n",
    "        \n",
    "        # Append this dictionary to the list\n",
    "        perf_ls.append(pred_dict)\n",
    "        \n",
    "    # Call pd.DataFrame on the list of performance dictionaries to create a df of performance and then return it\n",
    "    return pd.DataFrame(perf_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "0f957c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test set performance\n",
    "lgbm_full_model_bayes_test_perf_df = compute_lgbm_test_perf(lgbm_full_model_bayes_test_preds, test_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "6ceab748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized/scaled performance metrics as well\n",
    "lgbm_full_model_bayes_test_perf_df['nrmse'] = lgbm_full_model_bayes_test_perf_df['rmse']/lgbm_full_model_bayes_test_perf_df['mean']\n",
    "lgbm_full_model_bayes_test_perf_df['smae'] = lgbm_full_model_bayes_test_perf_df['mae']/lgbm_full_model_bayes_test_perf_df['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "bd3cc9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      30.603133\n",
       "mae       20.185643\n",
       "mean     265.435072\n",
       "nrmse      0.138456\n",
       "smae       0.093232\n",
       "dtype: float64"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of the performance metrics\n",
    "lgbm_full_model_bayes_test_perf_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8229455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute bootstrap pred intervals\n",
    "def compute_lgbm_boostrap_int(preds, resid, n_boot):\n",
    "    \"\"\"Function takes in three inputs: a data frame of predictions, a list of residuals, and the number of \n",
    "    bootstrap resamples to use, n_boot. Function returns a modified version of the preds data frame which includes\n",
    "    both 80% and 95% PIs\"\"\"\n",
    "    \n",
    "    # Set seeds\n",
    "    random.seed(54321)\n",
    "    np.random.seed(54321)\n",
    "       \n",
    "    resid = resid\n",
    "    n_boot = n_boot\n",
    "    \n",
    "    # Define sub function to compute samples\n",
    "    def percentile_sample(row):\n",
    "        \"\"\"Function to boostramp sample residuals, add to predicted value, and compute percentiles for PIs.\n",
    "        Function is written to specifically operate on the rows of the preds data frame\"\"\"\n",
    "        \n",
    "        # Bootstrap sample from the residuals\n",
    "        boot_samp = np.random.choice(resid, size=n_boot, replace=True)\n",
    "\n",
    "        # Add the predicted value to the bootstrap samples\n",
    "        new_val = row['test_preds']+boot_samp\n",
    "\n",
    "        # Compute percentiles of the samples for the 95% and then 80% PIs\n",
    "        lo_95 = np.percentile(new_val, 2.5)\n",
    "        hi_95 = np.percentile(new_val, 97.5)\n",
    "        lo_80 = np.percentile(new_val, 10)\n",
    "        hi_80 = np.percentile(new_val, 90)\n",
    "\n",
    "        # Return a tuple of the percentiles which can be assigned to new data frame columns\n",
    "        return lo_95,hi_95,lo_80,hi_80\n",
    "\n",
    "    # Reset the index of the preds df so that swifter apply will work properly\n",
    "    preds = preds.reset_index(drop=True)\n",
    "    \n",
    "    # Compute bootstrap PIs using the above sub function and assign to new df columns\n",
    "    preds['lo_95'], preds['hi_95'], preds['lo_80'], preds['hi_80'] = zip(*preds.swifter.apply(percentile_sample, axis=1))\n",
    "    \n",
    "    # Return the modified preds data frame\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "261aac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set n_boot to 1000 \n",
    "n_boot = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "46bea43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debc6877e88044238c3305ee9d08c85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/102144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the prediction inntervals\n",
    "lgbm_full_model_bayes_test_pred_int = compute_lgbm_boostrap_int(lgbm_full_model_bayes_test_preds,\n",
    "                                                                lgbm_full_model_bayes_residuals,\n",
    "                                                                n_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "30988526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102144, 6)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check shape of output\n",
    "lgbm_full_model_bayes_test_pred_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "9e0758a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the true target values as a column to the PI data frame\n",
    "lgbm_full_model_bayes_test_pred_int['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "036260cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_index</th>\n",
       "      <th>test_preds</th>\n",
       "      <th>lo_95</th>\n",
       "      <th>hi_95</th>\n",
       "      <th>lo_80</th>\n",
       "      <th>hi_80</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>329.603418</td>\n",
       "      <td>276.491873</td>\n",
       "      <td>387.566262</td>\n",
       "      <td>301.935275</td>\n",
       "      <td>358.900685</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>327.388077</td>\n",
       "      <td>266.698468</td>\n",
       "      <td>396.614923</td>\n",
       "      <td>296.641381</td>\n",
       "      <td>357.606190</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>341.182653</td>\n",
       "      <td>280.886330</td>\n",
       "      <td>397.902035</td>\n",
       "      <td>312.706347</td>\n",
       "      <td>367.273697</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>351.206502</td>\n",
       "      <td>285.292677</td>\n",
       "      <td>416.952564</td>\n",
       "      <td>322.111895</td>\n",
       "      <td>381.659577</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>342.699460</td>\n",
       "      <td>282.471138</td>\n",
       "      <td>400.051979</td>\n",
       "      <td>314.355361</td>\n",
       "      <td>372.743081</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_index  test_preds       lo_95       hi_95       lo_80       hi_80  \\\n",
       "0         1  329.603418  276.491873  387.566262  301.935275  358.900685   \n",
       "1         1  327.388077  266.698468  396.614923  296.641381  357.606190   \n",
       "2         1  341.182653  280.886330  397.902035  312.706347  367.273697   \n",
       "3         1  351.206502  285.292677  416.952564  322.111895  381.659577   \n",
       "4         1  342.699460  282.471138  400.051979  314.355361  372.743081   \n",
       "\n",
       "   actual  \n",
       "0   320.0  \n",
       "1   339.0  \n",
       "2   349.0  \n",
       "3   343.0  \n",
       "4   343.0  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print head to sanity check\n",
    "lgbm_full_model_bayes_test_pred_int.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64f5a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to compute the interval score\n",
    "def interval_score(true_values, lower, upper, interval_range):\n",
    "    \"\"\" Function which takes in the true values, the upper and lower bounds of PIs, and the PI level (e.g., 90%)\n",
    "        and from these inputs, computes the interval score for each prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute alpha from the interval range\n",
    "    alpha = 1-interval_range\n",
    "    \n",
    "    # Save the upper, lower, and true_values as numpy arrays for computation purposes\n",
    "    upper = np.array(upper)\n",
    "    lower = np.array(lower)\n",
    "    true_values = np.array(true_values)\n",
    "    \n",
    "    # Compute the lower component of the interval score - just a boolean for true below interval\n",
    "    def lower_ind(true,low):\n",
    "        if true<low:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the upper component of the interval score - similar boolean for true above interval\n",
    "    def upper_ind(true,up):\n",
    "        if true>up:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the actual score for each obsveration - formula here: https://epiforecasts.io/scoringutils/reference/interval_score.html\n",
    "    scores = (upper-lower) + (2/alpha)*(lower-true_values)*(lower > true_values) + (2/alpha)*(true_values-upper)*(true_values > upper)\n",
    "    \n",
    "    # Return the scores array\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "336fdb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 80% and 95% PI scores for each prediction\n",
    "lgbm_full_model_bayes_test_pred_int['int_95_score'] = interval_score(lgbm_full_model_bayes_test_pred_int.actual, \n",
    "                                                                     lgbm_full_model_bayes_test_pred_int.lo_95,\n",
    "                                                                     lgbm_full_model_bayes_test_pred_int.hi_95,\n",
    "                                                                     0.95)\n",
    "                                                    \n",
    "lgbm_full_model_bayes_test_pred_int['int_80_score'] = interval_score(lgbm_full_model_bayes_test_pred_int.actual, \n",
    "                                                                     lgbm_full_model_bayes_test_pred_int.lo_80,\n",
    "                                                                     lgbm_full_model_bayes_test_pred_int.hi_80,\n",
    "                                                                     0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "12515fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.750378\n",
       "lo_95           205.259919\n",
       "hi_95           328.566850\n",
       "lo_80           237.130444\n",
       "hi_80           295.344232\n",
       "actual          265.435072\n",
       "int_95_score    225.436875\n",
       "int_80_score    121.707257\n",
       "dtype: float64"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean PI scores\n",
    "lgbm_full_model_bayes_test_pred_int.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "f1977ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI data frame to a csv file\n",
    "lgbm_full_model_bayes_test_pred_int.to_csv(\"Results/Global/LightGBM Bayes/Full/test_pred_intervals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc047e",
   "metadata": {},
   "source": [
    "# Train and Test - Random Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "a90ca6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete variables no longer in use\n",
    "del lgbm_full_model_bayes_test_pred_int\n",
    "del lgbm_full_model_bayes_test_perf_df\n",
    "del lgbm_full_model_bayes_test_perf\n",
    "del lgbm_full_model_bayes_test_preds\n",
    "del lgbm_full_model_bayes_residuals\n",
    "del lgbm_full_model_bayes\n",
    "del X_train_val_full\n",
    "del y_train_val_full\n",
    "del X_val_full\n",
    "del y_val_full\n",
    "del X_train_full\n",
    "del y_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "1c78df68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67f12193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cluster data for random clusters, and rename assignments to 'cluster'\n",
    "rand_clust = pd.read_csv(\"Results/Clustering/Random/random_clustering_assign.csv\")\n",
    "rand_clust['cluster'] = rand_clust['random_clust_assign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "937965e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and val data frames with cluster assignments\n",
    "train_df_rand_clust = train_df_full.merge(rand_clust, on=\"ts_index\")\n",
    "val_df_rand_clust = val_df_full.merge(rand_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a9eed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of data frames which only contain data for each cluster. Do this for both\n",
    "# training and validation data\n",
    "train_df_rand_clust_ls = [df.reset_index(drop=True) for _,df in train_df_rand_clust.groupby(\"cluster\")]\n",
    "val_df_rand_clust_ls = [df.reset_index(drop=True) for _,df in val_df_rand_clust.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67dae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Random Cluster LGBM Models Bayes:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Loop through the list of training and validation data frames in a parallel fashion and run the Bayesian\n",
    "# optimization function for each cluster's data in parallel\n",
    "# Save the best params for each cluster to a list\n",
    "# Note that in the function call, we are subsetting the data frames to X and y data frames instead of doing\n",
    "# this beforehand like was done with the full model above\n",
    "with tqdm_joblib(tqdm(desc=\"Random Cluster LGBM Models Bayes\", \n",
    "                      total=len(train_df_rand_clust_ls))) as progress_bar:\n",
    "    rand_clust_mods_bayes = Parallel(n_jobs=4)(delayed(optimize_lgbm_w_bayes)(train_df_rand_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:], \n",
    "                                                                              train_df_rand_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                              val_df_rand_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                              val_df_rand_clust_ls[i].iloc[:,0]) for i in range(len(train_df_rand_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "55056a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each entry in the list of params returned above, round and cast the params which \n",
    "# LGBM models require to be integers\n",
    "for n in range(len(rand_clust_mods_bayes)):\n",
    "    rand_clust_mods_bayes[n][\"max_depth\"] = int(round(rand_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    rand_clust_mods_bayes[n][\"n_estimators\"] = int(round(rand_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    rand_clust_mods_bayes[n][\"num_leaves\"] = int(round(rand_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "228ff5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the train_val data frame with cluster assignments\n",
    "train_val_df_rand = train_val_df_full.merge(rand_clust, on=\"ts_index\")\n",
    "# Create a list of smaller data frames which contain data each from one cluster\n",
    "train_val_df_rand_ls = [df.reset_index(drop=True) for _,df in train_val_df_rand.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d152c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a light gbm model\n",
    "def train_lgbm(params, X, y):\n",
    "    \"\"\"Function takes in a set of params, X, and y data frames for training and returns a trained model\"\"\"\n",
    "    \n",
    "    # Create the model, using the passed params, a fixed random state, and a 'goss' boosting type\n",
    "    mod = LGBMRegressor(boosting_type='goss', **params, random_state=54321)  \n",
    "    # Fir the model to the provided data\n",
    "    mod.fit(X, y)\n",
    "    \n",
    "    # Return the fitted model\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "219936bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Cluster LGBM Models Bayes Final: 100%|██████████| 4/4 [01:23<00:00, 20.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each set of model params found above, loop through the list of full train_val data and train a model\n",
    "# Again, this is done in parallel with the models saved to a list, and again the X and y data frames are created\n",
    "# in the function call as opposed to before\n",
    "with tqdm_joblib(tqdm(desc=\"Random Cluster LGBM Models Bayes Final\", \n",
    "                      total=len(train_val_df_rand_ls))) as progress_bar:\n",
    "    rand_clust_mods_bayes_final = Parallel(n_jobs=4)(delayed(train_lgbm)(rand_clust_mods_bayes[i], \n",
    "                                                                         train_val_df_rand_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:], \n",
    "                                                                         train_val_df_rand_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(train_val_df_rand_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8719cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the models trained above, save them to a file\n",
    "for model_no in range(len(rand_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/Random Cluster/model_{model_no}\"\n",
    "    joblib.dump(rand_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67533e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Cluster LGBM Models Bayes Residuals: 100%|██████████| 4/4 [00:12<00:00,  3.22s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each of the above models, compute the residuals. Loop, in parallel, through the list of models,\n",
    "# create the X and y data frames the model was trained on, and return a list of residuals. These lists of \n",
    "# residuals are saved in a list\n",
    "with tqdm_joblib(tqdm(desc=\"Random Cluster LGBM Models Bayes Residuals\", \n",
    "                      total=len(rand_clust_mods_bayes_final))) as progress_bar:\n",
    "    rand_clust_mods_bayes_resid = Parallel(n_jobs=4)(delayed(compute_lgbm_residuals)(rand_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_rand_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_rand_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(rand_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44f1985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the test data with the cluster assignments\n",
    "test_df_full_rand = test_df_full.merge(rand_clust, on=\"ts_index\")\n",
    "# Split the test data frame into a list of data frames, each with data from one cluster\n",
    "test_df_full_rand_ls = [df.reset_index(drop=True) for _,df in test_df_full_rand.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cef82899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Cluster LGBM Models Bayes Test Preds: 100%|██████████| 4/4 [00:02<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# For each model, loop in parallel, compute the test preds as a data frame and save those data frames to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Random Cluster LGBM Models Bayes Test Preds\", \n",
    "                      total=len(rand_clust_mods_bayes_final))) as progress_bar:\n",
    "    rand_clust_mods_bayes_test_preds = Parallel(n_jobs=4)(delayed(compute_lgbm_test_preds)(rand_clust_mods_bayes_final[i],\n",
    "                                                                                           test_df_full_rand_ls[i],\n",
    "                                                                                           lag_n\n",
    "                                                                                          ) for i in range(len(rand_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d556e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the above created data frames of test preds into one data frame\n",
    "rand_clust_bayes_test_preds_df = pd.DataFrame()\n",
    "for clust_test_pred_df in rand_clust_mods_bayes_test_preds:\n",
    "    rand_clust_bayes_test_preds_df = rand_clust_bayes_test_preds_df.append(clust_test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37daaa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this one data frame of test preds, compute prediction performance\n",
    "rand_clust_bayes_test_perf = compute_lgbm_test_perf(rand_clust_bayes_test_preds_df,\n",
    "                                                    test_df_full_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85872636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled performance metrics to the data frame\n",
    "rand_clust_bayes_test_perf['nrmse'] = rand_clust_bayes_test_perf['rmse']/rand_clust_bayes_test_perf['mean']\n",
    "rand_clust_bayes_test_perf['smae'] = rand_clust_bayes_test_perf['mae']/rand_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9eef530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      31.394934\n",
       "mae       20.807758\n",
       "mean     265.435072\n",
       "nrmse      0.141546\n",
       "smae       0.095680\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of prediction performance metrics\n",
    "rand_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d1c081c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105ee982811140ac8a476987d8fe22d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec8f384c929458692cab0dc3df5725d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0502eb610fa4fb791c5b2a3d127ddce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bbf13071774ca98e6aea9236d3e65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty list to save PI data frames\n",
    "rand_clust_test_pred_int = list()\n",
    "# Loop through the list of prediction data frames\n",
    "for i in range(len(rand_clust_mods_bayes_test_preds)):\n",
    "    # For each one, compute bootstrap PIs and save that data frame to the above list\n",
    "    rand_clust_test_pred_int.append(compute_lgbm_boostrap_int(rand_clust_mods_bayes_test_preds[i], \n",
    "                                                              rand_clust_mods_bayes_resid[i], \n",
    "                                                              n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7dd5d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster\n",
    "for n in range(1, len(rand_clust_test_pred_int)+1):\n",
    "    # Get the true values for the target for that cluster\n",
    "    y_actual_sub = test_df_full_rand.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    # Add those true values as a column to that cluster's PI data frame\n",
    "    rand_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "06721338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all prediction interval data frames from each cluster into one data frame\n",
    "rand_clust_test_pred_int_df = pd.DataFrame()\n",
    "for clust_test_pred_int_df in rand_clust_test_pred_int:\n",
    "    rand_clust_test_pred_int_df = rand_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "6dd16841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For that one data frame, add columns which compute the 95% and 80% PI scores for each prediction\n",
    "rand_clust_test_pred_int_df['int_95_score'] = interval_score(rand_clust_test_pred_int_df['actual'],\n",
    "                                                             rand_clust_test_pred_int_df['lo_95'],\n",
    "                                                             rand_clust_test_pred_int_df['hi_95'],\n",
    "                                                             0.95\n",
    "                                                            )\n",
    "\n",
    "rand_clust_test_pred_int_df['int_80_score'] = interval_score(rand_clust_test_pred_int_df['actual'],\n",
    "                                                             rand_clust_test_pred_int_df['lo_80'],\n",
    "                                                             rand_clust_test_pred_int_df['hi_80'],\n",
    "                                                             0.80\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c09abdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.710682\n",
       "hi_95           313.366667\n",
       "lo_95           219.607463\n",
       "hi_80           290.765072\n",
       "lo_80           241.362420\n",
       "actual          265.435072\n",
       "int_95_score    263.662104\n",
       "int_80_score    127.577844\n",
       "dtype: float64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of those PI scores\n",
    "rand_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ac6971eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI data frame to a csv file\n",
    "rand_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/Random Cluster/test_pred_intervals.csv\", \n",
    "                                   index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3473fd9f",
   "metadata": {},
   "source": [
    "# Train and Test - Highway System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "1d1888b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused variables\n",
    "del train_df_rand_clust_ls\n",
    "del train_df_rand_clust\n",
    "del val_df_rand_clust_ls\n",
    "del val_df_rand_clust\n",
    "del rand_clust_mods_bayes\n",
    "del rand_clust\n",
    "del train_val_df_rand\n",
    "del train_val_df_rand_ls\n",
    "del rand_clust_mods_bayes_final\n",
    "del rand_clust_mods_bayes_resid\n",
    "del test_df_full_rand\n",
    "del test_df_full_rand_ls\n",
    "del rand_clust_mods_bayes_test_preds\n",
    "del rand_clust_bayes_test_preds_df\n",
    "del rand_clust_bayes_test_perf\n",
    "del rand_clust_test_pred_int\n",
    "del rand_clust_test_pred_int_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "27a612e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "cfce412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster assignments for the highway systems based on the no of sensors for each system\n",
    "highway_clust = pd.DataFrame({\"ts_index\": np.arange(1, 77),\n",
    "                                    \"cluster\": [1]*38 + [2]*19 + [3]*19}\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "88f18606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge training, validation, train_val, and test data with cluster assignments\n",
    "train_df_full_highway = train_df_full.merge(highway_clust, on=\"ts_index\")\n",
    "val_df_full_highway = val_df_full.merge(highway_clust, on=\"ts_index\")\n",
    "train_val_df_full_highway = train_val_df_full.merge(highway_clust, on=\"ts_index\")\n",
    "test_df_full_highway = test_df_full.merge(highway_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "11aaa9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and validation data frames into a list of data frames which each contain data for 1 cluster\n",
    "train_df_highway_clust_ls = [df.reset_index(drop=True) for _,df in train_df_full_highway.groupby(\"cluster\")]\n",
    "val_df_highway_clust_ls = [df.reset_index(drop=True) for _,df in val_df_full_highway.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a17c716a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway System LGBM Models Bayes:  67%|██████▋   | 2/3 [18:11<08:09, 489.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1667  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1687  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1949  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2138  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.186   \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.163   \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.8959  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5833  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 8.072   \u001b[0m | \u001b[0m 842.2   \u001b[0m | \u001b[0m 145.5   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1727  \u001b[0m | \u001b[0m 0.7325  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.9323  \u001b[0m | \u001b[0m 0.2438  \u001b[0m | \u001b[0m 11.23   \u001b[0m | \u001b[0m 464.7   \u001b[0m | \u001b[0m 31.1    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1961  \u001b[0m | \u001b[0m 0.5005  \u001b[0m | \u001b[0m 0.01999 \u001b[0m | \u001b[0m 0.6197  \u001b[0m | \u001b[0m 0.4357  \u001b[0m | \u001b[0m 14.53   \u001b[0m | \u001b[0m 458.2   \u001b[0m | \u001b[0m 21.54   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.1592  \u001b[0m | \u001b[95m 0.6376  \u001b[0m | \u001b[95m 0.4625  \u001b[0m | \u001b[95m 0.1236  \u001b[0m | \u001b[95m 0.1021  \u001b[0m | \u001b[95m 23.37   \u001b[0m | \u001b[95m 468.1   \u001b[0m | \u001b[95m 32.42   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1807  \u001b[0m | \u001b[0m 0.6461  \u001b[0m | \u001b[0m 0.5019  \u001b[0m | \u001b[0m 0.3834  \u001b[0m | \u001b[0m 0.2998  \u001b[0m | \u001b[0m 14.91   \u001b[0m | \u001b[0m 478.1   \u001b[0m | \u001b[0m 34.38   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1735  \u001b[0m | \u001b[0m 0.4375  \u001b[0m | \u001b[0m 0.04202 \u001b[0m | \u001b[0m 0.7955  \u001b[0m | \u001b[0m 0.237   \u001b[0m | \u001b[0m 20.64   \u001b[0m | \u001b[0m 455.9   \u001b[0m | \u001b[0m 39.71   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1733  \u001b[0m | \u001b[0m 0.1885  \u001b[0m | \u001b[0m 0.8531  \u001b[0m | \u001b[0m 0.4953  \u001b[0m | \u001b[0m 0.1927  \u001b[0m | \u001b[0m 16.33   \u001b[0m | \u001b[0m 466.8   \u001b[0m | \u001b[0m 46.48   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1706  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2716  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.01619 \u001b[0m | \u001b[0m 6.059   \u001b[0m | \u001b[0m 456.2   \u001b[0m | \u001b[0m 43.52   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1853  \u001b[0m | \u001b[0m 0.9405  \u001b[0m | \u001b[0m 0.3476  \u001b[0m | \u001b[0m 0.7516  \u001b[0m | \u001b[0m 0.34    \u001b[0m | \u001b[0m 9.398   \u001b[0m | \u001b[0m 446.6   \u001b[0m | \u001b[0m 32.54   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.8989  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 481.0   \u001b[0m | \u001b[0m 23.8    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1625  \u001b[0m | \u001b[0m 0.5156  \u001b[0m | \u001b[0m 0.2086  \u001b[0m | \u001b[0m 0.4619  \u001b[0m | \u001b[0m 0.1782  \u001b[0m | \u001b[0m 2.521   \u001b[0m | \u001b[0m 468.7   \u001b[0m | \u001b[0m 21.06   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1984  \u001b[0m | \u001b[0m 0.7816  \u001b[0m | \u001b[0m 0.1522  \u001b[0m | \u001b[0m 0.982   \u001b[0m | \u001b[0m 0.3994  \u001b[0m | \u001b[0m 9.231   \u001b[0m | \u001b[0m 472.4   \u001b[0m | \u001b[0m 41.35   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.5475  \u001b[0m | \u001b[0m 0.2275  \u001b[0m | \u001b[0m 0.9399  \u001b[0m | \u001b[0m 0.405   \u001b[0m | \u001b[0m 0.001274\u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 465.2   \u001b[0m | \u001b[0m 11.23   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1602  \u001b[0m | \u001b[0m 0.5187  \u001b[0m | \u001b[0m 0.5239  \u001b[0m | \u001b[0m 0.1644  \u001b[0m | \u001b[0m 0.04828 \u001b[0m | \u001b[0m 2.604   \u001b[0m | \u001b[0m 475.9   \u001b[0m | \u001b[0m 29.72   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.2175  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 24.12   \u001b[0m | \u001b[0m 457.0   \u001b[0m | \u001b[0m 28.55   \u001b[0m |\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m-0.1565  \u001b[0m | \u001b[95m 0.6297  \u001b[0m | \u001b[95m 0.02407 \u001b[0m | \u001b[95m 0.4819  \u001b[0m | \u001b[95m 0.01635 \u001b[0m | \u001b[95m 16.62   \u001b[0m | \u001b[95m 455.7   \u001b[0m | \u001b[95m 50.8    \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.2065  \u001b[0m | \u001b[0m 0.3686  \u001b[0m | \u001b[0m 0.4975  \u001b[0m | \u001b[0m 0.5434  \u001b[0m | \u001b[0m 0.4147  \u001b[0m | \u001b[0m 9.087   \u001b[0m | \u001b[0m 445.7   \u001b[0m | \u001b[0m 50.53   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1678  \u001b[0m | \u001b[0m 0.8475  \u001b[0m | \u001b[0m 0.9306  \u001b[0m | \u001b[0m 0.9275  \u001b[0m | \u001b[0m 0.4347  \u001b[0m | \u001b[0m 2.022   \u001b[0m | \u001b[0m 455.1   \u001b[0m | \u001b[0m 26.96   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1755  \u001b[0m | \u001b[0m 0.1904  \u001b[0m | \u001b[0m 0.1852  \u001b[0m | \u001b[0m 0.6725  \u001b[0m | \u001b[0m 0.2884  \u001b[0m | \u001b[0m 5.12    \u001b[0m | \u001b[0m 461.7   \u001b[0m | \u001b[0m 54.58   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1662  \u001b[0m | \u001b[0m 0.3977  \u001b[0m | \u001b[0m 0.7977  \u001b[0m | \u001b[0m 0.2085  \u001b[0m | \u001b[0m 0.1599  \u001b[0m | \u001b[0m 22.85   \u001b[0m | \u001b[0m 461.6   \u001b[0m | \u001b[0m 61.12   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.2038  \u001b[0m | \u001b[0m 0.7417  \u001b[0m | \u001b[0m 0.2617  \u001b[0m | \u001b[0m 0.4858  \u001b[0m | \u001b[0m 0.3844  \u001b[0m | \u001b[0m 17.02   \u001b[0m | \u001b[0m 449.8   \u001b[0m | \u001b[0m 66.1    \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1866  \u001b[0m | \u001b[0m 0.8171  \u001b[0m | \u001b[0m 0.5107  \u001b[0m | \u001b[0m 0.3071  \u001b[0m | \u001b[0m 0.2998  \u001b[0m | \u001b[0m 12.76   \u001b[0m | \u001b[0m 466.3   \u001b[0m | \u001b[0m 66.9    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.233   \u001b[0m | \u001b[0m 0.1806  \u001b[0m | \u001b[0m 0.4646  \u001b[0m | \u001b[0m 0.4705  \u001b[0m | \u001b[0m 0.4741  \u001b[0m | \u001b[0m 22.89   \u001b[0m | \u001b[0m 476.8   \u001b[0m | \u001b[0m 53.94   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.8991  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 446.1   \u001b[0m | \u001b[0m 52.36   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway System LGBM Models Bayes: 100%|██████████| 3/3 [20:38<00:00, 412.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# In parallel, loop through the lists of training and validation data, subset theminto X and y, and run the \n",
    "# Bayesian optimizer. Save the best model params for each cluster to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Highway System LGBM Models Bayes\", \n",
    "                      total=len(train_df_highway_clust_ls))) as progress_bar:\n",
    "    highway_clust_mods_bayes = Parallel(n_jobs=3)(delayed(optimize_lgbm_w_bayes)(train_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                 train_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                                 val_df_highway_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                                 val_df_highway_clust_ls[i].iloc[:,0]) for i in range(len(train_df_highway_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e46e90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each set of params in the list\n",
    "for n in range(len(highway_clust_mods_bayes)):\n",
    "    # Round and cast to int the LGBM model params which must be integers\n",
    "    highway_clust_mods_bayes[n][\"max_depth\"] = int(round(highway_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    highway_clust_mods_bayes[n][\"n_estimators\"] = int(round(highway_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    highway_clust_mods_bayes[n][\"num_leaves\"] = int(round(highway_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "32abbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of train_val data frames which only contain data for each cluster\n",
    "train_val_df_highway_clust_ls = [df.reset_index(drop=True) for _,df in train_val_df_full_highway.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d920312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Highway System LGBM Models Bayes Final:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1522  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1536  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1688  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2121  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1614  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1953  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1923  \u001b[0m | \u001b[0m 0.1823  \u001b[0m | \u001b[0m 0.2334  \u001b[0m | \u001b[0m 0.3629  \u001b[0m | \u001b[0m 0.06587 \u001b[0m | \u001b[0m 17.26   \u001b[0m | \u001b[0m 859.2   \u001b[0m | \u001b[0m 141.3   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1567  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.2829  \u001b[0m | \u001b[0m 0.9203  \u001b[0m | \u001b[0m 0.08668 \u001b[0m | \u001b[0m 8.428   \u001b[0m | \u001b[0m 942.3   \u001b[0m | \u001b[0m 106.7   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1769  \u001b[0m | \u001b[0m 0.6154  \u001b[0m | \u001b[0m 0.5809  \u001b[0m | \u001b[0m 0.5974  \u001b[0m | \u001b[0m 0.3896  \u001b[0m | \u001b[0m 23.0    \u001b[0m | \u001b[0m 433.1   \u001b[0m | \u001b[0m 83.41   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1927  \u001b[0m | \u001b[0m 0.2707  \u001b[0m | \u001b[0m 0.3919  \u001b[0m | \u001b[0m 0.8713  \u001b[0m | \u001b[0m 0.2398  \u001b[0m | \u001b[0m 21.29   \u001b[0m | \u001b[0m 182.6   \u001b[0m | \u001b[0m 128.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1541  \u001b[0m | \u001b[0m 0.5174  \u001b[0m | \u001b[0m 0.2394  \u001b[0m | \u001b[0m 0.01523 \u001b[0m | \u001b[0m 0.3594  \u001b[0m | \u001b[0m 2.433   \u001b[0m | \u001b[0m 593.3   \u001b[0m | \u001b[0m 126.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1545  \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 0.517   \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 0.09298 \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 583.4   \u001b[0m | \u001b[0m 123.1   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1641  \u001b[0m | \u001b[0m 0.957   \u001b[0m | \u001b[0m 0.5047  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.2706  \u001b[0m | \u001b[0m 8.573   \u001b[0m | \u001b[0m 757.1   \u001b[0m | \u001b[0m 17.0    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1788  \u001b[0m | \u001b[0m 0.2656  \u001b[0m | \u001b[0m 0.04668 \u001b[0m | \u001b[0m 0.03001 \u001b[0m | \u001b[0m 0.1727  \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 861.6   \u001b[0m | \u001b[0m 139.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1583  \u001b[0m | \u001b[0m 0.8199  \u001b[0m | \u001b[0m 0.4933  \u001b[0m | \u001b[0m 0.7328  \u001b[0m | \u001b[0m 0.2643  \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 398.9   \u001b[0m | \u001b[0m 92.87   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2312  \u001b[0m | \u001b[0m 0.5136  \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 0.06973 \u001b[0m | \u001b[0m 0.4773  \u001b[0m | \u001b[0m 10.62   \u001b[0m | \u001b[0m 642.0   \u001b[0m | \u001b[0m 97.73   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1712  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.371   \u001b[0m | \u001b[0m 9.194   \u001b[0m | \u001b[0m 969.5   \u001b[0m | \u001b[0m 23.1    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1772  \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.0695  \u001b[0m | \u001b[0m 0.3948  \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 27.02   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1556  \u001b[0m | \u001b[0m 0.9134  \u001b[0m | \u001b[0m 0.3416  \u001b[0m | \u001b[0m 0.2057  \u001b[0m | \u001b[0m 0.2121  \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 418.8   \u001b[0m | \u001b[0m 120.2   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1632  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.5603  \u001b[0m | \u001b[0m 0.4809  \u001b[0m | \u001b[0m 0.09778 \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 351.6   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1587  \u001b[0m | \u001b[0m 0.5316  \u001b[0m | \u001b[0m 0.3662  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.377   \u001b[0m | \u001b[0m 2.832   \u001b[0m | \u001b[0m 855.2   \u001b[0m | \u001b[0m 24.01   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1891  \u001b[0m | \u001b[0m 0.3696  \u001b[0m | \u001b[0m 0.9666  \u001b[0m | \u001b[0m 0.0882  \u001b[0m | \u001b[0m 0.3123  \u001b[0m | \u001b[0m 22.58   \u001b[0m | \u001b[0m 694.0   \u001b[0m | \u001b[0m 115.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1856  \u001b[0m | \u001b[0m 0.2374  \u001b[0m | \u001b[0m 0.5845  \u001b[0m | \u001b[0m 0.6013  \u001b[0m | \u001b[0m 0.06929 \u001b[0m | \u001b[0m 24.59   \u001b[0m | \u001b[0m 646.7   \u001b[0m | \u001b[0m 126.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1533  \u001b[0m | \u001b[0m 0.6942  \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.7711  \u001b[0m | \u001b[0m 0.1554  \u001b[0m | \u001b[0m 16.79   \u001b[0m | \u001b[0m 331.1   \u001b[0m | \u001b[0m 40.78   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2014  \u001b[0m | \u001b[0m 0.1268  \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 0.7912  \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 18.31   \u001b[0m | \u001b[0m 255.6   \u001b[0m | \u001b[0m 68.42   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1615  \u001b[0m | \u001b[0m 0.7789  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.5176  \u001b[0m | \u001b[0m 0.2534  \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 925.9   \u001b[0m | \u001b[0m 114.4   \u001b[0m |\n",
      "| \u001b[95m 27      \u001b[0m | \u001b[95m-0.1512  \u001b[0m | \u001b[95m 0.5703  \u001b[0m | \u001b[95m 0.1937  \u001b[0m | \u001b[95m 0.677   \u001b[0m | \u001b[95m 0.2474  \u001b[0m | \u001b[95m 2.781   \u001b[0m | \u001b[95m 583.6   \u001b[0m | \u001b[95m 123.5   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1878  \u001b[0m | \u001b[0m 0.4295  \u001b[0m | \u001b[0m 0.5138  \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 0.3808  \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 471.2   \u001b[0m | \u001b[0m 24.53   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1556  \u001b[0m | \u001b[0m 0.9737  \u001b[0m | \u001b[0m 0.6132  \u001b[0m | \u001b[0m 0.2585  \u001b[0m | \u001b[0m 0.3116  \u001b[0m | \u001b[0m 16.09   \u001b[0m | \u001b[0m 332.1   \u001b[0m | \u001b[0m 43.31   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1972  \u001b[0m | \u001b[0m 0.9304  \u001b[0m | \u001b[0m 0.5238  \u001b[0m | \u001b[0m 0.3005  \u001b[0m | \u001b[0m 0.4599  \u001b[0m | \u001b[0m 12.76   \u001b[0m | \u001b[0m 418.5   \u001b[0m | \u001b[0m 119.4   \u001b[0m |\n",
      "=============================================================================================================\n",
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.12    \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1194  \u001b[0m | \u001b[95m 0.7999  \u001b[0m | \u001b[95m 0.4889  \u001b[0m | \u001b[95m 0.05053 \u001b[0m | \u001b[95m 0.2692  \u001b[0m | \u001b[95m 2.954   \u001b[0m | \u001b[95m 827.3   \u001b[0m | \u001b[95m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1317  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1451  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.128   \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1239  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1635  \u001b[0m | \u001b[0m 0.9697  \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.4162  \u001b[0m | \u001b[0m 0.4815  \u001b[0m | \u001b[0m 10.06   \u001b[0m | \u001b[0m 820.2   \u001b[0m | \u001b[0m 147.2   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1157  \u001b[0m | \u001b[95m 0.5048  \u001b[0m | \u001b[95m 0.1897  \u001b[0m | \u001b[95m 0.9395  \u001b[0m | \u001b[95m 0.06436 \u001b[0m | \u001b[95m 10.9    \u001b[0m | \u001b[95m 474.2   \u001b[0m | \u001b[95m 25.27   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1182  \u001b[0m | \u001b[0m 0.4901  \u001b[0m | \u001b[0m 0.8833  \u001b[0m | \u001b[0m 0.8702  \u001b[0m | \u001b[0m 0.1799  \u001b[0m | \u001b[0m 7.472   \u001b[0m | \u001b[0m 468.2   \u001b[0m | \u001b[0m 22.02   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1182  \u001b[0m | \u001b[0m 0.6715  \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 0.7347  \u001b[0m | \u001b[0m 0.1921  \u001b[0m | \u001b[0m 7.175   \u001b[0m | \u001b[0m 477.5   \u001b[0m | \u001b[0m 18.71   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.117   \u001b[0m | \u001b[0m 0.564   \u001b[0m | \u001b[0m 0.2216  \u001b[0m | \u001b[0m 0.9552  \u001b[0m | \u001b[0m 0.1315  \u001b[0m | \u001b[0m 3.257   \u001b[0m | \u001b[0m 476.8   \u001b[0m | \u001b[0m 29.66   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1163  \u001b[0m | \u001b[0m 0.3634  \u001b[0m | \u001b[0m 0.7308  \u001b[0m | \u001b[0m 0.9633  \u001b[0m | \u001b[0m 0.08772 \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 483.7   \u001b[0m | \u001b[0m 25.75   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1575  \u001b[0m | \u001b[0m 0.1464  \u001b[0m | \u001b[0m 0.7348  \u001b[0m | \u001b[0m 0.007833\u001b[0m | \u001b[0m 0.4735  \u001b[0m | \u001b[0m 9.63    \u001b[0m | \u001b[0m 483.4   \u001b[0m | \u001b[0m 35.53   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1259  \u001b[0m | \u001b[0m 0.1344  \u001b[0m | \u001b[0m 0.5043  \u001b[0m | \u001b[0m 0.4524  \u001b[0m | \u001b[0m 0.3762  \u001b[0m | \u001b[0m 2.052   \u001b[0m | \u001b[0m 481.9   \u001b[0m | \u001b[0m 22.56   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1204  \u001b[0m | \u001b[0m 0.1712  \u001b[0m | \u001b[0m 0.9336  \u001b[0m | \u001b[0m 0.1298  \u001b[0m | \u001b[0m 0.1405  \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 485.2   \u001b[0m | \u001b[0m 20.86   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.9486  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 469.7   \u001b[0m | \u001b[0m 28.06   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1176  \u001b[0m | \u001b[0m 0.206   \u001b[0m | \u001b[0m 0.9642  \u001b[0m | \u001b[0m 0.5305  \u001b[0m | \u001b[0m 0.07462 \u001b[0m | \u001b[0m 15.8    \u001b[0m | \u001b[0m 480.6   \u001b[0m | \u001b[0m 23.64   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1249  \u001b[0m | \u001b[0m 0.3524  \u001b[0m | \u001b[0m 0.7884  \u001b[0m | \u001b[0m 0.09994 \u001b[0m | \u001b[0m 0.4937  \u001b[0m | \u001b[0m 3.381   \u001b[0m | \u001b[0m 482.6   \u001b[0m | \u001b[0m 29.38   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1314  \u001b[0m | \u001b[0m 0.1133  \u001b[0m | \u001b[0m 0.7165  \u001b[0m | \u001b[0m 0.5914  \u001b[0m | \u001b[0m 0.01684 \u001b[0m | \u001b[0m 7.683   \u001b[0m | \u001b[0m 485.5   \u001b[0m | \u001b[0m 17.54   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1386  \u001b[0m | \u001b[0m 0.695   \u001b[0m | \u001b[0m 0.6792  \u001b[0m | \u001b[0m 0.7813  \u001b[0m | \u001b[0m 0.4987  \u001b[0m | \u001b[0m 8.472   \u001b[0m | \u001b[0m 478.7   \u001b[0m | \u001b[0m 30.99   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1227  \u001b[0m | \u001b[0m 0.3129  \u001b[0m | \u001b[0m 0.42    \u001b[0m | \u001b[0m 0.8768  \u001b[0m | \u001b[0m 0.2503  \u001b[0m | \u001b[0m 14.07   \u001b[0m | \u001b[0m 464.4   \u001b[0m | \u001b[0m 18.34   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1192  \u001b[0m | \u001b[0m 0.4327  \u001b[0m | \u001b[0m 0.05727 \u001b[0m | \u001b[0m 0.342   \u001b[0m | \u001b[0m 0.2066  \u001b[0m | \u001b[0m 7.131   \u001b[0m | \u001b[0m 470.0   \u001b[0m | \u001b[0m 15.73   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1208  \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.6139  \u001b[0m | \u001b[0m 0.2184  \u001b[0m | \u001b[0m 0.2842  \u001b[0m | \u001b[0m 5.978   \u001b[0m | \u001b[0m 462.5   \u001b[0m | \u001b[0m 12.4    \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1173  \u001b[0m | \u001b[0m 0.4148  \u001b[0m | \u001b[0m 0.4723  \u001b[0m | \u001b[0m 0.4455  \u001b[0m | \u001b[0m 0.1467  \u001b[0m | \u001b[0m 16.54   \u001b[0m | \u001b[0m 473.6   \u001b[0m | \u001b[0m 14.13   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1273  \u001b[0m | \u001b[0m 0.4118  \u001b[0m | \u001b[0m 0.5937  \u001b[0m | \u001b[0m 0.6171  \u001b[0m | \u001b[0m 0.3045  \u001b[0m | \u001b[0m 16.94   \u001b[0m | \u001b[0m 489.3   \u001b[0m | \u001b[0m 27.81   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1207  \u001b[0m | \u001b[0m 0.2214  \u001b[0m | \u001b[0m 0.2257  \u001b[0m | \u001b[0m 0.3428  \u001b[0m | \u001b[0m 0.191   \u001b[0m | \u001b[0m 6.038   \u001b[0m | \u001b[0m 461.9   \u001b[0m | \u001b[0m 18.6    \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.9482  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 18.53   \u001b[0m | \u001b[0m 481.5   \u001b[0m | \u001b[0m 30.77   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1169  \u001b[0m | \u001b[0m 0.7784  \u001b[0m | \u001b[0m 0.3144  \u001b[0m | \u001b[0m 0.69    \u001b[0m | \u001b[0m 0.1599  \u001b[0m | \u001b[0m 16.46   \u001b[0m | \u001b[0m 481.0   \u001b[0m | \u001b[0m 14.71   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1277  \u001b[0m | \u001b[0m 0.6214  \u001b[0m | \u001b[0m 0.6739  \u001b[0m | \u001b[0m 0.4215  \u001b[0m | \u001b[0m 0.4349  \u001b[0m | \u001b[0m 10.36   \u001b[0m | \u001b[0m 475.1   \u001b[0m | \u001b[0m 13.35   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1322  \u001b[0m | \u001b[0m 0.3267  \u001b[0m | \u001b[0m 0.4726  \u001b[0m | \u001b[0m 0.2948  \u001b[0m | \u001b[0m 0.3936  \u001b[0m | \u001b[0m 11.34   \u001b[0m | \u001b[0m 491.7   \u001b[0m | \u001b[0m 27.24   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway System LGBM Models Bayes Final: 100%|██████████| 3/3 [00:55<00:00, 18.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# Using the above list and the list of best model params, loop in parallel across the clusters and create a \n",
    "# model for each one. Save those models to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Highway System LGBM Models Bayes Final\", \n",
    "                      total=len(highway_clust_mods_bayes))) as progress_bar:\n",
    "    highway_clust_mods_bayes_final = Parallel(n_jobs=3)(delayed(train_lgbm)(highway_clust_mods_bayes[i], \n",
    "                                                                            train_val_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                            train_val_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(highway_clust_mods_bayes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "124556ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each of those models to a file \n",
    "for model_no in range(len(highway_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/Highway System/model_{model_no}\"\n",
    "    joblib.dump(highway_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "043fdd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Highway LGBM Models Bayes Residuals:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.19373553408774502, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19373553408774502\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6769592763361791, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6769592763361791\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1897274647171161, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1897274647171161\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9394997735129474, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9394997735129474\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.024069888905684955, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.024069888905684955\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4818983869899286, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4818983869899286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway LGBM Models Bayes Residuals: 100%|██████████| 3/3 [00:10<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each of the newly created models, in paralle, loop through the models and training data and\n",
    "# compute the model residuals. Save the residuals from each model to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Highway LGBM Models Bayes Residuals\", \n",
    "                      total=len(highway_clust_mods_bayes_final))) as progress_bar:\n",
    "    highway_clust_mods_bayes_resid = Parallel(n_jobs=3)(delayed(compute_lgbm_residuals)(highway_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(highway_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e3feae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of test data frames where each entry in the list is the test data frame for one cluster\n",
    "test_df_full_highway_clust_ls = [df.reset_index(drop=True) for _,df in test_df_full_highway.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "2f8d4281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway LGBM Models Bayes Test Preds: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the models and the list of test data frames, create test predictions, and save those to a list of \n",
    "# data frames\n",
    "with tqdm_joblib(tqdm(desc=\"Highway LGBM Models Bayes Test Preds\", \n",
    "                      total=len(highway_clust_mods_bayes_final))) as progress_bar:\n",
    "    highway_clust_mods_bayes_test_preds = Parallel(n_jobs=4)(delayed(compute_lgbm_test_preds)(highway_clust_mods_bayes_final[i],\n",
    "                                                                                           test_df_full_highway_clust_ls[i],\n",
    "                                                                                           lag_n\n",
    "                                                                                          ) for i in range(len(highway_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "9ba4797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one data frame from the above list of test pred data frames\n",
    "highway_clust_bayes_test_preds_df = pd.DataFrame()\n",
    "for clust_test_pred_df in highway_clust_mods_bayes_test_preds:\n",
    "    highway_clust_bayes_test_preds_df = highway_clust_bayes_test_preds_df.append(clust_test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ef9eb93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance metrics on the full data frame of test predictions\n",
    "highway_clust_bayes_test_perf = compute_lgbm_test_perf(highway_clust_bayes_test_preds_df,\n",
    "                                                       test_df_full_highway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "65083c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized/scaled perf metrics\n",
    "highway_clust_bayes_test_perf['nrmse'] = highway_clust_bayes_test_perf['rmse']/highway_clust_bayes_test_perf['mean']\n",
    "highway_clust_bayes_test_perf['smae'] = highway_clust_bayes_test_perf['mae']/highway_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "a07c7dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      30.996605\n",
       "mae       20.548856\n",
       "mean     265.435072\n",
       "nrmse      0.140288\n",
       "smae       0.094851\n",
       "dtype: float64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print means of performance metrics\n",
    "highway_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "2f5b863e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fb326da46142d189cc5615a68a17a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/51072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9fc5081a374354b31e332bc65a4270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d161839cdaff4506a68823e23027f873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through each set of preds and compute the bootstrap PIs for those preds/cluster\n",
    "highway_clust_test_pred_int = list()\n",
    "for i in range(len(highway_clust_mods_bayes_test_preds)):\n",
    "    highway_clust_test_pred_int.append(compute_lgbm_boostrap_int(highway_clust_mods_bayes_test_preds[i], \n",
    "                                                                 highway_clust_mods_bayes_resid[i], \n",
    "                                                                 n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9814a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster, add the true values to the data frame of preds\n",
    "for n in range(1, len(highway_clust_test_pred_int)+1):\n",
    "    y_actual_sub = test_df_full_highway.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    highway_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8068919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all PI data frames into one data frame\n",
    "highway_clust_test_pred_int_df = pd.DataFrame()\n",
    "for clust_test_pred_int_df in highway_clust_test_pred_int:\n",
    "    highway_clust_test_pred_int_df = highway_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b336bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every prediction in the PI data frame, compute the 95% and 80% PI score\n",
    "highway_clust_test_pred_int_df['int_95_score'] = interval_score(highway_clust_test_pred_int_df['actual'],\n",
    "                                                                highway_clust_test_pred_int_df['lo_95'],\n",
    "                                                                highway_clust_test_pred_int_df['hi_95'],\n",
    "                                                                0.95\n",
    "                                                               )\n",
    "\n",
    "highway_clust_test_pred_int_df['int_80_score'] = interval_score(highway_clust_test_pred_int_df['actual'],\n",
    "                                                                highway_clust_test_pred_int_df['lo_80'],\n",
    "                                                                highway_clust_test_pred_int_df['hi_80'],\n",
    "                                                                0.80\n",
    "                                                               )\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "565ea233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.651307\n",
       "lo_95           208.883734\n",
       "hi_95           324.581622\n",
       "lo_80           237.374393\n",
       "hi_80           295.037625\n",
       "actual          265.435072\n",
       "int_95_score    225.009805\n",
       "int_80_score    122.212428\n",
       "dtype: float64"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of the PI scores\n",
    "highway_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "ebb6b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI data frame to a csv file\n",
    "highway_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/Highway System/test_pred_intervals.csv\",\n",
    "                                      index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91044ce",
   "metadata": {},
   "source": [
    "# Test and Train - Catch22 KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "ccb9259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused variables\n",
    "del highway_clust_test_pred_int_df\n",
    "del highway_clust_test_pred_int\n",
    "del clust_test_pred_int_df\n",
    "del y_actual_sub\n",
    "del highway_clust_bayes_test_perf\n",
    "del highway_clust_bayes_test_preds_df\n",
    "del clust_test_pred_df\n",
    "del highway_clust_mods_bayes_test_preds\n",
    "del test_df_full_highway_clust_ls\n",
    "del test_df_full_highway\n",
    "del highway_clust_mods_bayes_resid\n",
    "del highway_clust_mods_bayes_final\n",
    "del train_val_df_highway_clust_ls\n",
    "del train_val_df_full_highway\n",
    "del highway_clust_mods_bayes\n",
    "del train_df_highway_clust_ls\n",
    "del val_df_highway_clust_ls \n",
    "del train_df_full_highway\n",
    "del val_df_full_highway\n",
    "del highway_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c4775a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16821"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "7c8ba4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cluster assignmed from the Catch22-based KMeans clusters\n",
    "catch22_clust = pd.read_csv(\"Results/Clustering/KMeans/kmeans_catch22_clustering_assign.csv\")\n",
    "catch22_clust['cluster'] = catch22_clust['kmeans_catch22_clust_assign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "20857a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the training, validation, train_val, and test data with the cluster assignments\n",
    "train_df_full_catch22 = train_df_full.merge(catch22_clust, on=\"ts_index\")\n",
    "val_df_full_catch22 = val_df_full.merge(catch22_clust, on=\"ts_index\")\n",
    "train_val_df_full_catch22 = train_val_df_full.merge(catch22_clust, on=\"ts_index\")\n",
    "test_df_full_catch22 = test_df_full.merge(catch22_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "3b6d1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of training and validation data frames which contain data for only one cluster each\n",
    "train_df_catch22_clust_ls = [df.reset_index(drop=True) for _,df in train_df_full_catch22.groupby(\"cluster\")]\n",
    "val_df_catch22_clust_ls = [df.reset_index(drop=True) for _,df in val_df_full_catch22.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "2af55654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes:  67%|██████▋   | 2/3 [14:42<06:22, 382.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1946  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2015  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2204  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2564  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2166  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.191   \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.209   \u001b[0m | \u001b[0m 0.4405  \u001b[0m | \u001b[0m 0.1374  \u001b[0m | \u001b[0m 0.64    \u001b[0m | \u001b[0m 0.3496  \u001b[0m | \u001b[0m 2.775   \u001b[0m | \u001b[0m 837.2   \u001b[0m | \u001b[0m 144.8   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2482  \u001b[0m | \u001b[0m 0.4836  \u001b[0m | \u001b[0m 0.634   \u001b[0m | \u001b[0m 0.982   \u001b[0m | \u001b[0m 0.4812  \u001b[0m | \u001b[0m 6.837   \u001b[0m | \u001b[0m 473.0   \u001b[0m | \u001b[0m 25.04   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2186  \u001b[0m | \u001b[0m 0.3548  \u001b[0m | \u001b[0m 0.8135  \u001b[0m | \u001b[0m 0.5065  \u001b[0m | \u001b[0m 0.4409  \u001b[0m | \u001b[0m 3.499   \u001b[0m | \u001b[0m 830.0   \u001b[0m | \u001b[0m 143.2   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2013  \u001b[0m | \u001b[0m 0.5874  \u001b[0m | \u001b[0m 0.748   \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.278   \u001b[0m | \u001b[0m 12.53   \u001b[0m | \u001b[0m 465.6   \u001b[0m | \u001b[0m 20.65   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.1846  \u001b[0m | \u001b[95m 0.225   \u001b[0m | \u001b[95m 0.9094  \u001b[0m | \u001b[95m 0.07102 \u001b[0m | \u001b[95m 0.01027 \u001b[0m | \u001b[95m 7.201   \u001b[0m | \u001b[95m 833.4   \u001b[0m | \u001b[95m 149.4   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-0.1825  \u001b[0m | \u001b[95m 0.9429  \u001b[0m | \u001b[95m 0.1955  \u001b[0m | \u001b[95m 0.7214  \u001b[0m | \u001b[95m 0.07916 \u001b[0m | \u001b[95m 21.2    \u001b[0m | \u001b[95m 468.4   \u001b[0m | \u001b[95m 21.05   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2456  \u001b[0m | \u001b[0m 0.9178  \u001b[0m | \u001b[0m 0.8858  \u001b[0m | \u001b[0m 0.7062  \u001b[0m | \u001b[0m 0.4654  \u001b[0m | \u001b[0m 22.16   \u001b[0m | \u001b[0m 477.1   \u001b[0m | \u001b[0m 21.62   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1851  \u001b[0m | \u001b[0m 0.4927  \u001b[0m | \u001b[0m 0.2805  \u001b[0m | \u001b[0m 0.1107  \u001b[0m | \u001b[0m 0.07941 \u001b[0m | \u001b[0m 22.31   \u001b[0m | \u001b[0m 464.3   \u001b[0m | \u001b[0m 19.58   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2181  \u001b[0m | \u001b[0m 0.4397  \u001b[0m | \u001b[0m 0.6624  \u001b[0m | \u001b[0m 0.5607  \u001b[0m | \u001b[0m 0.3592  \u001b[0m | \u001b[0m 20.82   \u001b[0m | \u001b[0m 464.3   \u001b[0m | \u001b[0m 24.82   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.137   \u001b[0m | \u001b[0m 0.9545  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.321   \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 18.81   \u001b[0m | \u001b[0m 467.3   \u001b[0m | \u001b[0m 17.39   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.2085  \u001b[0m | \u001b[0m 0.9399  \u001b[0m | \u001b[0m 0.2984  \u001b[0m | \u001b[0m 0.1673  \u001b[0m | \u001b[0m 0.2724  \u001b[0m | \u001b[0m 8.662   \u001b[0m | \u001b[0m 833.7   \u001b[0m | \u001b[0m 148.2   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.196   \u001b[0m | \u001b[0m 0.6506  \u001b[0m | \u001b[0m 0.02882 \u001b[0m | \u001b[0m 0.7737  \u001b[0m | \u001b[0m 0.2288  \u001b[0m | \u001b[0m 21.31   \u001b[0m | \u001b[0m 470.8   \u001b[0m | \u001b[0m 22.71   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1827  \u001b[0m | \u001b[0m 0.4944  \u001b[0m | \u001b[0m 0.3307  \u001b[0m | \u001b[0m 0.4453  \u001b[0m | \u001b[0m 0.03993 \u001b[0m | \u001b[0m 16.18   \u001b[0m | \u001b[0m 472.7   \u001b[0m | \u001b[0m 25.08   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2265  \u001b[0m | \u001b[0m 0.8782  \u001b[0m | \u001b[0m 0.3818  \u001b[0m | \u001b[0m 0.08214 \u001b[0m | \u001b[0m 0.3856  \u001b[0m | \u001b[0m 24.79   \u001b[0m | \u001b[0m 466.1   \u001b[0m | \u001b[0m 22.27   \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-0.1795  \u001b[0m | \u001b[95m 0.8495  \u001b[0m | \u001b[95m 0.715   \u001b[0m | \u001b[95m 0.3199  \u001b[0m | \u001b[95m 0.08774 \u001b[0m | \u001b[95m 6.741   \u001b[0m | \u001b[95m 835.0   \u001b[0m | \u001b[95m 145.0   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.2326  \u001b[0m | \u001b[0m 0.7312  \u001b[0m | \u001b[0m 0.605   \u001b[0m | \u001b[0m 0.4415  \u001b[0m | \u001b[0m 0.4562  \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 460.5   \u001b[0m | \u001b[0m 21.38   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1853  \u001b[0m | \u001b[0m 0.5086  \u001b[0m | \u001b[0m 0.2611  \u001b[0m | \u001b[0m 0.2208  \u001b[0m | \u001b[0m 0.1038  \u001b[0m | \u001b[0m 21.71   \u001b[0m | \u001b[0m 468.3   \u001b[0m | \u001b[0m 25.75   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.2452  \u001b[0m | \u001b[0m 0.1841  \u001b[0m | \u001b[0m 0.05642 \u001b[0m | \u001b[0m 0.5359  \u001b[0m | \u001b[0m 0.3785  \u001b[0m | \u001b[0m 6.635   \u001b[0m | \u001b[0m 831.8   \u001b[0m | \u001b[0m 141.5   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2286  \u001b[0m | \u001b[0m 0.3983  \u001b[0m | \u001b[0m 0.4026  \u001b[0m | \u001b[0m 0.9185  \u001b[0m | \u001b[0m 0.3664  \u001b[0m | \u001b[0m 6.985   \u001b[0m | \u001b[0m 829.4   \u001b[0m | \u001b[0m 149.2   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1949  \u001b[0m | \u001b[0m 0.2826  \u001b[0m | \u001b[0m 0.8245  \u001b[0m | \u001b[0m 0.04737 \u001b[0m | \u001b[0m 0.1652  \u001b[0m | \u001b[0m 2.339   \u001b[0m | \u001b[0m 833.8   \u001b[0m | \u001b[0m 149.1   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.235   \u001b[0m | \u001b[0m 0.9257  \u001b[0m | \u001b[0m 0.5745  \u001b[0m | \u001b[0m 0.4407  \u001b[0m | \u001b[0m 0.4245  \u001b[0m | \u001b[0m 5.692   \u001b[0m | \u001b[0m 839.3   \u001b[0m | \u001b[0m 148.0   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.2102  \u001b[0m | \u001b[0m 0.485   \u001b[0m | \u001b[0m 0.799   \u001b[0m | \u001b[0m 0.515   \u001b[0m | \u001b[0m 0.3005  \u001b[0m | \u001b[0m 19.82   \u001b[0m | \u001b[0m 474.1   \u001b[0m | \u001b[0m 26.82   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.2448  \u001b[0m | \u001b[0m 0.6573  \u001b[0m | \u001b[0m 0.7202  \u001b[0m | \u001b[0m 0.7779  \u001b[0m | \u001b[0m 0.4688  \u001b[0m | \u001b[0m 11.22   \u001b[0m | \u001b[0m 469.0   \u001b[0m | \u001b[0m 22.42   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1927  \u001b[0m | \u001b[0m 0.1104  \u001b[0m | \u001b[0m 0.2138  \u001b[0m | \u001b[0m 0.8432  \u001b[0m | \u001b[0m 0.0597  \u001b[0m | \u001b[0m 8.928   \u001b[0m | \u001b[0m 836.5   \u001b[0m | \u001b[0m 141.1   \u001b[0m |\n",
      "=============================================================================================================\n",
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1458  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1519  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1745  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1945  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1607  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1392  \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1438  \u001b[0m | \u001b[0m 0.4892  \u001b[0m | \u001b[0m 0.1292  \u001b[0m | \u001b[0m 0.7004  \u001b[0m | \u001b[0m 0.1635  \u001b[0m | \u001b[0m 6.494   \u001b[0m | \u001b[0m 832.8   \u001b[0m | \u001b[0m 149.1   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1385  \u001b[0m | \u001b[95m 0.8211  \u001b[0m | \u001b[95m 0.9199  \u001b[0m | \u001b[95m 0.748   \u001b[0m | \u001b[95m 0.1659  \u001b[0m | \u001b[95m 2.619   \u001b[0m | \u001b[95m 839.8   \u001b[0m | \u001b[95m 144.5   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1739  \u001b[0m | \u001b[0m 0.3894  \u001b[0m | \u001b[0m 0.0252  \u001b[0m | \u001b[0m 0.3812  \u001b[0m | \u001b[0m 0.418   \u001b[0m | \u001b[0m 4.29    \u001b[0m | \u001b[0m 839.3   \u001b[0m | \u001b[0m 132.4   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1464  \u001b[0m | \u001b[0m 0.1802  \u001b[0m | \u001b[0m 0.4693  \u001b[0m | \u001b[0m 0.2619  \u001b[0m | \u001b[0m 0.1751  \u001b[0m | \u001b[0m 3.532   \u001b[0m | \u001b[0m 834.1   \u001b[0m | \u001b[0m 143.4   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.1372  \u001b[0m | \u001b[95m 0.2977  \u001b[0m | \u001b[95m 0.7155  \u001b[0m | \u001b[95m 0.534   \u001b[0m | \u001b[95m 0.05538 \u001b[0m | \u001b[95m 8.181   \u001b[0m | \u001b[95m 848.8   \u001b[0m | \u001b[95m 148.2   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1724  \u001b[0m | \u001b[0m 0.8964  \u001b[0m | \u001b[0m 0.3389  \u001b[0m | \u001b[0m 0.06909 \u001b[0m | \u001b[0m 0.4792  \u001b[0m | \u001b[0m 2.729   \u001b[0m | \u001b[0m 854.5   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1492  \u001b[0m | \u001b[0m 0.2703  \u001b[0m | \u001b[0m 0.2059  \u001b[0m | \u001b[0m 0.6876  \u001b[0m | \u001b[0m 0.172   \u001b[0m | \u001b[0m 10.71   \u001b[0m | \u001b[0m 842.8   \u001b[0m | \u001b[0m 143.3   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 847.5   \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1758  \u001b[0m | \u001b[0m 0.3142  \u001b[0m | \u001b[0m 0.8961  \u001b[0m | \u001b[0m 0.1782  \u001b[0m | \u001b[0m 0.3604  \u001b[0m | \u001b[0m 5.551   \u001b[0m | \u001b[0m 847.8   \u001b[0m | \u001b[0m 143.9   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1486  \u001b[0m | \u001b[0m 0.2398  \u001b[0m | \u001b[0m 0.6205  \u001b[0m | \u001b[0m 0.7586  \u001b[0m | \u001b[0m 0.1902  \u001b[0m | \u001b[0m 6.413   \u001b[0m | \u001b[0m 838.0   \u001b[0m | \u001b[0m 146.7   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1822  \u001b[0m | \u001b[0m 0.7666  \u001b[0m | \u001b[0m 0.6097  \u001b[0m | \u001b[0m 0.4124  \u001b[0m | \u001b[0m 0.4023  \u001b[0m | \u001b[0m 6.684   \u001b[0m | \u001b[0m 840.7   \u001b[0m | \u001b[0m 140.8   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1396  \u001b[0m | \u001b[0m 0.4946  \u001b[0m | \u001b[0m 0.9945  \u001b[0m | \u001b[0m 0.5067  \u001b[0m | \u001b[0m 0.08982 \u001b[0m | \u001b[0m 11.97   \u001b[0m | \u001b[0m 831.5   \u001b[0m | \u001b[0m 143.8   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1722  \u001b[0m | \u001b[0m 0.2367  \u001b[0m | \u001b[0m 0.5618  \u001b[0m | \u001b[0m 0.1283  \u001b[0m | \u001b[0m 0.2957  \u001b[0m | \u001b[0m 13.93   \u001b[0m | \u001b[0m 833.9   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m-0.1355  \u001b[0m | \u001b[95m 0.6163  \u001b[0m | \u001b[95m 0.8876  \u001b[0m | \u001b[95m 0.6893  \u001b[0m | \u001b[95m 0.06886 \u001b[0m | \u001b[95m 2.205   \u001b[0m | \u001b[95m 844.8   \u001b[0m | \u001b[95m 148.1   \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-0.1352  \u001b[0m | \u001b[95m 0.4097  \u001b[0m | \u001b[95m 0.5419  \u001b[0m | \u001b[95m 0.7418  \u001b[0m | \u001b[95m 0.03907 \u001b[0m | \u001b[95m 12.39   \u001b[0m | \u001b[95m 826.6   \u001b[0m | \u001b[95m 138.9   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1845  \u001b[0m | \u001b[0m 0.3967  \u001b[0m | \u001b[0m 0.742   \u001b[0m | \u001b[0m 0.06173 \u001b[0m | \u001b[0m 0.4344  \u001b[0m | \u001b[0m 5.218   \u001b[0m | \u001b[0m 827.4   \u001b[0m | \u001b[0m 139.5   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1686  \u001b[0m | \u001b[0m 0.1486  \u001b[0m | \u001b[0m 0.5826  \u001b[0m | \u001b[0m 0.6321  \u001b[0m | \u001b[0m 0.2265  \u001b[0m | \u001b[0m 15.17   \u001b[0m | \u001b[0m 822.9   \u001b[0m | \u001b[0m 143.4   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1562  \u001b[0m | \u001b[0m 0.1414  \u001b[0m | \u001b[0m 0.8579  \u001b[0m | \u001b[0m 0.3664  \u001b[0m | \u001b[0m 0.2384  \u001b[0m | \u001b[0m 8.524   \u001b[0m | \u001b[0m 825.0   \u001b[0m | \u001b[0m 144.2   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1623  \u001b[0m | \u001b[0m 0.4721  \u001b[0m | \u001b[0m 0.8715  \u001b[0m | \u001b[0m 0.4276  \u001b[0m | \u001b[0m 0.2871  \u001b[0m | \u001b[0m 16.31   \u001b[0m | \u001b[0m 835.0   \u001b[0m | \u001b[0m 136.4   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1438  \u001b[0m | \u001b[0m 0.3879  \u001b[0m | \u001b[0m 0.3024  \u001b[0m | \u001b[0m 0.4862  \u001b[0m | \u001b[0m 0.1306  \u001b[0m | \u001b[0m 21.85   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 141.7   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1397  \u001b[0m | \u001b[0m 0.3998  \u001b[0m | \u001b[0m 0.3865  \u001b[0m | \u001b[0m 0.4813  \u001b[0m | \u001b[0m 0.1013  \u001b[0m | \u001b[0m 16.97   \u001b[0m | \u001b[0m 826.9   \u001b[0m | \u001b[0m 135.2   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1687  \u001b[0m | \u001b[0m 0.8176  \u001b[0m | \u001b[0m 0.4623  \u001b[0m | \u001b[0m 0.05252 \u001b[0m | \u001b[0m 0.3393  \u001b[0m | \u001b[0m 11.1    \u001b[0m | \u001b[0m 823.7   \u001b[0m | \u001b[0m 131.7   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1761  \u001b[0m | \u001b[0m 0.4458  \u001b[0m | \u001b[0m 0.6995  \u001b[0m | \u001b[0m 0.419   \u001b[0m | \u001b[0m 0.3452  \u001b[0m | \u001b[0m 9.537   \u001b[0m | \u001b[0m 831.8   \u001b[0m | \u001b[0m 132.9   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1818  \u001b[0m | \u001b[0m 0.7506  \u001b[0m | \u001b[0m 0.1035  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 0.4096  \u001b[0m | \u001b[0m 21.22   \u001b[0m | \u001b[0m 821.4   \u001b[0m | \u001b[0m 138.8   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes: 100%|██████████| 3/3 [26:28<00:00, 529.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# In parallel, loop through the clusters and run the optimizer for a model for each cluster. Save best model\n",
    "# params for each cluster to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Catch22 LGBM Models Bayes\", \n",
    "                      total=len(train_df_catch22_clust_ls))) as progress_bar:\n",
    "    catch22_clust_mods_bayes = Parallel(n_jobs=3)(delayed(optimize_lgbm_w_bayes)(train_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                 train_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                                 val_df_catch22_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                                 val_df_catch22_clust_ls[i].iloc[:,0]) for i in range(len(train_df_catch22_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "cc642a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert params for each model to integer where necessary \n",
    "for n in range(len(catch22_clust_mods_bayes)):\n",
    "    catch22_clust_mods_bayes[n][\"max_depth\"] = int(round(catch22_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    catch22_clust_mods_bayes[n][\"n_estimators\"] = int(round(catch22_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    catch22_clust_mods_bayes[n][\"num_leaves\"] = int(round(catch22_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "acf59b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train_val data into a list of data frames as well\n",
    "train_val_df_catch22_clust_ls = [df.reset_index(drop=True) for _,df in train_val_df_full_catch22.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "2062ecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes Final: 100%|██████████| 3/3 [01:10<00:00, 23.55s/it]\n"
     ]
    }
   ],
   "source": [
    "# Using the train_val data, compute a final model for each cluster\n",
    "with tqdm_joblib(tqdm(desc=\"Catch22 LGBM Models Bayes Final\", \n",
    "                      total=len(catch22_clust_mods_bayes))) as progress_bar:\n",
    "    catch22_clust_mods_bayes_final = Parallel(n_jobs=3)(delayed(train_lgbm)(catch22_clust_mods_bayes[i], \n",
    "                                                                            train_val_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                            train_val_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(catch22_clust_mods_bayes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "3d96c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1211  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1219  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1312  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1466  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1289  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1316  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1268  \u001b[0m | \u001b[0m 0.1823  \u001b[0m | \u001b[0m 0.2334  \u001b[0m | \u001b[0m 0.3629  \u001b[0m | \u001b[0m 0.06587 \u001b[0m | \u001b[0m 17.26   \u001b[0m | \u001b[0m 859.2   \u001b[0m | \u001b[0m 141.3   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1198  \u001b[0m | \u001b[95m 0.5977  \u001b[0m | \u001b[95m 0.2829  \u001b[0m | \u001b[95m 0.9203  \u001b[0m | \u001b[95m 0.08668 \u001b[0m | \u001b[95m 8.428   \u001b[0m | \u001b[95m 942.3   \u001b[0m | \u001b[95m 106.7   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.14    \u001b[0m | \u001b[0m 0.6154  \u001b[0m | \u001b[0m 0.5809  \u001b[0m | \u001b[0m 0.5974  \u001b[0m | \u001b[0m 0.3896  \u001b[0m | \u001b[0m 23.0    \u001b[0m | \u001b[0m 433.1   \u001b[0m | \u001b[0m 83.41   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1307  \u001b[0m | \u001b[0m 0.2707  \u001b[0m | \u001b[0m 0.3919  \u001b[0m | \u001b[0m 0.8713  \u001b[0m | \u001b[0m 0.2398  \u001b[0m | \u001b[0m 21.29   \u001b[0m | \u001b[0m 182.6   \u001b[0m | \u001b[0m 128.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1244  \u001b[0m | \u001b[0m 0.5174  \u001b[0m | \u001b[0m 0.2394  \u001b[0m | \u001b[0m 0.01523 \u001b[0m | \u001b[0m 0.3594  \u001b[0m | \u001b[0m 2.433   \u001b[0m | \u001b[0m 593.3   \u001b[0m | \u001b[0m 126.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1219  \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 0.517   \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 0.09298 \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 583.4   \u001b[0m | \u001b[0m 123.1   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1239  \u001b[0m | \u001b[0m 0.957   \u001b[0m | \u001b[0m 0.5047  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.2706  \u001b[0m | \u001b[0m 8.573   \u001b[0m | \u001b[0m 757.1   \u001b[0m | \u001b[0m 17.0    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1314  \u001b[0m | \u001b[0m 0.2656  \u001b[0m | \u001b[0m 0.04668 \u001b[0m | \u001b[0m 0.03001 \u001b[0m | \u001b[0m 0.1727  \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 861.6   \u001b[0m | \u001b[0m 139.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1278  \u001b[0m | \u001b[0m 0.8199  \u001b[0m | \u001b[0m 0.4933  \u001b[0m | \u001b[0m 0.7328  \u001b[0m | \u001b[0m 0.2643  \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 398.9   \u001b[0m | \u001b[0m 92.87   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1645  \u001b[0m | \u001b[0m 0.5136  \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 0.06973 \u001b[0m | \u001b[0m 0.4773  \u001b[0m | \u001b[0m 10.62   \u001b[0m | \u001b[0m 642.0   \u001b[0m | \u001b[0m 97.73   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1313  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.371   \u001b[0m | \u001b[0m 9.194   \u001b[0m | \u001b[0m 969.5   \u001b[0m | \u001b[0m 23.1    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.125   \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.0695  \u001b[0m | \u001b[0m 0.3948  \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 27.02   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.137   \u001b[0m | \u001b[0m 0.4384  \u001b[0m | \u001b[0m 0.5412  \u001b[0m | \u001b[0m 0.7127  \u001b[0m | \u001b[0m 0.3604  \u001b[0m | \u001b[0m 5.896   \u001b[0m | \u001b[0m 938.8   \u001b[0m | \u001b[0m 108.2   \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m-0.1196  \u001b[0m | \u001b[95m 0.6604  \u001b[0m | \u001b[95m 0.5603  \u001b[0m | \u001b[95m 0.4809  \u001b[0m | \u001b[95m 0.09778 \u001b[0m | \u001b[95m 17.32   \u001b[0m | \u001b[95m 351.6   \u001b[0m | \u001b[95m 72.41   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1217  \u001b[0m | \u001b[0m 0.5473  \u001b[0m | \u001b[0m 0.4401  \u001b[0m | \u001b[0m 0.2456  \u001b[0m | \u001b[0m 0.03631 \u001b[0m | \u001b[0m 3.376   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1339  \u001b[0m | \u001b[0m 0.457   \u001b[0m | \u001b[0m 0.3322  \u001b[0m | \u001b[0m 0.2009  \u001b[0m | \u001b[0m 0.3646  \u001b[0m | \u001b[0m 5.143   \u001b[0m | \u001b[0m 822.7   \u001b[0m | \u001b[0m 148.3   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1599  \u001b[0m | \u001b[0m 0.3959  \u001b[0m | \u001b[0m 0.8988  \u001b[0m | \u001b[0m 0.704   \u001b[0m | \u001b[0m 0.4648  \u001b[0m | \u001b[0m 8.096   \u001b[0m | \u001b[0m 945.4   \u001b[0m | \u001b[0m 106.6   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1313  \u001b[0m | \u001b[0m 0.2895  \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.2897  \u001b[0m | \u001b[0m 18.61   \u001b[0m | \u001b[0m 352.7   \u001b[0m | \u001b[0m 74.32   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1322  \u001b[0m | \u001b[0m 0.1607  \u001b[0m | \u001b[0m 0.7421  \u001b[0m | \u001b[0m 0.2078  \u001b[0m | \u001b[0m 0.1644  \u001b[0m | \u001b[0m 18.01   \u001b[0m | \u001b[0m 350.9   \u001b[0m | \u001b[0m 70.73   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.128   \u001b[0m | \u001b[0m 0.5828  \u001b[0m | \u001b[0m 0.7701  \u001b[0m | \u001b[0m 0.3778  \u001b[0m | \u001b[0m 0.3432  \u001b[0m | \u001b[0m 5.039   \u001b[0m | \u001b[0m 826.5   \u001b[0m | \u001b[0m 148.8   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.134   \u001b[0m | \u001b[0m 0.4366  \u001b[0m | \u001b[0m 0.1673  \u001b[0m | \u001b[0m 0.4877  \u001b[0m | \u001b[0m 0.3943  \u001b[0m | \u001b[0m 9.174   \u001b[0m | \u001b[0m 754.4   \u001b[0m | \u001b[0m 17.32   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1201  \u001b[0m | \u001b[0m 0.522   \u001b[0m | \u001b[0m 0.2595  \u001b[0m | \u001b[0m 0.5406  \u001b[0m | \u001b[0m 0.08873 \u001b[0m | \u001b[0m 17.08   \u001b[0m | \u001b[0m 353.0   \u001b[0m | \u001b[0m 72.05   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.136   \u001b[0m | \u001b[0m 0.3906  \u001b[0m | \u001b[0m 0.8515  \u001b[0m | \u001b[0m 0.4464  \u001b[0m | \u001b[0m 0.3756  \u001b[0m | \u001b[0m 6.134   \u001b[0m | \u001b[0m 584.1   \u001b[0m | \u001b[0m 124.2   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1248  \u001b[0m | \u001b[0m 0.2755  \u001b[0m | \u001b[0m 0.8272  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.401   \u001b[0m | \u001b[0m 2.293   \u001b[0m | \u001b[0m 582.6   \u001b[0m | \u001b[0m 121.0   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5603264763739176, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5603264763739176\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4809420884228284, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4809420884228284\n"
     ]
    }
   ],
   "source": [
    "# Save the final models to files\n",
    "for model_no in range(len(catch22_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/Catch22 KMeans/model_{model_no}\"\n",
    "    joblib.dump(catch22_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "76795d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes Residuals: 100%|██████████| 3/3 [00:10<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each model, compute the model's residuals and save to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Catch22 LGBM Models Bayes Residuals\", \n",
    "                      total=len(catch22_clust_mods_bayes_final))) as progress_bar:\n",
    "    catch22_clust_mods_bayes_resid = Parallel(n_jobs=3)(delayed(compute_lgbm_residuals)(catch22_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(catch22_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "49d9ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test data into a list of data frames, one for each cluster\n",
    "test_df_full_catch22_clust_ls = [df.reset_index(drop=True) for _,df in test_df_full_catch22.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "66973326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Catch22 LGBM Models Bayes Test Preds:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.7150192379657201, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7150192379657201\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.31992602947600424, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.31992602947600424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5418859120290022, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5418859120290022\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7418325419012708, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7418325419012708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes Test Preds: 100%|██████████| 3/3 [00:05<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each cluster, compute the model's test predictions\n",
    "with tqdm_joblib(tqdm(desc=\"Catch22 LGBM Models Bayes Test Preds\", \n",
    "                      total=len(catch22_clust_mods_bayes_final))) as progress_bar:\n",
    "    catch22_clust_mods_bayes_test_preds = Parallel(n_jobs=4)(delayed(compute_lgbm_test_preds)(catch22_clust_mods_bayes_final[i],\n",
    "                                                                                              test_df_full_catch22_clust_ls[i],\n",
    "                                                                                              lag_n\n",
    "                                                                                             ) for i in range(len(catch22_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "ebfc084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all data frames from the above list into one data frame of test predictions\n",
    "catch22_clust_bayes_test_preds_df = pd.DataFrame()\n",
    "for clust_test_pred_df in catch22_clust_mods_bayes_test_preds:\n",
    "    catch22_clust_bayes_test_preds_df = catch22_clust_bayes_test_preds_df.append(clust_test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "1248de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test pred performance\n",
    "catch22_clust_bayes_test_perf = compute_lgbm_test_perf(catch22_clust_bayes_test_preds_df,\n",
    "                                                       test_df_full_catch22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "706ac2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add normalized performance metrics to the performance data frame\n",
    "catch22_clust_bayes_test_perf['nrmse'] = catch22_clust_bayes_test_perf['rmse']/catch22_clust_bayes_test_perf['mean']\n",
    "catch22_clust_bayes_test_perf['smae'] = catch22_clust_bayes_test_perf['mae']/catch22_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "810d79a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      30.702054\n",
       "mae       20.264652\n",
       "mean     265.435072\n",
       "nrmse      0.137546\n",
       "smae       0.092509\n",
       "dtype: float64"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of perf metrics\n",
    "catch22_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "fbb7599d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e216e464b645fb8c1509e9c6242f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/69888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a7e0cc2d894f9c8655d41f6eb1fb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/12096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911f11e02a7b4bad849f0cd95e069e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through the model preds and residuals, and create a df of bootstrap PIs for each prediction\n",
    "# save to a list of data frames\n",
    "catch22_clust_test_pred_int = list()\n",
    "for i in range(len(catch22_clust_mods_bayes_test_preds)):\n",
    "    catch22_clust_test_pred_int.append(compute_lgbm_boostrap_int(catch22_clust_mods_bayes_test_preds[i], \n",
    "                                                                 catch22_clust_mods_bayes_resid[i], \n",
    "                                                                 n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "a32b8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster, add the true values for y to the data frame in a new column called actual\n",
    "for n in range(1, len(catch22_clust_test_pred_int)+1):\n",
    "    y_actual_sub = test_df_full_catch22.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    catch22_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "695d21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all PI data frames into one data frame\n",
    "catch22_clust_test_pred_int_df = pd.DataFrame()\n",
    "for clust_test_pred_int_df in catch22_clust_test_pred_int:\n",
    "    catch22_clust_test_pred_int_df = catch22_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "859a2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On that one data frame, compute the 95% and 80% PI scores for each observation\n",
    "catch22_clust_test_pred_int_df['int_95_score'] = interval_score(catch22_clust_test_pred_int_df['actual'],\n",
    "                                                                catch22_clust_test_pred_int_df['lo_95'],\n",
    "                                                                catch22_clust_test_pred_int_df['hi_95'],\n",
    "                                                                0.95\n",
    "                                                               )\n",
    "\n",
    "catch22_clust_test_pred_int_df['int_80_score'] = interval_score(catch22_clust_test_pred_int_df['actual'],\n",
    "                                                                catch22_clust_test_pred_int_df['lo_80'],\n",
    "                                                                catch22_clust_test_pred_int_df['hi_80'],\n",
    "                                                                0.80\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "a97271b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.521986\n",
       "lo_95           221.558338\n",
       "hi_95           311.057911\n",
       "lo_80           241.508014\n",
       "hi_80           290.051726\n",
       "actual          265.435072\n",
       "int_95_score    253.125245\n",
       "int_80_score    123.540136\n",
       "dtype: float64"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean of the PI scores\n",
    "catch22_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "11680392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PI df to csv\n",
    "catch22_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/Catch22 KMeans/test_pred_intervals.csv\",\n",
    "                                      index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f777552",
   "metadata": {},
   "source": [
    "# Test and Train - TSFeat KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "db8af8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete variables that are no longer needed\n",
    "del catch22_clust_test_pred_int_df\n",
    "del catch22_clust_test_pred_int\n",
    "del clust_test_pred_int_df\n",
    "del y_actual_sub\n",
    "del catch22_clust_bayes_test_perf\n",
    "del catch22_clust_bayes_test_preds_df\n",
    "del clust_test_pred_df\n",
    "del catch22_clust_mods_bayes_test_preds\n",
    "del test_df_full_catch22_clust_ls\n",
    "del test_df_full_catch22\n",
    "del catch22_clust_mods_bayes_resid\n",
    "del catch22_clust_mods_bayes_final\n",
    "del train_val_df_catch22_clust_ls\n",
    "del train_val_df_full_catch22\n",
    "del catch22_clust_mods_bayes\n",
    "del train_df_catch22_clust_ls\n",
    "del val_df_catch22_clust_ls \n",
    "del train_df_full_catch22\n",
    "del val_df_full_catch22\n",
    "del catch22_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "6fabce63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the garbage collector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "2d1f9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cluster assignments for the KMeans clusted based on tsfeat feature set\n",
    "tsfeat_clust = pd.read_csv(\"Results/Clustering/KMeans/kmeans_tsfeat_clustering_assign.csv\")\n",
    "tsfeat_clust['cluster'] =  tsfeat_clust['kmeans_tsfeat_clust_assign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "7541ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the train, val, train_val, and test data frames with the cluster assignments\n",
    "train_df_full_tsfeat = train_df_full.merge(tsfeat_clust, on=\"ts_index\")\n",
    "val_df_full_tsfeat = val_df_full.merge(tsfeat_clust, on=\"ts_index\")\n",
    "train_val_df_full_tsfeat = train_val_df_full.merge(tsfeat_clust, on=\"ts_index\")\n",
    "test_df_full_tsfeat = test_df_full.merge(tsfeat_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "1ee7d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of data frames for training and validation, where each df in the list is data for one cluster\n",
    "train_df_tsfeat_clust_ls = [df.reset_index(drop=True) for _,df in train_df_full_tsfeat.groupby(\"cluster\")]\n",
    "val_df_tsfeat_clust_ls = [df.reset_index(drop=True) for _,df in val_df_full_tsfeat.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0e4b979e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes:  33%|███▎      | 1/3 [08:23<16:47, 503.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1853  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1928  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2263  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.258   \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2051  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1717  \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1817  \u001b[0m | \u001b[0m 0.4892  \u001b[0m | \u001b[0m 0.1292  \u001b[0m | \u001b[0m 0.7004  \u001b[0m | \u001b[0m 0.1635  \u001b[0m | \u001b[0m 6.494   \u001b[0m | \u001b[0m 832.8   \u001b[0m | \u001b[0m 149.1   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1722  \u001b[0m | \u001b[0m 0.5206  \u001b[0m | \u001b[0m 0.6055  \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 0.08544 \u001b[0m | \u001b[0m 2.594   \u001b[0m | \u001b[0m 828.8   \u001b[0m | \u001b[0m 143.6   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2013  \u001b[0m | \u001b[0m 0.6826  \u001b[0m | \u001b[0m 0.6963  \u001b[0m | \u001b[0m 0.3079  \u001b[0m | \u001b[0m 0.3418  \u001b[0m | \u001b[0m 2.918   \u001b[0m | \u001b[0m 841.9   \u001b[0m | \u001b[0m 142.4   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.223   \u001b[0m | \u001b[0m 0.9369  \u001b[0m | \u001b[0m 0.4143  \u001b[0m | \u001b[0m 0.7069  \u001b[0m | \u001b[0m 0.3657  \u001b[0m | \u001b[0m 8.715   \u001b[0m | \u001b[0m 829.7   \u001b[0m | \u001b[0m 137.2   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1737  \u001b[0m | \u001b[0m 0.2329  \u001b[0m | \u001b[0m 0.1652  \u001b[0m | \u001b[0m 0.1211  \u001b[0m | \u001b[0m 0.09329 \u001b[0m | \u001b[0m 10.94   \u001b[0m | \u001b[0m 471.0   \u001b[0m | \u001b[0m 29.59   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2053  \u001b[0m | \u001b[0m 0.7291  \u001b[0m | \u001b[0m 0.559   \u001b[0m | \u001b[0m 0.8316  \u001b[0m | \u001b[0m 0.3173  \u001b[0m | \u001b[0m 16.3    \u001b[0m | \u001b[0m 473.8   \u001b[0m | \u001b[0m 30.15   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-0.1696  \u001b[0m | \u001b[95m 0.3714  \u001b[0m | \u001b[95m 0.6943  \u001b[0m | \u001b[95m 0.03396 \u001b[0m | \u001b[95m 0.08815 \u001b[0m | \u001b[95m 5.266   \u001b[0m | \u001b[95m 470.4   \u001b[0m | \u001b[95m 29.83   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1786  \u001b[0m | \u001b[0m 0.9012  \u001b[0m | \u001b[0m 0.2099  \u001b[0m | \u001b[0m 0.3084  \u001b[0m | \u001b[0m 0.1794  \u001b[0m | \u001b[0m 4.745   \u001b[0m | \u001b[0m 474.3   \u001b[0m | \u001b[0m 24.49   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2146  \u001b[0m | \u001b[0m 0.8115  \u001b[0m | \u001b[0m 0.7408  \u001b[0m | \u001b[0m 0.7972  \u001b[0m | \u001b[0m 0.3592  \u001b[0m | \u001b[0m 8.13    \u001b[0m | \u001b[0m 463.8   \u001b[0m | \u001b[0m 23.34   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.9643  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 6.213   \u001b[0m | \u001b[0m 476.0   \u001b[0m | \u001b[0m 31.78   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1765  \u001b[0m | \u001b[0m 0.5845  \u001b[0m | \u001b[0m 0.2744  \u001b[0m | \u001b[0m 0.5184  \u001b[0m | \u001b[0m 0.1783  \u001b[0m | \u001b[0m 2.804   \u001b[0m | \u001b[0m 467.8   \u001b[0m | \u001b[0m 27.05   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1759  \u001b[0m | \u001b[0m 0.8202  \u001b[0m | \u001b[0m 0.05268 \u001b[0m | \u001b[0m 0.9972  \u001b[0m | \u001b[0m 0.1432  \u001b[0m | \u001b[0m 14.92   \u001b[0m | \u001b[0m 469.1   \u001b[0m | \u001b[0m 29.04   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2313  \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 0.7699  \u001b[0m | \u001b[0m 0.7385  \u001b[0m | \u001b[0m 0.4304  \u001b[0m | \u001b[0m 10.19   \u001b[0m | \u001b[0m 466.6   \u001b[0m | \u001b[0m 27.07   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2169  \u001b[0m | \u001b[0m 0.3667  \u001b[0m | \u001b[0m 0.02213 \u001b[0m | \u001b[0m 0.1958  \u001b[0m | \u001b[0m 0.3968  \u001b[0m | \u001b[0m 5.133   \u001b[0m | \u001b[0m 472.4   \u001b[0m | \u001b[0m 19.96   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1869  \u001b[0m | \u001b[0m 0.923   \u001b[0m | \u001b[0m 0.3188  \u001b[0m | \u001b[0m 0.5065  \u001b[0m | \u001b[0m 0.205   \u001b[0m | \u001b[0m 8.271   \u001b[0m | \u001b[0m 827.6   \u001b[0m | \u001b[0m 146.8   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1989  \u001b[0m | \u001b[0m 0.4496  \u001b[0m | \u001b[0m 0.9184  \u001b[0m | \u001b[0m 0.09983 \u001b[0m | \u001b[0m 0.2689  \u001b[0m | \u001b[0m 19.24   \u001b[0m | \u001b[0m 475.9   \u001b[0m | \u001b[0m 25.14   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1726  \u001b[0m | \u001b[0m 0.3193  \u001b[0m | \u001b[0m 0.8502  \u001b[0m | \u001b[0m 0.5868  \u001b[0m | \u001b[0m 0.09619 \u001b[0m | \u001b[0m 9.96    \u001b[0m | \u001b[0m 474.8   \u001b[0m | \u001b[0m 21.16   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.2508  \u001b[0m | \u001b[0m 0.1976  \u001b[0m | \u001b[0m 0.6803  \u001b[0m | \u001b[0m 0.8457  \u001b[0m | \u001b[0m 0.4398  \u001b[0m | \u001b[0m 5.154   \u001b[0m | \u001b[0m 823.7   \u001b[0m | \u001b[0m 142.9   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1704  \u001b[0m | \u001b[0m 0.535   \u001b[0m | \u001b[0m 0.27    \u001b[0m | \u001b[0m 0.3436  \u001b[0m | \u001b[0m 0.1005  \u001b[0m | \u001b[0m 5.325   \u001b[0m | \u001b[0m 465.0   \u001b[0m | \u001b[0m 33.45   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1745  \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 0.9007  \u001b[0m | \u001b[0m 0.18    \u001b[0m | \u001b[0m 0.1303  \u001b[0m | \u001b[0m 11.38   \u001b[0m | \u001b[0m 465.8   \u001b[0m | \u001b[0m 32.7    \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.178   \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 0.435   \u001b[0m | \u001b[0m 0.6741  \u001b[0m | \u001b[0m 0.1503  \u001b[0m | \u001b[0m 19.57   \u001b[0m | \u001b[0m 466.2   \u001b[0m | \u001b[0m 31.83   \u001b[0m |\n",
      "| \u001b[95m 28      \u001b[0m | \u001b[95m-0.1658  \u001b[0m | \u001b[95m 0.9232  \u001b[0m | \u001b[95m 0.6392  \u001b[0m | \u001b[95m 0.8771  \u001b[0m | \u001b[95m 0.06368 \u001b[0m | \u001b[95m 13.51   \u001b[0m | \u001b[95m 478.6   \u001b[0m | \u001b[95m 23.11   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1701  \u001b[0m | \u001b[0m 0.7059  \u001b[0m | \u001b[0m 0.02212 \u001b[0m | \u001b[0m 0.3852  \u001b[0m | \u001b[0m 0.09379 \u001b[0m | \u001b[0m 5.161   \u001b[0m | \u001b[0m 835.3   \u001b[0m | \u001b[0m 142.6   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1898  \u001b[0m | \u001b[0m 0.3119  \u001b[0m | \u001b[0m 0.49    \u001b[0m | \u001b[0m 0.4711  \u001b[0m | \u001b[0m 0.1958  \u001b[0m | \u001b[0m 9.31    \u001b[0m | \u001b[0m 833.5   \u001b[0m | \u001b[0m 144.3   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes: 100%|██████████| 3/3 [20:44<00:00, 414.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run the Bayesian optimizer, in parallel, for each cluster\n",
    "with tqdm_joblib(tqdm(desc=\"TSFeat LGBM Models Bayes\", \n",
    "                      total=len(train_df_tsfeat_clust_ls))) as progress_bar:\n",
    "    tsfeat_clust_mods_bayes = Parallel(n_jobs=3)(delayed(optimize_lgbm_w_bayes)(train_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                 train_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                                 val_df_tsfeat_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                                 val_df_tsfeat_clust_ls[i].iloc[:,0]) for i in range(len(train_df_tsfeat_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "7668d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each set of params returned by the optimizer, convert the required parameters to integers\n",
    "for n in range(len(tsfeat_clust_mods_bayes)):\n",
    "    tsfeat_clust_mods_bayes[n][\"max_depth\"] = int(round(tsfeat_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    tsfeat_clust_mods_bayes[n][\"n_estimators\"] = int(round(tsfeat_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    tsfeat_clust_mods_bayes[n][\"num_leaves\"] = int(round(tsfeat_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "44553050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train_val df into a list of data frames, one df per cluster\n",
    "train_val_df_tsfeat_clust_ls = [df.reset_index(drop=True) for _,df in train_val_df_full_tsfeat.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "8b0bc810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes Final: 100%|██████████| 3/3 [01:51<00:00, 37.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# In parallel, fit a model to each train_val df using the params found by the Bayesian optimizer\n",
    "with tqdm_joblib(tqdm(desc=\"TSFeat LGBM Models Bayes Final\", \n",
    "                      total=len(tsfeat_clust_mods_bayes))) as progress_bar:\n",
    "    tsfeat_clust_mods_bayes_final = Parallel(n_jobs=3)(delayed(train_lgbm)(tsfeat_clust_mods_bayes[i], \n",
    "                                                                            train_val_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                            train_val_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(tsfeat_clust_mods_bayes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d24415aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save those models to files\n",
    "for model_no in range(len(tsfeat_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/TSFeat KMeans/model_{model_no}\"\n",
    "    joblib.dump(tsfeat_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a4d347f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes Residuals: 100%|██████████| 3/3 [00:13<00:00,  4.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each model, compute the residuals and save the results into a list\n",
    "with tqdm_joblib(tqdm(desc=\"TSFeat LGBM Models Bayes Residuals\", \n",
    "                      total=len(tsfeat_clust_mods_bayes_final))) as progress_bar:\n",
    "    tsfeat_clust_mods_bayes_resid = Parallel(n_jobs=3)(delayed(compute_lgbm_residuals)(tsfeat_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(tsfeat_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "98d38c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test df into a list of data frames as well, one df per cluster\n",
    "test_df_full_tsfeat_clust_ls = [df.reset_index(drop=True) for _,df in test_df_full_tsfeat.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "35d42486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "TSFeat LGBM Models Bayes Test Preds:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1312  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1308  \u001b[0m | \u001b[95m 0.7999  \u001b[0m | \u001b[95m 0.4889  \u001b[0m | \u001b[95m 0.05053 \u001b[0m | \u001b[95m 0.2692  \u001b[0m | \u001b[95m 2.954   \u001b[0m | \u001b[95m 827.3   \u001b[0m | \u001b[95m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1465  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1657  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1421  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1404  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.1301  \u001b[0m | \u001b[95m 0.2156  \u001b[0m | \u001b[95m 0.3367  \u001b[0m | \u001b[95m 0.7178  \u001b[0m | \u001b[95m 0.0614  \u001b[0m | \u001b[95m 13.95   \u001b[0m | \u001b[95m 470.8   \u001b[0m | \u001b[95m 26.37   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1608  \u001b[0m | \u001b[0m 0.1855  \u001b[0m | \u001b[0m 0.0744  \u001b[0m | \u001b[0m 0.6661  \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 6.813   \u001b[0m | \u001b[0m 822.9   \u001b[0m | \u001b[0m 145.8   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.1294  \u001b[0m | \u001b[95m 0.7265  \u001b[0m | \u001b[95m 0.6488  \u001b[0m | \u001b[95m 0.2739  \u001b[0m | \u001b[95m 0.1655  \u001b[0m | \u001b[95m 12.84   \u001b[0m | \u001b[95m 469.5   \u001b[0m | \u001b[95m 23.2    \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.1262  \u001b[0m | \u001b[95m 0.9591  \u001b[0m | \u001b[95m 0.1986  \u001b[0m | \u001b[95m 0.1924  \u001b[0m | \u001b[95m 0.08383 \u001b[0m | \u001b[95m 9.679   \u001b[0m | \u001b[95m 471.5   \u001b[0m | \u001b[95m 26.8    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1426  \u001b[0m | \u001b[0m 0.472   \u001b[0m | \u001b[0m 0.211   \u001b[0m | \u001b[0m 0.1864  \u001b[0m | \u001b[0m 0.329   \u001b[0m | \u001b[0m 9.093   \u001b[0m | \u001b[0m 466.3   \u001b[0m | \u001b[0m 29.58   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1463  \u001b[0m | \u001b[0m 0.3691  \u001b[0m | \u001b[0m 0.7864  \u001b[0m | \u001b[0m 0.01713 \u001b[0m | \u001b[0m 0.3966  \u001b[0m | \u001b[0m 8.091   \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 23.3    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1357  \u001b[0m | \u001b[0m 0.2674  \u001b[0m | \u001b[0m 0.1844  \u001b[0m | \u001b[0m 0.6308  \u001b[0m | \u001b[0m 0.2563  \u001b[0m | \u001b[0m 15.66   \u001b[0m | \u001b[0m 466.5   \u001b[0m | \u001b[0m 21.68   \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.126   \u001b[0m | \u001b[95m 0.8496  \u001b[0m | \u001b[95m 0.1415  \u001b[0m | \u001b[95m 0.4193  \u001b[0m | \u001b[95m 0.0886  \u001b[0m | \u001b[95m 7.307   \u001b[0m | \u001b[95m 476.2   \u001b[0m | \u001b[95m 29.77   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1428  \u001b[0m | \u001b[0m 0.9849  \u001b[0m | \u001b[0m 0.6193  \u001b[0m | \u001b[0m 0.2947  \u001b[0m | \u001b[0m 0.3759  \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 476.3   \u001b[0m | \u001b[0m 27.44   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.043   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 8.451   \u001b[0m | \u001b[0m 472.8   \u001b[0m | \u001b[0m 30.45   \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m-0.1248  \u001b[0m | \u001b[95m 0.8052  \u001b[0m | \u001b[95m 0.02218 \u001b[0m | \u001b[95m 0.3386  \u001b[0m | \u001b[95m 0.01644 \u001b[0m | \u001b[95m 6.66    \u001b[0m | \u001b[95m 961.6   \u001b[0m | \u001b[95m 63.49   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1261  \u001b[0m | \u001b[0m 0.8973  \u001b[0m | \u001b[0m 0.531   \u001b[0m | \u001b[0m 0.2387  \u001b[0m | \u001b[0m 0.08109 \u001b[0m | \u001b[0m 11.57   \u001b[0m | \u001b[0m 475.3   \u001b[0m | \u001b[0m 28.99   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1279  \u001b[0m | \u001b[0m 0.4944  \u001b[0m | \u001b[0m 0.3307  \u001b[0m | \u001b[0m 0.4453  \u001b[0m | \u001b[0m 0.03993 \u001b[0m | \u001b[0m 16.18   \u001b[0m | \u001b[0m 472.7   \u001b[0m | \u001b[0m 25.08   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1337  \u001b[0m | \u001b[0m 0.1942  \u001b[0m | \u001b[0m 0.1678  \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.2678  \u001b[0m | \u001b[0m 3.474   \u001b[0m | \u001b[0m 827.0   \u001b[0m | \u001b[0m 147.3   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1278  \u001b[0m | \u001b[0m 0.6222  \u001b[0m | \u001b[0m 0.4823  \u001b[0m | \u001b[0m 0.2792  \u001b[0m | \u001b[0m 0.1363  \u001b[0m | \u001b[0m 10.93   \u001b[0m | \u001b[0m 476.9   \u001b[0m | \u001b[0m 26.34   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1311  \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 0.8094  \u001b[0m | \u001b[0m 0.2867  \u001b[0m | \u001b[0m 0.188   \u001b[0m | \u001b[0m 13.82   \u001b[0m | \u001b[0m 473.7   \u001b[0m | \u001b[0m 26.72   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1307  \u001b[0m | \u001b[0m 0.4321  \u001b[0m | \u001b[0m 0.03347 \u001b[0m | \u001b[0m 0.9627  \u001b[0m | \u001b[0m 0.1894  \u001b[0m | \u001b[0m 17.2    \u001b[0m | \u001b[0m 475.4   \u001b[0m | \u001b[0m 23.44   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.134   \u001b[0m | \u001b[0m 0.7482  \u001b[0m | \u001b[0m 0.6901  \u001b[0m | \u001b[0m 0.916   \u001b[0m | \u001b[0m 0.2831  \u001b[0m | \u001b[0m 17.15   \u001b[0m | \u001b[0m 474.7   \u001b[0m | \u001b[0m 27.44   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1302  \u001b[0m | \u001b[0m 0.4751  \u001b[0m | \u001b[0m 8.326e-0\u001b[0m | \u001b[0m 0.3395  \u001b[0m | \u001b[0m 0.1558  \u001b[0m | \u001b[0m 10.15   \u001b[0m | \u001b[0m 479.5   \u001b[0m | \u001b[0m 30.05   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1546  \u001b[0m | \u001b[0m 0.5609  \u001b[0m | \u001b[0m 0.5636  \u001b[0m | \u001b[0m 0.1198  \u001b[0m | \u001b[0m 0.4826  \u001b[0m | \u001b[0m 8.073   \u001b[0m | \u001b[0m 478.0   \u001b[0m | \u001b[0m 25.55   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1389  \u001b[0m | \u001b[0m 0.6416  \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 0.3494  \u001b[0m | \u001b[0m 0.3292  \u001b[0m | \u001b[0m 7.29    \u001b[0m | \u001b[0m 479.5   \u001b[0m | \u001b[0m 28.66   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1271  \u001b[0m | \u001b[0m 0.6514  \u001b[0m | \u001b[0m 0.428   \u001b[0m | \u001b[0m 0.7843  \u001b[0m | \u001b[0m 0.07997 \u001b[0m | \u001b[0m 9.17    \u001b[0m | \u001b[0m 469.3   \u001b[0m | \u001b[0m 24.92   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.133   \u001b[0m | \u001b[0m 0.7739  \u001b[0m | \u001b[0m 0.6988  \u001b[0m | \u001b[0m 0.4069  \u001b[0m | \u001b[0m 0.256   \u001b[0m | \u001b[0m 17.37   \u001b[0m | \u001b[0m 474.1   \u001b[0m | \u001b[0m 20.48   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1302  \u001b[0m | \u001b[0m 0.2418  \u001b[0m | \u001b[0m 0.734   \u001b[0m | \u001b[0m 0.6067  \u001b[0m | \u001b[0m 0.1081  \u001b[0m | \u001b[0m 12.09   \u001b[0m | \u001b[0m 465.7   \u001b[0m | \u001b[0m 26.71   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.022180210537899203, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.022180210537899203\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3385936068772376, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3385936068772376\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6391604515075964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6391604515075964\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8771432357235897, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8771432357235897\n",
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1318  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1311  \u001b[0m | \u001b[95m 0.7999  \u001b[0m | \u001b[95m 0.4889  \u001b[0m | \u001b[95m 0.05053 \u001b[0m | \u001b[95m 0.2692  \u001b[0m | \u001b[95m 2.954   \u001b[0m | \u001b[95m 827.3   \u001b[0m | \u001b[95m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1456  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1602  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1408  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1377  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1375  \u001b[0m | \u001b[0m 0.7862  \u001b[0m | \u001b[0m 0.2396  \u001b[0m | \u001b[0m 0.6049  \u001b[0m | \u001b[0m 0.3277  \u001b[0m | \u001b[0m 7.432   \u001b[0m | \u001b[0m 473.9   \u001b[0m | \u001b[0m 22.69   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.16    \u001b[0m | \u001b[0m 0.1855  \u001b[0m | \u001b[0m 0.0744  \u001b[0m | \u001b[0m 0.6661  \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 6.813   \u001b[0m | \u001b[0m 822.9   \u001b[0m | \u001b[0m 145.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1439  \u001b[0m | \u001b[0m 0.3771  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.3656  \u001b[0m | \u001b[0m 0.399   \u001b[0m | \u001b[0m 11.8    \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 20.04   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.1267  \u001b[0m | \u001b[95m 0.9591  \u001b[0m | \u001b[95m 0.1986  \u001b[0m | \u001b[95m 0.1924  \u001b[0m | \u001b[95m 0.08383 \u001b[0m | \u001b[95m 9.679   \u001b[0m | \u001b[95m 471.5   \u001b[0m | \u001b[95m 26.8    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1289  \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.2281  \u001b[0m | \u001b[0m 0.4638  \u001b[0m | \u001b[0m 0.01206 \u001b[0m | \u001b[0m 12.72   \u001b[0m | \u001b[0m 468.8   \u001b[0m | \u001b[0m 26.12   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1288  \u001b[0m | \u001b[0m 0.6713  \u001b[0m | \u001b[0m 0.4853  \u001b[0m | \u001b[0m 0.7558  \u001b[0m | \u001b[0m 0.1096  \u001b[0m | \u001b[0m 16.73   \u001b[0m | \u001b[0m 471.9   \u001b[0m | \u001b[0m 27.24   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1297  \u001b[0m | \u001b[0m 0.3714  \u001b[0m | \u001b[0m 0.6943  \u001b[0m | \u001b[0m 0.03396 \u001b[0m | \u001b[0m 0.08815 \u001b[0m | \u001b[0m 5.266   \u001b[0m | \u001b[0m 470.4   \u001b[0m | \u001b[0m 29.83   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.127   \u001b[0m | \u001b[0m 0.7327  \u001b[0m | \u001b[0m 0.3213  \u001b[0m | \u001b[0m 0.451   \u001b[0m | \u001b[0m 0.07224 \u001b[0m | \u001b[0m 10.52   \u001b[0m | \u001b[0m 477.8   \u001b[0m | \u001b[0m 28.91   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1301  \u001b[0m | \u001b[0m 0.5513  \u001b[0m | \u001b[0m 0.1443  \u001b[0m | \u001b[0m 0.03297 \u001b[0m | \u001b[0m 0.1204  \u001b[0m | \u001b[0m 14.76   \u001b[0m | \u001b[0m 473.2   \u001b[0m | \u001b[0m 33.4    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1431  \u001b[0m | \u001b[0m 0.5503  \u001b[0m | \u001b[0m 0.9942  \u001b[0m | \u001b[0m 0.433   \u001b[0m | \u001b[0m 0.3291  \u001b[0m | \u001b[0m 18.92   \u001b[0m | \u001b[0m 479.4   \u001b[0m | \u001b[0m 29.93   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1368  \u001b[0m | \u001b[0m 0.888   \u001b[0m | \u001b[0m 0.8694  \u001b[0m | \u001b[0m 0.7563  \u001b[0m | \u001b[0m 0.3033  \u001b[0m | \u001b[0m 10.15   \u001b[0m | \u001b[0m 473.7   \u001b[0m | \u001b[0m 30.37   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1301  \u001b[0m | \u001b[0m 0.9784  \u001b[0m | \u001b[0m 0.9119  \u001b[0m | \u001b[0m 0.6658  \u001b[0m | \u001b[0m 0.2048  \u001b[0m | \u001b[0m 8.386   \u001b[0m | \u001b[0m 481.1   \u001b[0m | \u001b[0m 29.26   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.143   \u001b[0m | \u001b[0m 0.5746  \u001b[0m | \u001b[0m 0.289   \u001b[0m | \u001b[0m 0.02813 \u001b[0m | \u001b[0m 0.3797  \u001b[0m | \u001b[0m 21.54   \u001b[0m | \u001b[0m 469.5   \u001b[0m | \u001b[0m 23.56   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1577  \u001b[0m | \u001b[0m 0.408   \u001b[0m | \u001b[0m 0.3347  \u001b[0m | \u001b[0m 0.3979  \u001b[0m | \u001b[0m 0.4518  \u001b[0m | \u001b[0m 16.38   \u001b[0m | \u001b[0m 466.6   \u001b[0m | \u001b[0m 32.29   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1511  \u001b[0m | \u001b[0m 0.1226  \u001b[0m | \u001b[0m 0.4517  \u001b[0m | \u001b[0m 0.1313  \u001b[0m | \u001b[0m 0.305   \u001b[0m | \u001b[0m 8.722   \u001b[0m | \u001b[0m 467.5   \u001b[0m | \u001b[0m 27.88   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1306  \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 0.8094  \u001b[0m | \u001b[0m 0.2867  \u001b[0m | \u001b[0m 0.188   \u001b[0m | \u001b[0m 13.82   \u001b[0m | \u001b[0m 473.7   \u001b[0m | \u001b[0m 26.72   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1541  \u001b[0m | \u001b[0m 0.2617  \u001b[0m | \u001b[0m 0.9828  \u001b[0m | \u001b[0m 0.1158  \u001b[0m | \u001b[0m 0.4229  \u001b[0m | \u001b[0m 9.818   \u001b[0m | \u001b[0m 478.3   \u001b[0m | \u001b[0m 25.85   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1354  \u001b[0m | \u001b[0m 0.1239  \u001b[0m | \u001b[0m 0.2185  \u001b[0m | \u001b[0m 0.5048  \u001b[0m | \u001b[0m 0.03632 \u001b[0m | \u001b[0m 12.02   \u001b[0m | \u001b[0m 477.6   \u001b[0m | \u001b[0m 30.83   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.132   \u001b[0m | \u001b[0m 0.4751  \u001b[0m | \u001b[0m 8.326e-0\u001b[0m | \u001b[0m 0.3395  \u001b[0m | \u001b[0m 0.1558  \u001b[0m | \u001b[0m 10.15   \u001b[0m | \u001b[0m 479.5   \u001b[0m | \u001b[0m 30.05   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1274  \u001b[0m | \u001b[0m 0.7345  \u001b[0m | \u001b[0m 0.7755  \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 0.1235  \u001b[0m | \u001b[0m 19.03   \u001b[0m | \u001b[0m 472.8   \u001b[0m | \u001b[0m 29.46   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1357  \u001b[0m | \u001b[0m 0.4891  \u001b[0m | \u001b[0m 0.3583  \u001b[0m | \u001b[0m 0.758   \u001b[0m | \u001b[0m 0.238   \u001b[0m | \u001b[0m 15.2    \u001b[0m | \u001b[0m 476.2   \u001b[0m | \u001b[0m 27.37   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1459  \u001b[0m | \u001b[0m 0.4295  \u001b[0m | \u001b[0m 0.5138  \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 0.3808  \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 471.2   \u001b[0m | \u001b[0m 24.53   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1423  \u001b[0m | \u001b[0m 0.7537  \u001b[0m | \u001b[0m 0.2433  \u001b[0m | \u001b[0m 0.217   \u001b[0m | \u001b[0m 0.3703  \u001b[0m | \u001b[0m 8.024   \u001b[0m | \u001b[0m 474.0   \u001b[0m | \u001b[0m 26.5    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.175   \u001b[0m | \u001b[0m 0.1245  \u001b[0m | \u001b[0m 0.9863  \u001b[0m | \u001b[0m 0.9103  \u001b[0m | \u001b[0m 0.4904  \u001b[0m | \u001b[0m 20.26   \u001b[0m | \u001b[0m 474.6   \u001b[0m | \u001b[0m 28.81   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19859083221957885, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19859083221957885\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19237149168315193, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19237149168315193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes Test Preds: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the models and test data frames and compute the test predictions\n",
    "with tqdm_joblib(tqdm(desc=\"TSFeat LGBM Models Bayes Test Preds\", \n",
    "                      total=len(tsfeat_clust_mods_bayes_final))) as progress_bar:\n",
    "    tsfeat_clust_mods_bayes_test_preds = Parallel(n_jobs=3)(delayed(compute_lgbm_test_preds)(tsfeat_clust_mods_bayes_final[i],\n",
    "                                                                                           test_df_full_tsfeat_clust_ls[i],\n",
    "                                                                                           lag_n\n",
    "                                                                                          ) for i in range(len(tsfeat_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "013e2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame to which the test preds from each cluster are appened\n",
    "tsfeat_clust_bayes_test_preds_df = pd.DataFrame()\n",
    "for clust_test_pred_df in tsfeat_clust_mods_bayes_test_preds:\n",
    "    tsfeat_clust_bayes_test_preds_df = tsfeat_clust_bayes_test_preds_df.append(clust_test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "f0117227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test pred performance\n",
    "tsfeat_clust_bayes_test_perf = compute_lgbm_test_perf(tsfeat_clust_bayes_test_preds_df,\n",
    "                                                       test_df_full_tsfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "0e248cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized performance metrics\n",
    "tsfeat_clust_bayes_test_perf['nrmse'] = tsfeat_clust_bayes_test_perf['rmse']/tsfeat_clust_bayes_test_perf['mean']\n",
    "tsfeat_clust_bayes_test_perf['smae'] = tsfeat_clust_bayes_test_perf['mae']/tsfeat_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "5d403f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      30.711607\n",
       "mae       20.331793\n",
       "mean     265.435072\n",
       "nrmse      0.139024\n",
       "smae       0.093969\n",
       "dtype: float64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the normalized performance metrics\n",
    "tsfeat_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "8c2695a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d3d3f77a064db1900198165c73bf13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/41664 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36d44e9362149129e1743eaed855fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/51072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d55b4c3c07b42369e100bab34f48c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each model/cluster, compute the PIs for the test preds via residual bootstrap. \n",
    "# Save the resulting data frames to a list\n",
    "tsfeat_clust_test_pred_int = list()\n",
    "for i in range(len(tsfeat_clust_mods_bayes_test_preds)):\n",
    "    tsfeat_clust_test_pred_int.append(compute_lgbm_boostrap_int(tsfeat_clust_mods_bayes_test_preds[i], \n",
    "                                                                 tsfeat_clust_mods_bayes_resid[i], \n",
    "                                                                 n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "db1a9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each PI data frame, grab the true value of the target for that cluster and add a df column for the true data\n",
    "for n in range(1, len(tsfeat_clust_test_pred_int)+1):\n",
    "    y_actual_sub = test_df_full_tsfeat.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    tsfeat_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "1af7775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all PI data frames into one\n",
    "tsfeat_clust_test_pred_int_df = pd.DataFrame()\n",
    "for clust_test_pred_int_df in tsfeat_clust_test_pred_int:\n",
    "    tsfeat_clust_test_pred_int_df = tsfeat_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "3e7a0c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the interval scores for each observation in that one df\n",
    "tsfeat_clust_test_pred_int_df['int_95_score'] = interval_score(tsfeat_clust_test_pred_int_df['actual'],\n",
    "                                                                tsfeat_clust_test_pred_int_df['lo_95'],\n",
    "                                                                tsfeat_clust_test_pred_int_df['hi_95'],\n",
    "                                                                0.95\n",
    "                                                               )\n",
    "\n",
    "tsfeat_clust_test_pred_int_df['int_80_score'] = interval_score(tsfeat_clust_test_pred_int_df['actual'],\n",
    "                                                                tsfeat_clust_test_pred_int_df['lo_80'],\n",
    "                                                                tsfeat_clust_test_pred_int_df['hi_80'],\n",
    "                                                                0.80\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "82c18a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.602405\n",
       "lo_95           210.787509\n",
       "hi_95           322.123643\n",
       "lo_80           237.905332\n",
       "hi_80           294.067204\n",
       "actual          265.435072\n",
       "int_95_score    225.888255\n",
       "int_80_score    121.427276\n",
       "dtype: float64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean PI scores\n",
    "tsfeat_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e4b341d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI df to a csv file\n",
    "tsfeat_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/TSFeat KMeans/test_pred_intervals.csv\",\n",
    "                                     index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b1fd1",
   "metadata": {},
   "source": [
    "# Train and Test - DTW Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "a688f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete variable which will no longer be used\n",
    "del tsfeat_clust_test_pred_int_df\n",
    "del tsfeat_clust_test_pred_int\n",
    "del clust_test_pred_int_df\n",
    "del y_actual_sub\n",
    "del tsfeat_clust_bayes_test_perf\n",
    "del tsfeat_clust_bayes_test_preds_df\n",
    "del clust_test_pred_df\n",
    "del tsfeat_clust_mods_bayes_test_preds\n",
    "del test_df_full_tsfeat_clust_ls\n",
    "del test_df_full_tsfeat\n",
    "del tsfeat_clust_mods_bayes_resid\n",
    "del tsfeat_clust_mods_bayes_final\n",
    "del train_val_df_tsfeat_clust_ls\n",
    "del train_val_df_full_tsfeat\n",
    "del tsfeat_clust_mods_bayes\n",
    "del train_df_tsfeat_clust_ls\n",
    "del val_df_tsfeat_clust_ls \n",
    "del train_df_full_tsfeat\n",
    "del val_df_full_tsfeat\n",
    "del tsfeat_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "010b7463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the garbage collector to ensure we are freeing up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "c36b9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cluster assignments for the DTW based clusters\n",
    "dtw_clust = pd.read_csv(\"Results/Clustering/DTW/dtw_clustering_assign.csv\")\n",
    "dtw_clust['cluster'] =  dtw_clust['dtw_clust_assign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "fc9798c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train, val, train_val, and test data with cluster assignments\n",
    "train_df_full_dtw = train_df_full.merge(dtw_clust, on=\"ts_index\")\n",
    "val_df_full_dtw = val_df_full.merge(dtw_clust, on=\"ts_index\")\n",
    "train_val_df_full_dtw = train_val_df_full.merge(dtw_clust, on=\"ts_index\")\n",
    "test_df_full_dtw = test_df_full.merge(dtw_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "9132f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the above data frames into lists of data frames where there is one df per cluster\n",
    "train_df_dtw_clust_ls = [df.reset_index(drop=True) for _,df in train_df_full_dtw.groupby(\"cluster\")]\n",
    "val_df_dtw_clust_ls = [df.reset_index(drop=True) for _,df in val_df_full_dtw.groupby(\"cluster\")]\n",
    "train_val_df_dtw_clust_ls = [df.reset_index(drop=True) for _,df in train_val_df_full_dtw.groupby(\"cluster\")]\n",
    "test_df_full_dtw_clust_ls = [df.reset_index(drop=True) for _,df in test_df_full_dtw.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "2a0fdd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes:  50%|█████     | 1/2 [12:38<12:38, 758.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1062  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1053  \u001b[0m | \u001b[95m 0.7999  \u001b[0m | \u001b[95m 0.4889  \u001b[0m | \u001b[95m 0.05053 \u001b[0m | \u001b[95m 0.2692  \u001b[0m | \u001b[95m 2.954   \u001b[0m | \u001b[95m 827.3   \u001b[0m | \u001b[95m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1186  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1347  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1158  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1117  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.112   \u001b[0m | \u001b[0m 0.7862  \u001b[0m | \u001b[0m 0.2396  \u001b[0m | \u001b[0m 0.6049  \u001b[0m | \u001b[0m 0.3277  \u001b[0m | \u001b[0m 7.432   \u001b[0m | \u001b[0m 473.9   \u001b[0m | \u001b[0m 22.69   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1345  \u001b[0m | \u001b[0m 0.1855  \u001b[0m | \u001b[0m 0.0744  \u001b[0m | \u001b[0m 0.6661  \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 6.813   \u001b[0m | \u001b[0m 822.9   \u001b[0m | \u001b[0m 145.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1162  \u001b[0m | \u001b[0m 0.3771  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.3656  \u001b[0m | \u001b[0m 0.399   \u001b[0m | \u001b[0m 11.8    \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 20.04   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.1017  \u001b[0m | \u001b[95m 0.9591  \u001b[0m | \u001b[95m 0.1986  \u001b[0m | \u001b[95m 0.1924  \u001b[0m | \u001b[95m 0.08383 \u001b[0m | \u001b[95m 9.679   \u001b[0m | \u001b[95m 471.5   \u001b[0m | \u001b[95m 26.8    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1038  \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.2281  \u001b[0m | \u001b[0m 0.4638  \u001b[0m | \u001b[0m 0.01206 \u001b[0m | \u001b[0m 12.72   \u001b[0m | \u001b[0m 468.8   \u001b[0m | \u001b[0m 26.12   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1034  \u001b[0m | \u001b[0m 0.6713  \u001b[0m | \u001b[0m 0.4853  \u001b[0m | \u001b[0m 0.7558  \u001b[0m | \u001b[0m 0.1096  \u001b[0m | \u001b[0m 16.73   \u001b[0m | \u001b[0m 471.9   \u001b[0m | \u001b[0m 27.24   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1038  \u001b[0m | \u001b[0m 0.3714  \u001b[0m | \u001b[0m 0.6943  \u001b[0m | \u001b[0m 0.03396 \u001b[0m | \u001b[0m 0.08815 \u001b[0m | \u001b[0m 5.266   \u001b[0m | \u001b[0m 470.4   \u001b[0m | \u001b[0m 29.83   \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.1016  \u001b[0m | \u001b[95m 0.7327  \u001b[0m | \u001b[95m 0.3213  \u001b[0m | \u001b[95m 0.451   \u001b[0m | \u001b[95m 0.07224 \u001b[0m | \u001b[95m 10.52   \u001b[0m | \u001b[95m 477.8   \u001b[0m | \u001b[95m 28.91   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1056  \u001b[0m | \u001b[0m 0.5513  \u001b[0m | \u001b[0m 0.1443  \u001b[0m | \u001b[0m 0.03297 \u001b[0m | \u001b[0m 0.1204  \u001b[0m | \u001b[0m 14.76   \u001b[0m | \u001b[0m 473.2   \u001b[0m | \u001b[0m 33.4    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1072  \u001b[0m | \u001b[0m 0.5561  \u001b[0m | \u001b[0m 0.2134  \u001b[0m | \u001b[0m 0.5187  \u001b[0m | \u001b[0m 0.02851 \u001b[0m | \u001b[0m 3.242   \u001b[0m | \u001b[0m 476.4   \u001b[0m | \u001b[0m 36.88   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1209  \u001b[0m | \u001b[0m 0.4771  \u001b[0m | \u001b[0m 0.7687  \u001b[0m | \u001b[0m 0.7201  \u001b[0m | \u001b[0m 0.005915\u001b[0m | \u001b[0m 9.767   \u001b[0m | \u001b[0m 483.3   \u001b[0m | \u001b[0m 32.84   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1091  \u001b[0m | \u001b[0m 0.154   \u001b[0m | \u001b[0m 0.7117  \u001b[0m | \u001b[0m 0.2027  \u001b[0m | \u001b[0m 0.06436 \u001b[0m | \u001b[0m 8.336   \u001b[0m | \u001b[0m 470.2   \u001b[0m | \u001b[0m 35.98   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1031  \u001b[0m | \u001b[0m 0.6389  \u001b[0m | \u001b[0m 0.04805 \u001b[0m | \u001b[0m 0.8311  \u001b[0m | \u001b[0m 0.02567 \u001b[0m | \u001b[0m 18.6    \u001b[0m | \u001b[0m 477.8   \u001b[0m | \u001b[0m 28.88   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1087  \u001b[0m | \u001b[0m 0.3299  \u001b[0m | \u001b[0m 0.4504  \u001b[0m | \u001b[0m 0.3306  \u001b[0m | \u001b[0m 0.2092  \u001b[0m | \u001b[0m 24.4    \u001b[0m | \u001b[0m 475.7   \u001b[0m | \u001b[0m 21.68   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1108  \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 0.6214  \u001b[0m | \u001b[0m 0.988   \u001b[0m | \u001b[0m 0.2937  \u001b[0m | \u001b[0m 22.06   \u001b[0m | \u001b[0m 465.9   \u001b[0m | \u001b[0m 24.44   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.7431  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 21.65   \u001b[0m | \u001b[0m 483.7   \u001b[0m | \u001b[0m 25.35   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1094  \u001b[0m | \u001b[0m 0.3995  \u001b[0m | \u001b[0m 0.3116  \u001b[0m | \u001b[0m 0.1618  \u001b[0m | \u001b[0m 0.3252  \u001b[0m | \u001b[0m 23.3    \u001b[0m | \u001b[0m 473.4   \u001b[0m | \u001b[0m 12.79   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1124  \u001b[0m | \u001b[0m 0.142   \u001b[0m | \u001b[0m 0.3418  \u001b[0m | \u001b[0m 0.5062  \u001b[0m | \u001b[0m 0.2697  \u001b[0m | \u001b[0m 24.85   \u001b[0m | \u001b[0m 473.3   \u001b[0m | \u001b[0m 35.27   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1043  \u001b[0m | \u001b[0m 0.6969  \u001b[0m | \u001b[0m 0.5188  \u001b[0m | \u001b[0m 0.4917  \u001b[0m | \u001b[0m 0.1898  \u001b[0m | \u001b[0m 17.63   \u001b[0m | \u001b[0m 460.2   \u001b[0m | \u001b[0m 15.48   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1072  \u001b[0m | \u001b[0m 0.2214  \u001b[0m | \u001b[0m 0.2257  \u001b[0m | \u001b[0m 0.3428  \u001b[0m | \u001b[0m 0.191   \u001b[0m | \u001b[0m 6.038   \u001b[0m | \u001b[0m 461.9   \u001b[0m | \u001b[0m 18.6    \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1059  \u001b[0m | \u001b[0m 0.5249  \u001b[0m | \u001b[0m 0.4119  \u001b[0m | \u001b[0m 0.1269  \u001b[0m | \u001b[0m 0.219   \u001b[0m | \u001b[0m 4.167   \u001b[0m | \u001b[0m 458.1   \u001b[0m | \u001b[0m 30.09   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1098  \u001b[0m | \u001b[0m 0.9775  \u001b[0m | \u001b[0m 0.441   \u001b[0m | \u001b[0m 0.0103  \u001b[0m | \u001b[0m 0.2437  \u001b[0m | \u001b[0m 14.86   \u001b[0m | \u001b[0m 455.7   \u001b[0m | \u001b[0m 32.63   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1018  \u001b[0m | \u001b[0m 0.9779  \u001b[0m | \u001b[0m 0.2133  \u001b[0m | \u001b[0m 0.4655  \u001b[0m | \u001b[0m 0.08819 \u001b[0m | \u001b[0m 12.02   \u001b[0m | \u001b[0m 451.8   \u001b[0m | \u001b[0m 20.6    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1125  \u001b[0m | \u001b[0m 0.9166  \u001b[0m | \u001b[0m 0.2756  \u001b[0m | \u001b[0m 0.7699  \u001b[0m | \u001b[0m 0.3295  \u001b[0m | \u001b[0m 21.66   \u001b[0m | \u001b[0m 455.1   \u001b[0m | \u001b[0m 24.96   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes: 100%|██████████| 2/2 [25:13<00:00, 756.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the clusters and run the optimizer for each cluster. Return a list of best model params\n",
    "with tqdm_joblib(tqdm(desc=\"DTW LGBM Models Bayes\", \n",
    "                      total=len(train_df_dtw_clust_ls))) as progress_bar:\n",
    "    dtw_clust_mods_bayes = Parallel(n_jobs=2)(delayed(optimize_lgbm_w_bayes)(train_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                 train_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                                 val_df_dtw_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                                 val_df_dtw_clust_ls[i].iloc[:,0]) for i in range(len(train_df_dtw_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "76b629b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the list of model params and convert to int where required\n",
    "for n in range(len(dtw_clust_mods_bayes)):\n",
    "    dtw_clust_mods_bayes[n][\"max_depth\"] = int(round(dtw_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    dtw_clust_mods_bayes[n][\"n_estimators\"] = int(round(dtw_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    dtw_clust_mods_bayes[n][\"num_leaves\"] = int(round(dtw_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "dcac30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes Final:  50%|█████     | 1/2 [00:37<00:37, 37.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1471  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.146   \u001b[0m | \u001b[95m 0.7999  \u001b[0m | \u001b[95m 0.4889  \u001b[0m | \u001b[95m 0.05053 \u001b[0m | \u001b[95m 0.2692  \u001b[0m | \u001b[95m 2.954   \u001b[0m | \u001b[95m 827.3   \u001b[0m | \u001b[95m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.163   \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1788  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1595  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1498  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1532  \u001b[0m | \u001b[0m 0.6992  \u001b[0m | \u001b[0m 0.5316  \u001b[0m | \u001b[0m 0.5757  \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 12.38   \u001b[0m | \u001b[0m 818.6   \u001b[0m | \u001b[0m 142.7   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1521  \u001b[0m | \u001b[0m 0.6896  \u001b[0m | \u001b[0m 0.294   \u001b[0m | \u001b[0m 0.4966  \u001b[0m | \u001b[0m 0.2649  \u001b[0m | \u001b[0m 18.57   \u001b[0m | \u001b[0m 482.9   \u001b[0m | \u001b[0m 30.68   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.1432  \u001b[0m | \u001b[95m 0.8418  \u001b[0m | \u001b[95m 0.9842  \u001b[0m | \u001b[95m 0.6839  \u001b[0m | \u001b[95m 0.1345  \u001b[0m | \u001b[95m 22.78   \u001b[0m | \u001b[95m 479.1   \u001b[0m | \u001b[95m 11.61   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.144   \u001b[0m | \u001b[0m 0.5074  \u001b[0m | \u001b[0m 0.199   \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1149  \u001b[0m | \u001b[0m 11.03   \u001b[0m | \u001b[0m 487.9   \u001b[0m | \u001b[0m 10.83   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.9001  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 498.2   \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1479  \u001b[0m | \u001b[0m 0.5863  \u001b[0m | \u001b[0m 0.1335  \u001b[0m | \u001b[0m 0.915   \u001b[0m | \u001b[0m 0.2828  \u001b[0m | \u001b[0m 5.158   \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 12.72   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1492  \u001b[0m | \u001b[0m 0.1261  \u001b[0m | \u001b[0m 0.7298  \u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m 0.2367  \u001b[0m | \u001b[0m 2.177   \u001b[0m | \u001b[0m 485.0   \u001b[0m | \u001b[0m 32.12   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1854  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.06306 \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.414   \u001b[0m | \u001b[0m 11.09   \u001b[0m | \u001b[0m 471.1   \u001b[0m | \u001b[0m 46.64   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1432  \u001b[0m | \u001b[0m 0.6858  \u001b[0m | \u001b[0m 0.5742  \u001b[0m | \u001b[0m 0.1694  \u001b[0m | \u001b[0m 0.08158 \u001b[0m | \u001b[0m 23.42   \u001b[0m | \u001b[0m 455.5   \u001b[0m | \u001b[0m 12.52   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1919  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 455.7   \u001b[0m | \u001b[0m 32.76   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1578  \u001b[0m | \u001b[0m 0.315   \u001b[0m | \u001b[0m 0.0872  \u001b[0m | \u001b[0m 0.3611  \u001b[0m | \u001b[0m 0.499   \u001b[0m | \u001b[0m 4.5     \u001b[0m | \u001b[0m 449.0   \u001b[0m | \u001b[0m 13.05   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.157   \u001b[0m | \u001b[0m 0.9857  \u001b[0m | \u001b[0m 0.8369  \u001b[0m | \u001b[0m 0.3733  \u001b[0m | \u001b[0m 0.4588  \u001b[0m | \u001b[0m 24.93   \u001b[0m | \u001b[0m 437.2   \u001b[0m | \u001b[0m 15.05   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1481  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 826.9   \u001b[0m | \u001b[0m 127.9   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1497  \u001b[0m | \u001b[0m 0.5076  \u001b[0m | \u001b[0m 0.2557  \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.1423  \u001b[0m | \u001b[0m 20.53   \u001b[0m | \u001b[0m 834.9   \u001b[0m | \u001b[0m 126.6   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1818  \u001b[0m | \u001b[0m 0.8584  \u001b[0m | \u001b[0m 0.994   \u001b[0m | \u001b[0m 0.8094  \u001b[0m | \u001b[0m 0.357   \u001b[0m | \u001b[0m 22.25   \u001b[0m | \u001b[0m 839.9   \u001b[0m | \u001b[0m 148.0   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1729  \u001b[0m | \u001b[0m 0.8207  \u001b[0m | \u001b[0m 0.3236  \u001b[0m | \u001b[0m 0.5907  \u001b[0m | \u001b[0m 0.3208  \u001b[0m | \u001b[0m 15.78   \u001b[0m | \u001b[0m 815.5   \u001b[0m | \u001b[0m 124.0   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1469  \u001b[0m | \u001b[0m 0.9061  \u001b[0m | \u001b[0m 0.2707  \u001b[0m | \u001b[0m 0.631   \u001b[0m | \u001b[0m 0.2434  \u001b[0m | \u001b[0m 4.256   \u001b[0m | \u001b[0m 846.3   \u001b[0m | \u001b[0m 126.3   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1515  \u001b[0m | \u001b[0m 0.8992  \u001b[0m | \u001b[0m 0.5018  \u001b[0m | \u001b[0m 0.354   \u001b[0m | \u001b[0m 0.1866  \u001b[0m | \u001b[0m 8.382   \u001b[0m | \u001b[0m 835.3   \u001b[0m | \u001b[0m 110.8   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1521  \u001b[0m | \u001b[0m 0.8649  \u001b[0m | \u001b[0m 0.4837  \u001b[0m | \u001b[0m 0.6621  \u001b[0m | \u001b[0m 0.1735  \u001b[0m | \u001b[0m 20.2    \u001b[0m | \u001b[0m 853.5   \u001b[0m | \u001b[0m 117.2   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1522  \u001b[0m | \u001b[0m 0.2119  \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 0.5861  \u001b[0m | \u001b[0m 0.2481  \u001b[0m | \u001b[0m 4.717   \u001b[0m | \u001b[0m 860.9   \u001b[0m | \u001b[0m 111.0   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1507  \u001b[0m | \u001b[0m 0.2513  \u001b[0m | \u001b[0m 0.144   \u001b[0m | \u001b[0m 0.5229  \u001b[0m | \u001b[0m 0.1542  \u001b[0m | \u001b[0m 8.46    \u001b[0m | \u001b[0m 868.1   \u001b[0m | \u001b[0m 129.2   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1434  \u001b[0m | \u001b[0m 0.9213  \u001b[0m | \u001b[0m 0.1138  \u001b[0m | \u001b[0m 0.7532  \u001b[0m | \u001b[0m 0.09081 \u001b[0m | \u001b[0m 20.81   \u001b[0m | \u001b[0m 873.5   \u001b[0m | \u001b[0m 115.6   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1489  \u001b[0m | \u001b[0m 0.2741  \u001b[0m | \u001b[0m 0.6744  \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 0.1674  \u001b[0m | \u001b[0m 6.031   \u001b[0m | \u001b[0m 884.3   \u001b[0m | \u001b[0m 112.5   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1864  \u001b[0m | \u001b[0m 0.6123  \u001b[0m | \u001b[0m 0.3501  \u001b[0m | \u001b[0m 0.3633  \u001b[0m | \u001b[0m 0.3923  \u001b[0m | \u001b[0m 12.64   \u001b[0m | \u001b[0m 875.0   \u001b[0m | \u001b[0m 98.31   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3212994785101474, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3212994785101474\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.45103270481577384, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.45103270481577384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes Final: 100%|██████████| 2/2 [00:47<00:00, 23.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the clusters, and using the params found by the optimizer, train a final model for each cluster.\n",
    "# Save to a list of models\n",
    "with tqdm_joblib(tqdm(desc=\"DTW LGBM Models Bayes Final\", \n",
    "                      total=len(dtw_clust_mods_bayes))) as progress_bar:\n",
    "    dtw_clust_mods_bayes_final = Parallel(n_jobs=2)(delayed(train_lgbm)(dtw_clust_mods_bayes[i], \n",
    "                                                                            train_val_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                            train_val_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(dtw_clust_mods_bayes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4fa0c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the models to files\n",
    "for model_no in range(len(dtw_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/DTW/model_{model_no}\"\n",
    "    joblib.dump(dtw_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "05e4631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "DTW LGBM Models Bayes Residuals:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.984179694224035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.984179694224035\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6839054457162111, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6839054457162111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes Residuals: 100%|██████████| 2/2 [00:11<00:00,  5.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each model and train_val data used to train the model, compute the residuals. Save the residual list for\n",
    "# each model as an entry in a list\n",
    "with tqdm_joblib(tqdm(desc=\"DTW LGBM Models Bayes Residuals\", \n",
    "                      total=len(dtw_clust_mods_bayes_final))) as progress_bar:\n",
    "    dtw_clust_mods_bayes_resid = Parallel(n_jobs=3)(delayed(compute_lgbm_residuals)(dtw_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(dtw_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b40b21f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes Test Preds: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each model, compute the predictions on the test data\n",
    "with tqdm_joblib(tqdm(desc=\"DTW LGBM Models Bayes Test Preds\", \n",
    "                      total=len(dtw_clust_mods_bayes_final))) as progress_bar:\n",
    "    dtw_clust_mods_bayes_test_preds = Parallel(n_jobs=2)(delayed(compute_lgbm_test_preds)(dtw_clust_mods_bayes_final[i],\n",
    "                                                                                           test_df_full_dtw_clust_ls[i],\n",
    "                                                                                           lag_n\n",
    "                                                                                          ) for i in range(len(dtw_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "2c5652c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one data frame of test preds from the list created above\n",
    "dtw_clust_bayes_test_preds_df = pd.DataFrame()\n",
    "for clust_test_pred_df in dtw_clust_mods_bayes_test_preds:\n",
    "    dtw_clust_bayes_test_preds_df = dtw_clust_bayes_test_preds_df.append(clust_test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "5cb4cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test pred performance\n",
    "dtw_clust_bayes_test_perf = compute_lgbm_test_perf(dtw_clust_bayes_test_preds_df,\n",
    "                                                       test_df_full_dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "283e1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized performance metrics as well\n",
    "dtw_clust_bayes_test_perf['nrmse'] = dtw_clust_bayes_test_perf['rmse']/dtw_clust_bayes_test_perf['mean']\n",
    "dtw_clust_bayes_test_perf['smae'] = dtw_clust_bayes_test_perf['mae']/dtw_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "25dcda4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      30.616158\n",
       "mae       20.269448\n",
       "mean     265.435072\n",
       "nrmse      0.138503\n",
       "smae       0.093470\n",
       "dtype: float64"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print means of perf metrics\n",
    "dtw_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "4dfa162e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e621c5d340a4d649e9b69e82cd41485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/33600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ca80143931403fa082cfe28e32c527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/68544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each model/cluster, compute bootstrap PIs for each prediction from the test set. Save the data frames of PI's\n",
    "# to a lift\n",
    "dtw_clust_test_pred_int = list()\n",
    "for i in range(len(dtw_clust_mods_bayes_test_preds)):\n",
    "    dtw_clust_test_pred_int.append(compute_lgbm_boostrap_int(dtw_clust_mods_bayes_test_preds[i], \n",
    "                                                                 dtw_clust_mods_bayes_resid[i], \n",
    "                                                                 n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "80db3585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster's PI DF, add a column with the true value for each observation\n",
    "for n in range(1, len(dtw_clust_test_pred_int)+1):\n",
    "    y_actual_sub = test_df_full_dtw.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    dtw_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "2f9c2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all PI data frames into one data frame\n",
    "dtw_clust_test_pred_int_df = pd.DataFrame()\n",
    "for clust_test_pred_int_df in dtw_clust_test_pred_int:\n",
    "    dtw_clust_test_pred_int_df = dtw_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "fd715197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the interval score for each observation's 95% and 80% PI\n",
    "dtw_clust_test_pred_int_df['int_95_score'] = interval_score(dtw_clust_test_pred_int_df['actual'],\n",
    "                                                                dtw_clust_test_pred_int_df['lo_95'],\n",
    "                                                                dtw_clust_test_pred_int_df['hi_95'],\n",
    "                                                                0.95\n",
    "                                                               )\n",
    "\n",
    "dtw_clust_test_pred_int_df['int_80_score'] = interval_score(dtw_clust_test_pred_int_df['actual'],\n",
    "                                                                dtw_clust_test_pred_int_df['lo_80'],\n",
    "                                                                dtw_clust_test_pred_int_df['hi_80'],\n",
    "                                                                0.80\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "df65e03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.603006\n",
       "lo_95           211.775386\n",
       "hi_95           321.324330\n",
       "lo_80           237.246404\n",
       "hi_80           294.863473\n",
       "actual          265.435072\n",
       "int_95_score    201.996183\n",
       "int_80_score    115.150907\n",
       "dtype: float64"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean interval scores\n",
    "dtw_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "3e100013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI df to a csv file\n",
    "dtw_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/DTW/test_pred_intervals.csv\",\n",
    "                                     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f0707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
