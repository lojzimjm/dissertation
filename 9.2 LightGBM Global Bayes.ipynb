{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff818f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the libraries are not yet installed, they can be installed in this notebook using commands similar to the below\n",
    "# %conda install numpy\n",
    "# %conda install pandas\n",
    "# %conda install matplotlib\n",
    "# %conda install scikit-learn\n",
    "# %conda install -c conda-forge lightgbm \n",
    "# %conda install -c conda-forge swifter\n",
    "# %conda install -c conda-forge bayesian-optimization \n",
    "# %conda install -c conda-forge scipy\n",
    "# %conda install joblib\n",
    "# %conda install tdqm\n",
    "\n",
    "# Something like the following may also work if the above does not\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} numpy\n",
    "# !conda install --yes --prefix {sys.prefix} pandas\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} lightgbm\n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} swifter\n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} bayesian-optimization \n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} scipy \n",
    "# !conda install --yes --prefix {sys.prefix} joblib\n",
    "# !conda install --yes --prefix {sys.prefix} tdqm\n",
    "\n",
    "# To install a specific version, add the version to the install command\n",
    "# E.g., %conda install numpy=1.20.3\n",
    "\n",
    "# If all else fails, use pip or follow additional advice such as found at\n",
    "# https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "\n",
    "# If your plan to use pip (especially if you are not working within a specified conda environment), \n",
    "# the pip commands might look like:\n",
    "# pip install numpy\n",
    "# pip install pandas\n",
    "# pip install scikit-learn\n",
    "# pip install lightgbm\n",
    "# pip install swifter\n",
    "# pip install bayesian-optimization \n",
    "# pip install scipy\n",
    "# pip install joblib\n",
    "# pip install tdqm\n",
    "\n",
    "# To install a specific version, add the version to the pip install command\n",
    "# E.g., pip install numpy==1.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8c99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import glob\n",
    "from lightgbm import LGBMRegressor\n",
    "import random\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import scipy\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "import contextlib\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from bayes_opt import BayesianOptimization\n",
    "import swifter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ef1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f000e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories to save results\n",
    "\n",
    "if not os.path.exists(\"Results/Global/LightGBM Bayes/\"):\n",
    "    os.mkdir(\"Results/Global/LightGBM Bayes\")\n",
    "      \n",
    "if not os.path.exists(\"Results/Global/LightGBM Bayes/Full\"):\n",
    "    os.mkdir(\"Results/Global/LightGBM Bayes/Full\")\n",
    "    \n",
    "if not os.path.exists(\"Results/Global/LightGBM Bayes/Random Cluster\"):\n",
    "    os.mkdir(\"Results/Global/LightGBM Bayes/Random Cluster\")\n",
    "    \n",
    "if not os.path.exists(\"Results/Global/LightGBM Bayes/Highway System\"):\n",
    "    os.mkdir(\"Results/Global/LightGBM Bayes/Highway System\")\n",
    "    \n",
    "if not os.path.exists(\"Results/Global/LightGBM Bayes/Catch22 KMeans\"):\n",
    "    os.mkdir(\"Results/Global/LightGBM Bayes/Catch22 KMeans\")\n",
    "\n",
    "if not os.path.exists(\"Results/Global/LightGBM Bayes/TSFeat KMeans\"):\n",
    "    os.mkdir(\"Results/Global/LightGBM Bayes/TSFeat KMeans\")\n",
    "\n",
    "if not os.path.exists(\"Results/Global/LightGBM Bayes/DTW\"):\n",
    "    os.mkdir(\"Results/Global/LightGBM Bayes/DTW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2eba8",
   "metadata": {},
   "source": [
    "# Read in Data and Prepare for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28a607f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Processed/Highways_England/A11-6310-1_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A11-6312-2_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A14-1107A_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A14-1144B_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A1M-9842B_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A1M-9847a_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A46-7636-1_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A46-7636-2_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A47-6337-1_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A47-6337-2_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A5-6847-2_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A5-7572-1-Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A590-9531-1_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A590-9634-1_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A64-9251-1_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A64-9252-1_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A69-9784-1_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/A69-9785-1_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M1-2148L_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M1-2633A_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M11-6400B_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M11-6747A_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M18-7569B_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M18-7578A_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M20-6552A2_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M20-6572B2_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M25-4490B_Counterclockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M25-4565A_Clockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M3-1524A_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M3-1537L_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M4-2156A_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M4-3434B_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M5-7650B_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M5-8291A_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M6-5441A_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M6-7036B_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M60-9327B_Counterclockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Highways_England/M60-9374A_Clockwise_2019_Processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to hold the dataframes of highways england data\n",
    "england_df_list = list()\n",
    "\n",
    "# Loop through the files, sorted in alphabetical order\n",
    "# Read them into a df, make sure they are sorted by timestamp, and append to the list\n",
    "for fname in sorted(glob.glob(\"Data/Processed/Highways_England/*.csv\")):\n",
    "    print(\"Reading {}\".format(fname))\n",
    "    df = pd.read_csv(fname) #, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "    df = df.sort_values(by=\"timestamp\")\n",
    "    england_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ebb492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Processed/Portland/I205-101068_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I205-101073_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I405-100395_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I405-100527_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I5-100688_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I5-100703_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I84-101108_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/I84-101161_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/OR217-100300_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/OR217-100314_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/R2 Delta Hwy-101745_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/R2 OR18-102111_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/R2 OR18-102113_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/SR 14-102001_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/SR 14-102003_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/SR 500-1000022_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/SR 500-1000104_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/US26-100627_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Portland/US26-100650_Westbound_2019_Processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Follow the same process in this cell and the next as was done above, just for other highway systems\n",
    "portland_df_list = list()\n",
    "\n",
    "for fname in sorted(glob.glob(\"Data/Processed/Portland/*.csv\")):\n",
    "    print(\"Reading {}\".format(fname))\n",
    "    df = pd.read_csv(fname) #, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "    df = df.sort_values(by=\"timestamp\")\n",
    "    portland_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a07831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Processed/Utah/I15-3103178_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I15-749_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I215-134_Counterclockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I215-31_Clockwise_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I70-3103400_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I70-3103401_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I80-600_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I80-667_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I84-451_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/I84-482_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/LegacyParkway-810_Northbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/LegacyParkway-890_Southbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US189-260_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US189-470_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US40-634_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US40-635_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US6-3103114_Eastbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US6-3103115_Westbound_2019_Processed.csv\n",
      "Reading Data/Processed/Utah/US89-483_Northbound_2019_Processed.csv\n"
     ]
    }
   ],
   "source": [
    "utah_df_list = list()\n",
    "\n",
    "for fname in sorted(glob.glob(\"Data/Processed/Utah/*.csv\")):\n",
    "    print(\"Reading {}\".format(fname))\n",
    "    df = pd.read_csv(fname) #, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "    df = df.sort_values(by=\"timestamp\")\n",
    "    utah_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7124ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all df lists together into one\n",
    "total_df_list = england_df_list + portland_df_list + utah_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4992fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the start and end points csv, and subtract 1 to deal with index differences between R and python\n",
    "start_end = pd.read_csv(\"start_end_points.csv\")\n",
    "start_end[\"start\"] = start_end[\"start\"] - 1\n",
    "start_end[\"end\"] = start_end[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79acc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to hold the subset data frames (those with only 12 weeks of data per highway)\n",
    "subset_df_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f007a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each df in our original total df list\n",
    "for idx, df in enumerate(total_df_list):\n",
    "        \n",
    "    # Filter the timeframe based on the start_end_points csv files\n",
    "    subset_df = df.iloc[start_end.iloc[idx,0]:start_end.iloc[idx,1], ]\\\n",
    "    .reset_index(drop=True).reset_index(drop=False)\\\n",
    "    .rename(columns={\"index\":\"rn\"})\n",
    "    \n",
    "    # Create a new field called train_val_test to differentiate each set of data\n",
    "    subset_df[\"train_val_test\"] = np.where(subset_df[\"rn\"]<(96*7*8),\n",
    "                                           \"train\",\n",
    "                                           np.where(subset_df[\"rn\"]<(96*7*10),\n",
    "                                                    \"val\",\n",
    "                                                    \"test\"\n",
    "                                                   )\n",
    "                                       )\n",
    "    \n",
    "    # Append to list\n",
    "    subset_df_list.append(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e4362e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of df's with only fields we need\n",
    "\n",
    "# Initialize empty list\n",
    "model_df_list = list()\n",
    "\n",
    "# For df in subset list\n",
    "for df in subset_df_list:\n",
    "       \n",
    "    # Extract the timestamp, the volume, and the train_val_test assignment\n",
    "    model_df = df[['timestamp', 'total_volume', \"train_val_test\"]]\\\n",
    "    .rename(columns={'timestamp':'start', 'total_volume':'target'})\n",
    "    \n",
    "    # Append this df to the new list\n",
    "    model_df_list.append(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb115fab",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3af45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for progress bar:\n",
    "# https://stackoverflow.com/questions/24983493/tracking-progress-of-joblib-parallel-execution\n",
    "# This allows us to print a progress bar while running parallel loops using joblib \n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa7c967",
   "metadata": {},
   "source": [
    "## Create Lag Emebedded Matrices for each TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae0aab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the final lag value to be used for all lag embedding\n",
    "lag_n = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "210f115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2585/1739749478.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = df['target'].shift(n)\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to save lag embedded data into\n",
    "lag_embed_df_list = list()\n",
    "\n",
    "# For each data frame\n",
    "for df in model_df_list:\n",
    "    for n in range(1, (lag_n+1)):\n",
    "        # For each lag level, up to lag_n + 1 (we add 1 to preserve the target value correctly)\n",
    "        # Create a new column called target-n\n",
    "        name = f\"target-{n}\"\n",
    "        # Save the target shifted n values into this column\n",
    "        df[name] = df['target'].shift(n)\n",
    "    # Append the lag embedded df to the list\n",
    "    lag_embed_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ebe6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the lag embedded list into train, val, and test lists\n",
    "\n",
    "# First, initialize empty lists for each train, val, and test\n",
    "train_df_list = list()\n",
    "val_df_list = list()\n",
    "test_df_list = list()\n",
    "\n",
    "# For each df in our list\n",
    "for i in range(len(lag_embed_df_list)):\n",
    "    \n",
    "    # Create a copy of just the data frame of interest\n",
    "    df = lag_embed_df_list[i].copy()\n",
    "    # Add a field to it for ts_index, this is for joining with cluster data later and is equal to i+1 due to \n",
    "    # differences in indexing between R and Python\n",
    "    df['ts_index'] = i + 1\n",
    "    \n",
    "    # Subset into train, val, and test df's based on the train_val_test_field\n",
    "    train_df = df.query(\"train_val_test == 'train'\").copy()\n",
    "    val_df = df.query(\"train_val_test=='val'\").copy()\n",
    "    test_df = df.query(\"train_val_test=='test'\").copy()\n",
    "   \n",
    "    # Append to appropriate lists\n",
    "    train_df_list.append(train_df)\n",
    "    val_df_list.append(val_df)\n",
    "    test_df_list.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53835e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all dfs from the lists together to create one full train, val, and test df\n",
    "train_df_full = pd.concat(train_df_list)\n",
    "val_df_full = pd.concat(val_df_list)\n",
    "test_df_full = pd.concat(test_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba6ce7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "train_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "val_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "test_df_full.drop(columns=['start', 'train_val_test'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0a8cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the training and validation data together for later use\n",
    "train_val_df_full = train_df_full.append(val_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "401c6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused variables to free up memory\n",
    "del train_df_list\n",
    "del val_df_list \n",
    "del test_df_list\n",
    "del lag_embed_df_list\n",
    "del model_df_list\n",
    "del subset_df_list\n",
    "del total_df_list\n",
    "del england_df_list\n",
    "del portland_df_list\n",
    "del utah_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28285bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ad589",
   "metadata": {},
   "source": [
    "# Full Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "994bbf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y training and validation data frames\n",
    "# y is always the first column of the data frame, and X is the remaining columns up to lag_n+1\n",
    "# For train, we use dropna to ensure that the first lag_n row, which have null values in them,\n",
    "# are not included in the training data. This is not necessary for validation as there are no null values\n",
    "X_train_full = train_df_full.iloc[:,0:(lag_n+1)].dropna().iloc[:,1:]\n",
    "y_train_full = train_df_full.iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "\n",
    "X_val_full = val_df_full.iloc[:,1:(lag_n+1)]\n",
    "y_val_full = val_df_full.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54b97b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to optimize a light gbm model using Bayesian optimization\n",
    "\n",
    "def optimize_lgbm_w_bayes(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Function takes in four inputs: the training and validation X and y data frames\n",
    "    and returns the model params found by the Bayesian optimizer to have the best performance\"\"\"\n",
    "    \n",
    "    # Set the X_train, y_train, X_val, and y_val variables inside the function\n",
    "    X_train = X_train\n",
    "    y_train = y_train\n",
    "    \n",
    "    X_val = X_val\n",
    "    y_val = y_val\n",
    "    \n",
    "    # Set up the min and max of the parameter space to explore for each parameter\n",
    "    bayes_param_ss = {\n",
    "    \"n_estimators\": (100, 1000),\n",
    "    \"max_depth\": (2, 25),\n",
    "    \"lambda_l1\": (0, 1),\n",
    "    \"lambda_l2\": (0, 1),\n",
    "    \"num_leaves\": (10, 150),\n",
    "    \"colsample_bytree\": (0.1, 1),\n",
    "    \"learning_rate\": (0.00001, 0.5)\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Define a function to compute validation set predictions\n",
    "    def val_predict(model, X_val, y_val):\n",
    "        \"\"\"Function which takes a trained model and X and y for validation set \n",
    "        and returns the scaled rmse for the validation set predictions\"\"\"\n",
    "        \n",
    "        # Compute the mean of the target values\n",
    "        val_mean = np.mean(y_val)\n",
    "        \n",
    "        # Compute predictions with the validation X data frame\n",
    "        val_preds = model.predict(X_val)\n",
    "        \n",
    "        # Compute validation rmse and scaled rmse by dividing by the mean\n",
    "        val_rmse = mean_squared_error(y_val, val_preds, squared=False)\n",
    "        val_nrmse = val_rmse/val_mean\n",
    "            \n",
    "        # Return scaled rmse\n",
    "        return val_nrmse\n",
    "    \n",
    "    \n",
    "    # Define a function to perform the Bayesian optimization\n",
    "    def lgbm_eval_for_bayes(n_estimators,\n",
    "                        max_depth,\n",
    "                        lambda_l1, \n",
    "                        lambda_l2,\n",
    "                        num_leaves,\n",
    "                        colsample_bytree,\n",
    "                        learning_rate\n",
    "                       ):\n",
    "    \n",
    "        \"\"\"Function which takes in parameter values as inputs and returns a value to be maximized by the\n",
    "        Bayesian optimizer. In this case, we return -1*validation_nrmse as this allows us to minimize the\n",
    "        validation nrmse\"\"\"\n",
    "        \n",
    "        # Set the proper boosting type\n",
    "        params = {\"boosting_type\": \"goss\"\n",
    "                 }\n",
    "\n",
    "        # Set the params dictionary to include all input params\n",
    "        # For n_estimators, max_depth, and num_leaves, round and cast as int - this is what the lgbm model requires\n",
    "        params[\"n_estimators\"] = int(round(n_estimators))\n",
    "        params[\"max_depth\"] = int(round(max_depth))\n",
    "        params[\"reg_alpha\"] = max(lambda_l1, 0)\n",
    "        params[\"reg_lambda\"] = max(lambda_l2, 0)\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params[\"colsample_bytree\"] = colsample_bytree\n",
    "        params[\"learning_rate\"] = learning_rate\n",
    "\n",
    "        # Create the model given these params\n",
    "        mod = LGBMRegressor(**params, random_state=54321)  \n",
    "        # Fit the model to the X and y training data defined earlier in the overall function\n",
    "        mod.fit(X_train, y_train)\n",
    "\n",
    "        # Compute validation performance using the data passed to the main function and the previously\n",
    "        # defined function to compute val performance. Note that we multiply by -1 here as the optimizer\n",
    "        # is expecting a value to be maximized, not minimized\n",
    "        val_perf = -1*np.mean(val_predict(mod, X_val, y_val))\n",
    "\n",
    "        # Return the negative validation nrmse\n",
    "        return val_perf\n",
    "\n",
    "    # Create an optimizer object    \n",
    "    optimizer = BayesianOptimization(lgbm_eval_for_bayes,\n",
    "                                     bayes_param_ss,\n",
    "                                     random_state=54321)\n",
    "    # Maximize the optimizer with 5 random initialization points and 25 further iterations\n",
    "    optimizer.maximize(init_points=5, n_iter=25)\n",
    "    \n",
    "    # Return the best param set found by the optimizer\n",
    "    return optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dacea9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1318  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1319  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1428  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1558  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1387  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1415  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1346  \u001b[0m | \u001b[0m 0.1823  \u001b[0m | \u001b[0m 0.2334  \u001b[0m | \u001b[0m 0.3629  \u001b[0m | \u001b[0m 0.06587 \u001b[0m | \u001b[0m 17.26   \u001b[0m | \u001b[0m 859.2   \u001b[0m | \u001b[0m 141.3   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1295  \u001b[0m | \u001b[95m 0.5977  \u001b[0m | \u001b[95m 0.2829  \u001b[0m | \u001b[95m 0.9203  \u001b[0m | \u001b[95m 0.08668 \u001b[0m | \u001b[95m 8.428   \u001b[0m | \u001b[95m 942.3   \u001b[0m | \u001b[95m 106.7   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1514  \u001b[0m | \u001b[0m 0.6154  \u001b[0m | \u001b[0m 0.5809  \u001b[0m | \u001b[0m 0.5974  \u001b[0m | \u001b[0m 0.3896  \u001b[0m | \u001b[0m 23.0    \u001b[0m | \u001b[0m 433.1   \u001b[0m | \u001b[0m 83.41   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1406  \u001b[0m | \u001b[0m 0.2707  \u001b[0m | \u001b[0m 0.3919  \u001b[0m | \u001b[0m 0.8713  \u001b[0m | \u001b[0m 0.2398  \u001b[0m | \u001b[0m 21.29   \u001b[0m | \u001b[0m 182.6   \u001b[0m | \u001b[0m 128.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1339  \u001b[0m | \u001b[0m 0.5174  \u001b[0m | \u001b[0m 0.2394  \u001b[0m | \u001b[0m 0.01523 \u001b[0m | \u001b[0m 0.3594  \u001b[0m | \u001b[0m 2.433   \u001b[0m | \u001b[0m 593.3   \u001b[0m | \u001b[0m 126.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1315  \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 0.517   \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 0.09298 \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 583.4   \u001b[0m | \u001b[0m 123.1   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1346  \u001b[0m | \u001b[0m 0.957   \u001b[0m | \u001b[0m 0.5047  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.2706  \u001b[0m | \u001b[0m 8.573   \u001b[0m | \u001b[0m 757.1   \u001b[0m | \u001b[0m 17.0    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1417  \u001b[0m | \u001b[0m 0.2656  \u001b[0m | \u001b[0m 0.04668 \u001b[0m | \u001b[0m 0.03001 \u001b[0m | \u001b[0m 0.1727  \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 861.6   \u001b[0m | \u001b[0m 139.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.138   \u001b[0m | \u001b[0m 0.8199  \u001b[0m | \u001b[0m 0.4933  \u001b[0m | \u001b[0m 0.7328  \u001b[0m | \u001b[0m 0.2643  \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 398.9   \u001b[0m | \u001b[0m 92.87   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1724  \u001b[0m | \u001b[0m 0.5136  \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 0.06973 \u001b[0m | \u001b[0m 0.4773  \u001b[0m | \u001b[0m 10.62   \u001b[0m | \u001b[0m 642.0   \u001b[0m | \u001b[0m 97.73   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1424  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.371   \u001b[0m | \u001b[0m 9.194   \u001b[0m | \u001b[0m 969.5   \u001b[0m | \u001b[0m 23.1    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1356  \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.0695  \u001b[0m | \u001b[0m 0.3948  \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 27.02   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.137   \u001b[0m | \u001b[0m 0.9134  \u001b[0m | \u001b[0m 0.3416  \u001b[0m | \u001b[0m 0.2057  \u001b[0m | \u001b[0m 0.2121  \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 418.8   \u001b[0m | \u001b[0m 120.2   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1296  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.5603  \u001b[0m | \u001b[0m 0.4809  \u001b[0m | \u001b[0m 0.09778 \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 351.6   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1335  \u001b[0m | \u001b[0m 0.5316  \u001b[0m | \u001b[0m 0.3662  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.377   \u001b[0m | \u001b[0m 2.832   \u001b[0m | \u001b[0m 855.2   \u001b[0m | \u001b[0m 24.01   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1516  \u001b[0m | \u001b[0m 0.3696  \u001b[0m | \u001b[0m 0.9666  \u001b[0m | \u001b[0m 0.0882  \u001b[0m | \u001b[0m 0.3123  \u001b[0m | \u001b[0m 22.58   \u001b[0m | \u001b[0m 694.0   \u001b[0m | \u001b[0m 115.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1324  \u001b[0m | \u001b[0m 0.2374  \u001b[0m | \u001b[0m 0.5845  \u001b[0m | \u001b[0m 0.6013  \u001b[0m | \u001b[0m 0.06929 \u001b[0m | \u001b[0m 24.59   \u001b[0m | \u001b[0m 646.7   \u001b[0m | \u001b[0m 126.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1309  \u001b[0m | \u001b[0m 0.6942  \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.7711  \u001b[0m | \u001b[0m 0.1554  \u001b[0m | \u001b[0m 16.79   \u001b[0m | \u001b[0m 331.1   \u001b[0m | \u001b[0m 40.78   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.144   \u001b[0m | \u001b[0m 0.1268  \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 0.7912  \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 18.31   \u001b[0m | \u001b[0m 255.6   \u001b[0m | \u001b[0m 68.42   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1432  \u001b[0m | \u001b[0m 0.7789  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.5176  \u001b[0m | \u001b[0m 0.2534  \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 925.9   \u001b[0m | \u001b[0m 114.4   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1316  \u001b[0m | \u001b[0m 0.5703  \u001b[0m | \u001b[0m 0.1937  \u001b[0m | \u001b[0m 0.677   \u001b[0m | \u001b[0m 0.2474  \u001b[0m | \u001b[0m 2.781   \u001b[0m | \u001b[0m 583.6   \u001b[0m | \u001b[0m 123.5   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1303  \u001b[0m | \u001b[0m 0.5409  \u001b[0m | \u001b[0m 0.5363  \u001b[0m | \u001b[0m 0.4746  \u001b[0m | \u001b[0m 0.1094  \u001b[0m | \u001b[0m 5.482   \u001b[0m | \u001b[0m 820.7   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m-0.1287  \u001b[0m | \u001b[95m 0.5727  \u001b[0m | \u001b[95m 0.5147  \u001b[0m | \u001b[95m 0.3481  \u001b[0m | \u001b[95m 0.01791 \u001b[0m | \u001b[95m 6.203   \u001b[0m | \u001b[95m 946.5   \u001b[0m | \u001b[95m 100.4   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1702  \u001b[0m | \u001b[0m 0.3398  \u001b[0m | \u001b[0m 0.8271  \u001b[0m | \u001b[0m 0.04637 \u001b[0m | \u001b[0m 0.4301  \u001b[0m | \u001b[0m 13.4    \u001b[0m | \u001b[0m 945.7   \u001b[0m | \u001b[0m 100.1   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Call the optimizer defined above\n",
    "bayes_full_model = optimize_lgbm_w_bayes(X_train_full,\n",
    "                                         y_train_full,\n",
    "                                         X_val_full,\n",
    "                                         y_val_full\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78560eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5726978820897191,\n",
       " 'lambda_l1': 0.514735973118135,\n",
       " 'lambda_l2': 0.34808264544051104,\n",
       " 'learning_rate': 0.017905362936323412,\n",
       " 'max_depth': 6.203116045410376,\n",
       " 'n_estimators': 946.4600324511604,\n",
       " 'num_leaves': 100.383333212035}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inpsect the params found by the optimizer\n",
    "bayes_full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb4b917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round and cast to int the model params which must be integers\n",
    "bayes_full_model['max_depth'] = int(round(bayes_full_model['max_depth']))\n",
    "bayes_full_model['n_estimators'] = int(round(bayes_full_model['n_estimators']))\n",
    "bayes_full_model['num_leaves'] = int(round(bayes_full_model['num_leaves']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1bc2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model using the params found by the optimizer\n",
    "lgbm_full_model_bayes = LGBMRegressor(boosting_type=\"goss\", **bayes_full_model, random_state=54321)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6509b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y for the training and validation data together to fit the final model to this full set\n",
    "X_train_val_full = train_val_df_full.iloc[:,0:(lag_n+1)].dropna().iloc[:,1:]\n",
    "y_train_val_full = train_val_df_full.iloc[:,0:(lag_n+1)].dropna().iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e8f6d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.514735973118135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.514735973118135\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34808264544051104, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.34808264544051104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='goss', colsample_bytree=0.5726978820897191,\n",
       "              lambda_l1=0.514735973118135, lambda_l2=0.34808264544051104,\n",
       "              learning_rate=0.017905362936323412, max_depth=6, n_estimators=946,\n",
       "              num_leaves=100, random_state=54321)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "lgbm_full_model_bayes.fit(X_train_val_full, y_train_val_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bc7493d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Results/Global/LightGBM Bayes/Full/model']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to file to use later\n",
    "filename = 'Results/Global/LightGBM Bayes/Full/model'\n",
    "joblib.dump(lgbm_full_model_bayes, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d05fb7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from file using joblib.load\n",
    "lgbm_full_model_bayes = joblib.load(\"Results/Global/LightGBM Bayes/Full/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4adeaeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute model residuals\n",
    "def compute_lgbm_residuals(mod, X, y):\n",
    "    \"\"\"Function takes in a trained model and X and y on which the model was trained, \n",
    "    and compute residuals. Residuals are returned as a list\"\"\"\n",
    "    \n",
    "    # Compute model predicitons from the provided X\n",
    "    pred = mod.predict(X)\n",
    "    \n",
    "    # Compute residuals as y - predictions, and convert to list\n",
    "    resid = (y - pred).to_list()\n",
    "    \n",
    "    # Return list of residuals\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a483973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model residuals using above function\n",
    "lgbm_full_model_bayes_residuals = compute_lgbm_residuals(lgbm_full_model_bayes, \n",
    "                                                         X_train_val_full,\n",
    "                                                         y_train_val_full\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7290c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mod_resid_df = pd.DataFrame({\"residual\": lgbm_full_model_bayes_residuals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2db8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mod_resid_df.to_csv(\"Results/Global/LightGBM Bayes/Full/residual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3977f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute test preds\n",
    "def compute_lgbm_test_preds(mod, data, lag_n):\n",
    "    \"\"\"Function takes in a trained model, test data frame, and lag_n used for lag embedding, and\n",
    "    returns a data frame of predictions for the provided data\"\"\"\n",
    "\n",
    "    # Create an empty data frame to store predictions in\n",
    "    pred_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop through each time series index in the data set\n",
    "    for ts_idx in data.ts_index.unique():\n",
    "        # For each time series index, grab X by eliminating the first column and any columns past (lag_n+1)\n",
    "        X = data.query(\"ts_index==@ts_idx\").iloc[:,1:(lag_n+1)].copy()\n",
    "        # Compute model preds from X\n",
    "        preds = mod.predict(X)\n",
    "        \n",
    "        # Save the preds, along with the time series index, to a temp data frame\n",
    "        pred_df_sub = pd.DataFrame({\"ts_index\": ts_idx, \"test_preds\": preds})\n",
    "        \n",
    "        # Append the temp df to the full df\n",
    "        pred_df = pred_df.append(pred_df_sub)\n",
    "    \n",
    "    # Return the full data frame of test set predictions\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5696aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test set predictions using the above function\n",
    "lgbm_full_model_bayes_test_preds = compute_lgbm_test_preds(lgbm_full_model_bayes,\n",
    "                                                           test_df_full,\n",
    "                                                           lag_n\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7eb6ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute test prediction performance metrics\n",
    "def compute_lgbm_test_perf(preds, data):\n",
    "    \"\"\"Function which takes in a data frame of predictions and a test data frame and computes model performance\"\"\"\n",
    "    \n",
    "    # Create an empty list to store performance data\n",
    "    perf_ls = list()\n",
    "    \n",
    "    # Loop through the time series indexes in our data\n",
    "    for ts_idx in data.ts_index.unique():\n",
    "        # For each time series index\n",
    "        # Extract the true target value (first column of the data frame)\n",
    "        y_sub = data.query(\"ts_index==@ts_idx\").iloc[:,0]\n",
    "        # Extract the preds for that ts_idx\n",
    "        preds_sub = preds.query(\"ts_index==@ts_idx\").test_preds\n",
    "        \n",
    "        # Compute rmse, mae, and the mean of the true target data using numpy and sklearn functions\n",
    "        rmse_sub = mean_squared_error(y_sub, preds_sub, squared=False)\n",
    "        mae_sub = mean_absolute_error(y_sub, preds_sub)\n",
    "        mean_sub = np.mean(y_sub)\n",
    "        \n",
    "        # Create a dictionary to hold these metrics\n",
    "        pred_dict = {\"rmse\": rmse_sub, \"mae\": mae_sub, \"mean\": mean_sub}\n",
    "        \n",
    "        # Append this dictionary to the list\n",
    "        perf_ls.append(pred_dict)\n",
    "        \n",
    "    # Call pd.DataFrame on the list of performance dictionaries to create a df of performance and then return it\n",
    "    return pd.DataFrame(perf_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f27b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test set performance\n",
    "lgbm_full_model_bayes_test_perf_df = compute_lgbm_test_perf(lgbm_full_model_bayes_test_preds, test_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e226af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized/scaled performance metrics as well\n",
    "lgbm_full_model_bayes_test_perf_df['nrmse'] = lgbm_full_model_bayes_test_perf_df['rmse']/lgbm_full_model_bayes_test_perf_df['mean']\n",
    "lgbm_full_model_bayes_test_perf_df['smae'] = lgbm_full_model_bayes_test_perf_df['mae']/lgbm_full_model_bayes_test_perf_df['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dd77e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      30.603133\n",
       "mae       20.185643\n",
       "mean     265.435072\n",
       "nrmse      0.138456\n",
       "smae       0.093232\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of the performance metrics\n",
    "lgbm_full_model_bayes_test_perf_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d094639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute bootstrap pred intervals\n",
    "def compute_lgbm_boostrap_int(preds, resid, n_boot):\n",
    "    \"\"\"Function takes in three inputs: a data frame of predictions, a list of residuals, and the number of \n",
    "    bootstrap resamples to use, n_boot. Function returns a modified version of the preds data frame which includes\n",
    "    both 80% and 95% PIs\"\"\"\n",
    "    \n",
    "    # Set seeds\n",
    "    random.seed(54321)\n",
    "    np.random.seed(54321)\n",
    "       \n",
    "    resid = resid\n",
    "    n_boot = n_boot\n",
    "    \n",
    "    # Define sub function to compute samples\n",
    "    def percentile_sample(row):\n",
    "        \"\"\"Function to boostramp sample residuals, add to predicted value, and compute percentiles for PIs.\n",
    "        Function is written to specifically operate on the rows of the preds data frame\"\"\"\n",
    "        \n",
    "        # Bootstrap sample from the residuals\n",
    "        boot_samp = np.random.choice(resid, size=n_boot, replace=True)\n",
    "\n",
    "        # Add the predicted value to the bootstrap samples\n",
    "        new_val = row['test_preds']+boot_samp\n",
    "\n",
    "        # Compute percentiles of the samples for the 95% and then 80% PIs\n",
    "        lo_95 = np.percentile(new_val, 2.5)\n",
    "        hi_95 = np.percentile(new_val, 97.5)\n",
    "        lo_80 = np.percentile(new_val, 10)\n",
    "        hi_80 = np.percentile(new_val, 90)\n",
    "\n",
    "        # Return a tuple of the percentiles which can be assigned to new data frame columns\n",
    "        return lo_95,hi_95,lo_80,hi_80\n",
    "\n",
    "    # Reset the index of the preds df so that swifter apply will work properly\n",
    "    preds = preds.reset_index(drop=True)\n",
    "    \n",
    "    # Compute bootstrap PIs using the above sub function and assign to new df columns\n",
    "    preds['lo_95'], preds['hi_95'], preds['lo_80'], preds['hi_80'] = zip(*preds.swifter.apply(percentile_sample, axis=1))\n",
    "    \n",
    "    # Return the modified preds data frame\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e70e9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set n_boot to 1000 \n",
    "n_boot = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24c24cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4cf38dfcae4d8a8cc29b5469c63832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/102144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the prediction inntervals\n",
    "lgbm_full_model_bayes_test_pred_int = compute_lgbm_boostrap_int(lgbm_full_model_bayes_test_preds,\n",
    "                                                                lgbm_full_model_bayes_residuals,\n",
    "                                                                n_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef1331c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102144, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check shape of output\n",
    "lgbm_full_model_bayes_test_pred_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21315e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the true target values as a column to the PI data frame\n",
    "lgbm_full_model_bayes_test_pred_int['actual'] = test_df_full.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4300d563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_index</th>\n",
       "      <th>test_preds</th>\n",
       "      <th>lo_95</th>\n",
       "      <th>hi_95</th>\n",
       "      <th>lo_80</th>\n",
       "      <th>hi_80</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>329.603418</td>\n",
       "      <td>276.491873</td>\n",
       "      <td>387.566262</td>\n",
       "      <td>301.935275</td>\n",
       "      <td>358.900685</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>327.388077</td>\n",
       "      <td>266.698468</td>\n",
       "      <td>396.614923</td>\n",
       "      <td>296.641381</td>\n",
       "      <td>357.606190</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>341.182653</td>\n",
       "      <td>280.886330</td>\n",
       "      <td>397.902035</td>\n",
       "      <td>312.706347</td>\n",
       "      <td>367.273697</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>351.206502</td>\n",
       "      <td>285.292677</td>\n",
       "      <td>416.952564</td>\n",
       "      <td>322.111895</td>\n",
       "      <td>381.659577</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>342.699460</td>\n",
       "      <td>282.471138</td>\n",
       "      <td>400.051979</td>\n",
       "      <td>314.355361</td>\n",
       "      <td>372.743081</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_index  test_preds       lo_95       hi_95       lo_80       hi_80  \\\n",
       "0         1  329.603418  276.491873  387.566262  301.935275  358.900685   \n",
       "1         1  327.388077  266.698468  396.614923  296.641381  357.606190   \n",
       "2         1  341.182653  280.886330  397.902035  312.706347  367.273697   \n",
       "3         1  351.206502  285.292677  416.952564  322.111895  381.659577   \n",
       "4         1  342.699460  282.471138  400.051979  314.355361  372.743081   \n",
       "\n",
       "   actual  \n",
       "0   320.0  \n",
       "1   339.0  \n",
       "2   349.0  \n",
       "3   343.0  \n",
       "4   343.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print head to sanity check\n",
    "lgbm_full_model_bayes_test_pred_int.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e880886a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_full_model_bayes_test_pred_int.ts_index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac984835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to compute the interval score\n",
    "def interval_score(true_values, lower, upper, interval_range):\n",
    "    \"\"\" Function which takes in the true values, the upper and lower bounds of PIs, and the PI level (e.g., 90%)\n",
    "        and from these inputs, computes the interval score for each prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute alpha from the interval range\n",
    "    alpha = 1-interval_range\n",
    "    \n",
    "    # Save the upper, lower, and true_values as numpy arrays for computation purposes\n",
    "    upper = np.array(upper)\n",
    "    lower = np.array(lower)\n",
    "    true_values = np.array(true_values)\n",
    "    \n",
    "    # Compute the lower component of the interval score - just a boolean for true below interval\n",
    "    def lower_ind(true,low):\n",
    "        if true<low:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the upper component of the interval score - similar boolean for true above interval\n",
    "    def upper_ind(true,up):\n",
    "        if true>up:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the actual score for each obsveration - formula here: https://epiforecasts.io/scoringutils/reference/interval_score.html\n",
    "    scores = (upper-lower) + (2/alpha)*(lower-true_values)*(lower > true_values) + (2/alpha)*(true_values-upper)*(true_values > upper)\n",
    "    \n",
    "    # Return the scores array\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52248acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 80% and 95% PI scores for each prediction\n",
    "lgbm_full_model_bayes_test_pred_int['int_95_score'] = interval_score(lgbm_full_model_bayes_test_pred_int.actual, \n",
    "                                                                     lgbm_full_model_bayes_test_pred_int.lo_95,\n",
    "                                                                     lgbm_full_model_bayes_test_pred_int.hi_95,\n",
    "                                                                     0.95)\n",
    "                                                    \n",
    "lgbm_full_model_bayes_test_pred_int['int_80_score'] = interval_score(lgbm_full_model_bayes_test_pred_int.actual, \n",
    "                                                                     lgbm_full_model_bayes_test_pred_int.lo_80,\n",
    "                                                                     lgbm_full_model_bayes_test_pred_int.hi_80,\n",
    "                                                                     0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "159e7239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.750378\n",
       "lo_95           205.259919\n",
       "hi_95           328.566850\n",
       "lo_80           237.130444\n",
       "hi_80           295.344232\n",
       "actual          265.435072\n",
       "int_95_score    225.436875\n",
       "int_80_score    121.707257\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean PI scores\n",
    "lgbm_full_model_bayes_test_pred_int.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed52a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_full_model_bayes_test_pred_int_grouped = lgbm_full_model_bayes_test_pred_int.groupby(\"ts_index\")\\\n",
    ".agg({\"int_95_score\":\"mean\", \"int_80_score\":\"mean\", \"actual\":\"mean\"}).reset_index()\n",
    "\n",
    "lgbm_full_model_bayes_test_pred_int_grouped['int_95_score_scaled'] = lgbm_full_model_bayes_test_pred_int_grouped['int_95_score']/lgbm_full_model_bayes_test_pred_int_grouped['actual']\n",
    "lgbm_full_model_bayes_test_pred_int_grouped['int_80_score_scaled'] = lgbm_full_model_bayes_test_pred_int_grouped['int_80_score']/lgbm_full_model_bayes_test_pred_int_grouped['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca4c9a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_80_score_scaled    0.604982\n",
       "int_95_score_scaled    1.122800\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_full_model_bayes_test_pred_int_grouped[['int_80_score_scaled', 'int_95_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbe1629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI data frame to a csv file\n",
    "lgbm_full_model_bayes_test_pred_int.to_csv(\"Results/Global/LightGBM Bayes/Full/test_pred_intervals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f167e1a",
   "metadata": {},
   "source": [
    "# Train and Test - Random Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d43f30d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete variables no longer in use\n",
    "del lgbm_full_model_bayes_test_pred_int\n",
    "del lgbm_full_model_bayes_test_perf_df\n",
    "del lgbm_full_model_bayes_test_preds\n",
    "del lgbm_full_model_bayes_residuals\n",
    "del lgbm_full_model_bayes\n",
    "del X_train_val_full\n",
    "del y_train_val_full\n",
    "del X_val_full\n",
    "del y_val_full\n",
    "del X_train_full\n",
    "del y_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f33edac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de1fb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cluster data for random clusters, and rename assignments to 'cluster'\n",
    "rand_clust = pd.read_csv(\"Results/Clustering/Random/random_clustering_assign.csv\")\n",
    "rand_clust['cluster'] = rand_clust['random_clust_assign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "226790c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and val data frames with cluster assignments\n",
    "train_df_rand_clust = train_df_full.merge(rand_clust, on=\"ts_index\")\n",
    "val_df_rand_clust = val_df_full.merge(rand_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9cefc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of data frames which only contain data for each cluster. Do this for both\n",
    "# training and validation data\n",
    "train_df_rand_clust_ls = [df.reset_index(drop=True) for _,df in train_df_rand_clust.groupby(\"cluster\")]\n",
    "val_df_rand_clust_ls = [df.reset_index(drop=True) for _,df in val_df_rand_clust.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd16aa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Cluster LGBM Models Bayes:  50%|█████     | 2/4 [19:55<17:41, 530.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1505  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1518  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1711  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1966  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1662  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1587  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2066  \u001b[0m | \u001b[0m 0.9697  \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.4162  \u001b[0m | \u001b[0m 0.4815  \u001b[0m | \u001b[0m 10.06   \u001b[0m | \u001b[0m 820.2   \u001b[0m | \u001b[0m 147.2   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1465  \u001b[0m | \u001b[95m 0.5048  \u001b[0m | \u001b[95m 0.1897  \u001b[0m | \u001b[95m 0.9395  \u001b[0m | \u001b[95m 0.06436 \u001b[0m | \u001b[95m 10.9    \u001b[0m | \u001b[95m 474.2   \u001b[0m | \u001b[95m 25.27   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1504  \u001b[0m | \u001b[0m 0.4901  \u001b[0m | \u001b[0m 0.8833  \u001b[0m | \u001b[0m 0.8702  \u001b[0m | \u001b[0m 0.1799  \u001b[0m | \u001b[0m 7.472   \u001b[0m | \u001b[0m 468.2   \u001b[0m | \u001b[0m 22.02   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1506  \u001b[0m | \u001b[0m 0.6715  \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 0.7347  \u001b[0m | \u001b[0m 0.1921  \u001b[0m | \u001b[0m 7.175   \u001b[0m | \u001b[0m 477.5   \u001b[0m | \u001b[0m 18.71   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1768  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9226  \u001b[0m | \u001b[0m 0.977   \u001b[0m | \u001b[0m 0.4671  \u001b[0m | \u001b[0m 14.35   \u001b[0m | \u001b[0m 482.4   \u001b[0m | \u001b[0m 23.7    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1484  \u001b[0m | \u001b[0m 0.4071  \u001b[0m | \u001b[0m 0.6239  \u001b[0m | \u001b[0m 0.3472  \u001b[0m | \u001b[0m 0.09999 \u001b[0m | \u001b[0m 2.894   \u001b[0m | \u001b[0m 472.7   \u001b[0m | \u001b[0m 22.53   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-0.1454  \u001b[0m | \u001b[95m 0.8351  \u001b[0m | \u001b[95m 0.9648  \u001b[0m | \u001b[95m 0.5529  \u001b[0m | \u001b[95m 0.09726 \u001b[0m | \u001b[95m 3.964   \u001b[0m | \u001b[95m 472.7   \u001b[0m | \u001b[95m 32.15   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1747  \u001b[0m | \u001b[0m 0.3124  \u001b[0m | \u001b[0m 0.6753  \u001b[0m | \u001b[0m 0.8881  \u001b[0m | \u001b[0m 0.3906  \u001b[0m | \u001b[0m 11.41   \u001b[0m | \u001b[0m 463.5   \u001b[0m | \u001b[0m 32.8    \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1542  \u001b[0m | \u001b[0m 0.5135  \u001b[0m | \u001b[0m 0.8313  \u001b[0m | \u001b[0m 0.1862  \u001b[0m | \u001b[0m 0.3136  \u001b[0m | \u001b[0m 2.001   \u001b[0m | \u001b[0m 482.2   \u001b[0m | \u001b[0m 30.4    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.172   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 476.7   \u001b[0m | \u001b[0m 39.47   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1556  \u001b[0m | \u001b[0m 0.329   \u001b[0m | \u001b[0m 0.757   \u001b[0m | \u001b[0m 0.9946  \u001b[0m | \u001b[0m 0.1913  \u001b[0m | \u001b[0m 19.37   \u001b[0m | \u001b[0m 470.4   \u001b[0m | \u001b[0m 30.97   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1739  \u001b[0m | \u001b[0m 0.1449  \u001b[0m | \u001b[0m 0.8675  \u001b[0m | \u001b[0m 0.3325  \u001b[0m | \u001b[0m 0.4067  \u001b[0m | \u001b[0m 3.433   \u001b[0m | \u001b[0m 486.2   \u001b[0m | \u001b[0m 21.48   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1652  \u001b[0m | \u001b[0m 0.21    \u001b[0m | \u001b[0m 0.6047  \u001b[0m | \u001b[0m 0.6062  \u001b[0m | \u001b[0m 0.3516  \u001b[0m | \u001b[0m 6.637   \u001b[0m | \u001b[0m 469.7   \u001b[0m | \u001b[0m 11.21   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.147   \u001b[0m | \u001b[0m 0.6105  \u001b[0m | \u001b[0m 0.1191  \u001b[0m | \u001b[0m 0.9869  \u001b[0m | \u001b[0m 0.1255  \u001b[0m | \u001b[0m 13.44   \u001b[0m | \u001b[0m 478.3   \u001b[0m | \u001b[0m 11.71   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1459  \u001b[0m | \u001b[0m 0.8109  \u001b[0m | \u001b[0m 0.7083  \u001b[0m | \u001b[0m 0.9913  \u001b[0m | \u001b[0m 0.02871 \u001b[0m | \u001b[0m 3.77    \u001b[0m | \u001b[0m 463.3   \u001b[0m | \u001b[0m 30.37   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-1.172   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.5537  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 22.51   \u001b[0m | \u001b[0m 476.8   \u001b[0m | \u001b[0m 16.45   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1529  \u001b[0m | \u001b[0m 0.9363  \u001b[0m | \u001b[0m 0.1795  \u001b[0m | \u001b[0m 0.4883  \u001b[0m | \u001b[0m 0.1914  \u001b[0m | \u001b[0m 2.162   \u001b[0m | \u001b[0m 481.5   \u001b[0m | \u001b[0m 12.13   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1625  \u001b[0m | \u001b[0m 0.3352  \u001b[0m | \u001b[0m 0.5933  \u001b[0m | \u001b[0m 0.05428 \u001b[0m | \u001b[0m 0.3882  \u001b[0m | \u001b[0m 9.058   \u001b[0m | \u001b[0m 491.5   \u001b[0m | \u001b[0m 11.35   \u001b[0m |\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m-0.1448  \u001b[0m | \u001b[95m 0.892   \u001b[0m | \u001b[95m 0.7394  \u001b[0m | \u001b[95m 0.3552  \u001b[0m | \u001b[95m 0.013   \u001b[0m | \u001b[95m 8.026   \u001b[0m | \u001b[95m 487.6   \u001b[0m | \u001b[95m 28.98   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.158   \u001b[0m | \u001b[0m 0.2722  \u001b[0m | \u001b[0m 0.1899  \u001b[0m | \u001b[0m 0.3119  \u001b[0m | \u001b[0m 0.2779  \u001b[0m | \u001b[0m 3.828   \u001b[0m | \u001b[0m 496.9   \u001b[0m | \u001b[0m 29.59   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1796  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 15.5    \u001b[0m | \u001b[0m 462.4   \u001b[0m | \u001b[0m 23.94   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1495  \u001b[0m | \u001b[0m 0.4074  \u001b[0m | \u001b[0m 0.4154  \u001b[0m | \u001b[0m 0.2302  \u001b[0m | \u001b[0m 0.1517  \u001b[0m | \u001b[0m 7.114   \u001b[0m | \u001b[0m 495.2   \u001b[0m | \u001b[0m 19.82   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1864  \u001b[0m | \u001b[0m 0.2487  \u001b[0m | \u001b[0m 0.2374  \u001b[0m | \u001b[0m 0.5722  \u001b[0m | \u001b[0m 0.4532  \u001b[0m | \u001b[0m 14.52   \u001b[0m | \u001b[0m 497.6   \u001b[0m | \u001b[0m 25.72   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1579  \u001b[0m | \u001b[0m 0.7532  \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 0.6553  \u001b[0m | \u001b[0m 0.4664  \u001b[0m | \u001b[0m 3.426   \u001b[0m | \u001b[0m 505.9   \u001b[0m | \u001b[0m 22.12   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Cluster LGBM Models Bayes: 100%|██████████| 4/4 [22:35<00:00, 338.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the list of training and validation data frames in a parallel fashion and run the Bayesian\n",
    "# optimization function for each cluster's data in parallel\n",
    "# Save the best params for each cluster to a list\n",
    "# Note that in the function call, we are subsetting the data frames to X and y data frames instead of doing\n",
    "# this beforehand like was done with the full model above\n",
    "with tqdm_joblib(tqdm(desc=\"Random Cluster LGBM Models Bayes\", \n",
    "                      total=len(train_df_rand_clust_ls))) as progress_bar:\n",
    "    rand_clust_mods_bayes = Parallel(n_jobs=4)(delayed(optimize_lgbm_w_bayes)(train_df_rand_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:], \n",
    "                                                                              train_df_rand_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                              val_df_rand_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                              val_df_rand_clust_ls[i].iloc[:,0]) for i in range(len(train_df_rand_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e314a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each entry in the list of params returned above, round and cast the params which \n",
    "# LGBM models require to be integers\n",
    "for n in range(len(rand_clust_mods_bayes)):\n",
    "    rand_clust_mods_bayes[n][\"max_depth\"] = int(round(rand_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    rand_clust_mods_bayes[n][\"n_estimators\"] = int(round(rand_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    rand_clust_mods_bayes[n][\"num_leaves\"] = int(round(rand_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93f05d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the train_val data frame with cluster assignments\n",
    "train_val_df_rand = train_val_df_full.merge(rand_clust, on=\"ts_index\")\n",
    "# Create a list of smaller data frames which contain data each from one cluster\n",
    "train_val_df_rand_ls = [df.reset_index(drop=True) for _,df in train_val_df_rand.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b2f4634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a light gbm model\n",
    "def train_lgbm(params, X, y):\n",
    "    \"\"\"Function takes in a set of params, X, and y data frames for training and returns a trained model\"\"\"\n",
    "    \n",
    "    # Create the model, using the passed params, a fixed random state, and a 'goss' boosting type\n",
    "    mod = LGBMRegressor(boosting_type='goss', **params, random_state=54321)  \n",
    "    # Fir the model to the provided data\n",
    "    mod.fit(X, y)\n",
    "    \n",
    "    # Return the fitted model\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea1fd6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Cluster LGBM Models Bayes Final:  25%|█▎   | 1/4 [00:50<02:31, 50.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1224  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1233  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1396  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1518  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1324  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1222  \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1239  \u001b[0m | \u001b[0m 0.5963  \u001b[0m | \u001b[0m 0.3886  \u001b[0m | \u001b[0m 0.004962\u001b[0m | \u001b[0m 0.1545  \u001b[0m | \u001b[0m 24.93   \u001b[0m | \u001b[0m 873.6   \u001b[0m | \u001b[0m 141.5   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1458  \u001b[0m | \u001b[0m 0.1704  \u001b[0m | \u001b[0m 0.4918  \u001b[0m | \u001b[0m 0.3949  \u001b[0m | \u001b[0m 0.3943  \u001b[0m | \u001b[0m 15.21   \u001b[0m | \u001b[0m 410.9   \u001b[0m | \u001b[0m 36.46   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.9314  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 849.0   \u001b[0m | \u001b[0m 108.3   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1561  \u001b[0m | \u001b[0m 0.9932  \u001b[0m | \u001b[0m 0.7939  \u001b[0m | \u001b[0m 0.9013  \u001b[0m | \u001b[0m 0.4695  \u001b[0m | \u001b[0m 13.08   \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 53.08   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1323  \u001b[0m | \u001b[0m 0.8767  \u001b[0m | \u001b[0m 0.08573 \u001b[0m | \u001b[0m 0.01561 \u001b[0m | \u001b[0m 0.4092  \u001b[0m | \u001b[0m 4.512   \u001b[0m | \u001b[0m 439.2   \u001b[0m | \u001b[0m 12.11   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1317  \u001b[0m | \u001b[0m 0.3661  \u001b[0m | \u001b[0m 0.08135 \u001b[0m | \u001b[0m 0.01251 \u001b[0m | \u001b[0m 0.2102  \u001b[0m | \u001b[0m 22.6    \u001b[0m | \u001b[0m 910.3   \u001b[0m | \u001b[0m 144.8   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1319  \u001b[0m | \u001b[0m 0.1064  \u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.02659 \u001b[0m | \u001b[0m 0.02738 \u001b[0m | \u001b[0m 2.001   \u001b[0m | \u001b[0m 936.5   \u001b[0m | \u001b[0m 19.93   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1339  \u001b[0m | \u001b[0m 0.6137  \u001b[0m | \u001b[0m 0.5026  \u001b[0m | \u001b[0m 0.1901  \u001b[0m | \u001b[0m 0.3695  \u001b[0m | \u001b[0m 21.85   \u001b[0m | \u001b[0m 977.1   \u001b[0m | \u001b[0m 12.71   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1263  \u001b[0m | \u001b[0m 0.4313  \u001b[0m | \u001b[0m 0.296   \u001b[0m | \u001b[0m 0.3772  \u001b[0m | \u001b[0m 0.2663  \u001b[0m | \u001b[0m 5.454   \u001b[0m | \u001b[0m 506.5   \u001b[0m | \u001b[0m 49.14   \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m-0.1183  \u001b[0m | \u001b[95m 0.9977  \u001b[0m | \u001b[95m 0.8536  \u001b[0m | \u001b[95m 0.3947  \u001b[0m | \u001b[95m 0.1575  \u001b[0m | \u001b[95m 21.3    \u001b[0m | \u001b[95m 526.5   \u001b[0m | \u001b[95m 10.9    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1193  \u001b[0m | \u001b[0m 0.4284  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.4892  \u001b[0m | \u001b[0m 0.1167  \u001b[0m | \u001b[0m 10.84   \u001b[0m | \u001b[0m 551.5   \u001b[0m | \u001b[0m 44.18   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.121   \u001b[0m | \u001b[0m 0.8395  \u001b[0m | \u001b[0m 0.8915  \u001b[0m | \u001b[0m 0.8235  \u001b[0m | \u001b[0m 0.2037  \u001b[0m | \u001b[0m 21.21   \u001b[0m | \u001b[0m 576.3   \u001b[0m | \u001b[0m 13.13   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1704  \u001b[0m | \u001b[0m 0.4911  \u001b[0m | \u001b[0m 0.03052 \u001b[0m | \u001b[0m 0.01225 \u001b[0m | \u001b[0m 0.4859  \u001b[0m | \u001b[0m 18.58   \u001b[0m | \u001b[0m 596.6   \u001b[0m | \u001b[0m 56.19   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1273  \u001b[0m | \u001b[0m 0.745   \u001b[0m | \u001b[0m 0.01692 \u001b[0m | \u001b[0m 0.2737  \u001b[0m | \u001b[0m 0.2017  \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 531.8   \u001b[0m | \u001b[0m 81.8    \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-0.1182  \u001b[0m | \u001b[95m 0.6724  \u001b[0m | \u001b[95m 0.02329 \u001b[0m | \u001b[95m 0.229   \u001b[0m | \u001b[95m 0.03735 \u001b[0m | \u001b[95m 3.303   \u001b[0m | \u001b[95m 492.4   \u001b[0m | \u001b[95m 94.19   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.128   \u001b[0m | \u001b[0m 0.4855  \u001b[0m | \u001b[0m 0.4066  \u001b[0m | \u001b[0m 0.6756  \u001b[0m | \u001b[0m 0.3657  \u001b[0m | \u001b[0m 4.415   \u001b[0m | \u001b[0m 522.8   \u001b[0m | \u001b[0m 125.4   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1647  \u001b[0m | \u001b[0m 0.8927  \u001b[0m | \u001b[0m 0.4648  \u001b[0m | \u001b[0m 0.2772  \u001b[0m | \u001b[0m 0.4642  \u001b[0m | \u001b[0m 24.05   \u001b[0m | \u001b[0m 484.3   \u001b[0m | \u001b[0m 134.1   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.9333  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7345  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 563.4   \u001b[0m | \u001b[0m 103.1   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1531  \u001b[0m | \u001b[0m 0.7757  \u001b[0m | \u001b[0m 0.9016  \u001b[0m | \u001b[0m 0.8712  \u001b[0m | \u001b[0m 0.4301  \u001b[0m | \u001b[0m 22.92   \u001b[0m | \u001b[0m 490.6   \u001b[0m | \u001b[0m 66.87   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.121   \u001b[0m | \u001b[0m 0.2478  \u001b[0m | \u001b[0m 0.3913  \u001b[0m | \u001b[0m 0.843   \u001b[0m | \u001b[0m 0.1661  \u001b[0m | \u001b[0m 17.08   \u001b[0m | \u001b[0m 620.4   \u001b[0m | \u001b[0m 12.62   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1372  \u001b[0m | \u001b[0m 0.3752  \u001b[0m | \u001b[0m 0.8455  \u001b[0m | \u001b[0m 0.1209  \u001b[0m | \u001b[0m 0.4564  \u001b[0m | \u001b[0m 4.2     \u001b[0m | \u001b[0m 645.4   \u001b[0m | \u001b[0m 42.94   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.128   \u001b[0m | \u001b[0m 0.8913  \u001b[0m | \u001b[0m 0.08761 \u001b[0m | \u001b[0m 0.03195 \u001b[0m | \u001b[0m 0.314   \u001b[0m | \u001b[0m 22.28   \u001b[0m | \u001b[0m 661.9   \u001b[0m | \u001b[0m 12.52   \u001b[0m |\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m-0.1147  \u001b[0m | \u001b[95m 0.8615  \u001b[0m | \u001b[95m 0.01578 \u001b[0m | \u001b[95m 0.5012  \u001b[0m | \u001b[95m 0.02532 \u001b[0m | \u001b[95m 25.0    \u001b[0m | \u001b[95m 687.0   \u001b[0m | \u001b[95m 49.52   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1336  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 701.1   \u001b[0m | \u001b[0m 18.79   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6238248361897051, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6238248361897051\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7918038353977315, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7918038353977315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Cluster LGBM Models Bayes Final: 100%|█████| 4/4 [01:24<00:00, 21.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each set of model params found above, loop through the list of full train_val data and train a model\n",
    "# Again, this is done in parallel with the models saved to a list, and again the X and y data frames are created\n",
    "# in the function call as opposed to before\n",
    "with tqdm_joblib(tqdm(desc=\"Random Cluster LGBM Models Bayes Final\", \n",
    "                      total=len(train_val_df_rand_ls))) as progress_bar:\n",
    "    rand_clust_mods_bayes_final = Parallel(n_jobs=4)(delayed(train_lgbm)(rand_clust_mods_bayes[i], \n",
    "                                                                         train_val_df_rand_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:], \n",
    "                                                                         train_val_df_rand_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(train_val_df_rand_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59978386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the models trained above, save them to a file\n",
    "for model_no in range(len(rand_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/Random Cluster/model_{model_no}\"\n",
    "    joblib.dump(rand_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9bddc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clust_mods_bayes_final = list()\n",
    "\n",
    "# For each of the models trained above, save them to a file\n",
    "for model_no in range(len(train_val_df_rand_ls)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/Random Cluster/model_{model_no}\"\n",
    "    rand_clust_mods_bayes_final.append(joblib.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7df222a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Cluster LGBM Models Bayes Residuals: 100%|█| 4/4 [00:11<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each of the above models, compute the residuals. Loop, in parallel, through the list of models,\n",
    "# create the X and y data frames the model was trained on, and return a list of residuals. These lists of \n",
    "# residuals are saved in a list\n",
    "with tqdm_joblib(tqdm(desc=\"Random Cluster LGBM Models Bayes Residuals\", \n",
    "                      total=len(rand_clust_mods_bayes_final))) as progress_bar:\n",
    "    rand_clust_mods_bayes_resid = Parallel(n_jobs=4)(delayed(compute_lgbm_residuals)(rand_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_rand_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_rand_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(rand_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1cf6f6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111720"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_clust_mods_bayes_resid[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4a22889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[4.236943301123034, 9.797984935874439, 3.33155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[-19.96974756315297, 2.609522412481862, 8.9609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[-12.854841077574974, -22.138411981257377, -36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[-6.423664164266484, 3.396377552591389, -51.33...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                           residual\n",
       "0        1  [4.236943301123034, 9.797984935874439, 3.33155...\n",
       "1        2  [-19.96974756315297, 2.609522412481862, 8.9609...\n",
       "2        3  [-12.854841077574974, -22.138411981257377, -36...\n",
       "3        4  [-6.423664164266484, 3.396377552591389, -51.33..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_clust_res_df = pd.DataFrame({'cluster': list({(i+1): rand_clust_mods_bayes_resid[i] for i in range(len(rand_clust_mods_bayes_resid))}.keys()),\n",
    "                                  'residual': list({(i+1): rand_clust_mods_bayes_resid[i] for i in range(len(rand_clust_mods_bayes_resid))}.values())})\n",
    "\n",
    "rand_clust_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45829798",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clust_res_df.to_csv(\"Results/Global/LightGBM Bayes/Random Cluster/residual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84991eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the test data with the cluster assignments\n",
    "test_df_full_rand = test_df_full.merge(rand_clust, on=\"ts_index\")\n",
    "# Split the test data frame into a list of data frames, each with data from one cluster\n",
    "test_df_full_rand_ls = [df.reset_index(drop=True) for _,df in test_df_full_rand.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f6e3f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Cluster LGBM Models Bayes Test Preds: 100%|█| 4/4 [00:02<00:00,  1.47it/s\n"
     ]
    }
   ],
   "source": [
    "# For each model, loop in parallel, compute the test preds as a data frame and save those data frames to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Random Cluster LGBM Models Bayes Test Preds\", \n",
    "                      total=len(rand_clust_mods_bayes_final))) as progress_bar:\n",
    "    rand_clust_mods_bayes_test_preds = Parallel(n_jobs=4)(delayed(compute_lgbm_test_preds)(rand_clust_mods_bayes_final[i],\n",
    "                                                                                           test_df_full_rand_ls[i],\n",
    "                                                                                           lag_n\n",
    "                                                                                          ) for i in range(len(rand_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7dedafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the above created data frames of test preds into one data frame\n",
    "rand_clust_bayes_test_preds_df = pd.concat(rand_clust_mods_bayes_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc208a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this one data frame of test preds, compute prediction performance\n",
    "rand_clust_bayes_test_perf = compute_lgbm_test_perf(rand_clust_bayes_test_preds_df,\n",
    "                                                    test_df_full_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad2d607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled performance metrics to the data frame\n",
    "rand_clust_bayes_test_perf['nrmse'] = rand_clust_bayes_test_perf['rmse']/rand_clust_bayes_test_perf['mean']\n",
    "rand_clust_bayes_test_perf['smae'] = rand_clust_bayes_test_perf['mae']/rand_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f1a50e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      31.254831\n",
       "mae       20.767924\n",
       "mean     265.435072\n",
       "nrmse      0.142022\n",
       "smae       0.096263\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of prediction performance metrics\n",
    "rand_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f3a8926d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9974bd807e3b419798e7d9fbfd3743bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52270b5bf694499a7c766e754e0e575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1444  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1475  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1705  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1831  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1584  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1407  \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1477  \u001b[0m | \u001b[0m 0.4405  \u001b[0m | \u001b[0m 0.1374  \u001b[0m | \u001b[0m 0.64    \u001b[0m | \u001b[0m 0.3496  \u001b[0m | \u001b[0m 2.775   \u001b[0m | \u001b[0m 837.2   \u001b[0m | \u001b[0m 144.8   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1854  \u001b[0m | \u001b[0m 0.6162  \u001b[0m | \u001b[0m 0.6006  \u001b[0m | \u001b[0m 0.7334  \u001b[0m | \u001b[0m 0.4287  \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 832.8   \u001b[0m | \u001b[0m 148.4   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.155   \u001b[0m | \u001b[0m 0.1274  \u001b[0m | \u001b[0m 0.9705  \u001b[0m | \u001b[0m 0.1708  \u001b[0m | \u001b[0m 0.3104  \u001b[0m | \u001b[0m 17.45   \u001b[0m | \u001b[0m 479.4   \u001b[0m | \u001b[0m 19.92   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1519  \u001b[0m | \u001b[0m 0.7474  \u001b[0m | \u001b[0m 0.1242  \u001b[0m | \u001b[0m 0.2853  \u001b[0m | \u001b[0m 0.3626  \u001b[0m | \u001b[0m 2.616   \u001b[0m | \u001b[0m 826.6   \u001b[0m | \u001b[0m 141.9   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.1386  \u001b[0m | \u001b[95m 0.2329  \u001b[0m | \u001b[95m 0.1652  \u001b[0m | \u001b[95m 0.1211  \u001b[0m | \u001b[95m 0.09329 \u001b[0m | \u001b[95m 10.94   \u001b[0m | \u001b[95m 471.0   \u001b[0m | \u001b[95m 29.59   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1634  \u001b[0m | \u001b[0m 0.8882  \u001b[0m | \u001b[0m 0.8457  \u001b[0m | \u001b[0m 0.6157  \u001b[0m | \u001b[0m 0.4738  \u001b[0m | \u001b[0m 3.654   \u001b[0m | \u001b[0m 470.2   \u001b[0m | \u001b[0m 23.45   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1453  \u001b[0m | \u001b[0m 0.812   \u001b[0m | \u001b[0m 0.03873 \u001b[0m | \u001b[0m 0.6878  \u001b[0m | \u001b[0m 0.2175  \u001b[0m | \u001b[0m 17.47   \u001b[0m | \u001b[0m 470.6   \u001b[0m | \u001b[0m 31.43   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1693  \u001b[0m | \u001b[0m 0.3124  \u001b[0m | \u001b[0m 0.6753  \u001b[0m | \u001b[0m 0.8881  \u001b[0m | \u001b[0m 0.3906  \u001b[0m | \u001b[0m 11.41   \u001b[0m | \u001b[0m 463.5   \u001b[0m | \u001b[0m 32.8    \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.162   \u001b[0m | \u001b[0m 0.9849  \u001b[0m | \u001b[0m 0.6193  \u001b[0m | \u001b[0m 0.2947  \u001b[0m | \u001b[0m 0.3759  \u001b[0m | \u001b[0m 13.29   \u001b[0m | \u001b[0m 476.3   \u001b[0m | \u001b[0m 27.44   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.058   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.06184 \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 14.07   \u001b[0m | \u001b[0m 469.3   \u001b[0m | \u001b[0m 26.75   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1439  \u001b[0m | \u001b[0m 0.329   \u001b[0m | \u001b[0m 0.757   \u001b[0m | \u001b[0m 0.9946  \u001b[0m | \u001b[0m 0.1913  \u001b[0m | \u001b[0m 19.37   \u001b[0m | \u001b[0m 470.4   \u001b[0m | \u001b[0m 30.97   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1489  \u001b[0m | \u001b[0m 0.6827  \u001b[0m | \u001b[0m 0.3388  \u001b[0m | \u001b[0m 0.7134  \u001b[0m | \u001b[0m 0.255   \u001b[0m | \u001b[0m 17.99   \u001b[0m | \u001b[0m 467.8   \u001b[0m | \u001b[0m 32.84   \u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-0.1353  \u001b[0m | \u001b[95m 0.8305  \u001b[0m | \u001b[95m 0.5304  \u001b[0m | \u001b[95m 0.2073  \u001b[0m | \u001b[95m 0.06217 \u001b[0m | \u001b[95m 4.62    \u001b[0m | \u001b[95m 838.2   \u001b[0m | \u001b[95m 142.2   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.143   \u001b[0m | \u001b[0m 0.1812  \u001b[0m | \u001b[0m 0.9955  \u001b[0m | \u001b[0m 0.9632  \u001b[0m | \u001b[0m 0.2494  \u001b[0m | \u001b[0m 2.578   \u001b[0m | \u001b[0m 828.1   \u001b[0m | \u001b[0m 144.8   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1372  \u001b[0m | \u001b[0m 0.8495  \u001b[0m | \u001b[0m 0.715   \u001b[0m | \u001b[0m 0.3199  \u001b[0m | \u001b[0m 0.08774 \u001b[0m | \u001b[0m 6.741   \u001b[0m | \u001b[0m 835.0   \u001b[0m | \u001b[0m 145.0   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1361  \u001b[0m | \u001b[0m 0.8966  \u001b[0m | \u001b[0m 0.4975  \u001b[0m | \u001b[0m 0.1643  \u001b[0m | \u001b[0m 0.058   \u001b[0m | \u001b[0m 15.25   \u001b[0m | \u001b[0m 474.1   \u001b[0m | \u001b[0m 19.02   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1507  \u001b[0m | \u001b[0m 0.1023  \u001b[0m | \u001b[0m 0.09793 \u001b[0m | \u001b[0m 0.8345  \u001b[0m | \u001b[0m 0.3051  \u001b[0m | \u001b[0m 2.818   \u001b[0m | \u001b[0m 841.9   \u001b[0m | \u001b[0m 144.7   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1365  \u001b[0m | \u001b[0m 0.4863  \u001b[0m | \u001b[0m 0.8563  \u001b[0m | \u001b[0m 0.1751  \u001b[0m | \u001b[0m 0.07443 \u001b[0m | \u001b[0m 4.213   \u001b[0m | \u001b[0m 831.5   \u001b[0m | \u001b[0m 145.0   \u001b[0m |\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m-0.1348  \u001b[0m | \u001b[95m 0.8833  \u001b[0m | \u001b[95m 0.4164  \u001b[0m | \u001b[95m 0.3832  \u001b[0m | \u001b[95m 0.04955 \u001b[0m | \u001b[95m 9.271   \u001b[0m | \u001b[95m 472.8   \u001b[0m | \u001b[95m 31.99   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1485  \u001b[0m | \u001b[0m 0.6257  \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 0.6586  \u001b[0m | \u001b[0m 0.2213  \u001b[0m | \u001b[0m 7.136   \u001b[0m | \u001b[0m 830.9   \u001b[0m | \u001b[0m 142.3   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1775  \u001b[0m | \u001b[0m 0.9257  \u001b[0m | \u001b[0m 0.5745  \u001b[0m | \u001b[0m 0.4407  \u001b[0m | \u001b[0m 0.4245  \u001b[0m | \u001b[0m 5.692   \u001b[0m | \u001b[0m 839.3   \u001b[0m | \u001b[0m 148.0   \u001b[0m |\n",
      "| \u001b[95m 28      \u001b[0m | \u001b[95m-0.1344  \u001b[0m | \u001b[95m 0.8699  \u001b[0m | \u001b[95m 0.3702  \u001b[0m | \u001b[95m 0.1234  \u001b[0m | \u001b[95m 0.02506 \u001b[0m | \u001b[95m 19.68   \u001b[0m | \u001b[95m 475.3   \u001b[0m | \u001b[95m 17.95   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1347  \u001b[0m | \u001b[0m 0.37    \u001b[0m | \u001b[0m 0.627   \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 0.04239 \u001b[0m | \u001b[0m 7.315   \u001b[0m | \u001b[0m 825.8   \u001b[0m | \u001b[0m 144.9   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1402  \u001b[0m | \u001b[0m 0.1104  \u001b[0m | \u001b[0m 0.2138  \u001b[0m | \u001b[0m 0.8432  \u001b[0m | \u001b[0m 0.0597  \u001b[0m | \u001b[0m 8.928   \u001b[0m | \u001b[0m 836.5   \u001b[0m | \u001b[0m 141.1   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7393709098295614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7393709098295614\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.35518632902047587, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.35518632902047587\n",
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1328  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1345  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1458  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1924  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1429  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1649  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1654  \u001b[0m | \u001b[0m 0.1823  \u001b[0m | \u001b[0m 0.2334  \u001b[0m | \u001b[0m 0.3629  \u001b[0m | \u001b[0m 0.06587 \u001b[0m | \u001b[0m 17.26   \u001b[0m | \u001b[0m 859.2   \u001b[0m | \u001b[0m 141.3   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1386  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.2829  \u001b[0m | \u001b[0m 0.9203  \u001b[0m | \u001b[0m 0.08668 \u001b[0m | \u001b[0m 8.428   \u001b[0m | \u001b[0m 942.3   \u001b[0m | \u001b[0m 106.7   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1578  \u001b[0m | \u001b[0m 0.6154  \u001b[0m | \u001b[0m 0.5809  \u001b[0m | \u001b[0m 0.5974  \u001b[0m | \u001b[0m 0.3896  \u001b[0m | \u001b[0m 23.0    \u001b[0m | \u001b[0m 433.1   \u001b[0m | \u001b[0m 83.41   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1604  \u001b[0m | \u001b[0m 0.2707  \u001b[0m | \u001b[0m 0.3919  \u001b[0m | \u001b[0m 0.8713  \u001b[0m | \u001b[0m 0.2398  \u001b[0m | \u001b[0m 21.29   \u001b[0m | \u001b[0m 182.6   \u001b[0m | \u001b[0m 128.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1397  \u001b[0m | \u001b[0m 0.5174  \u001b[0m | \u001b[0m 0.2394  \u001b[0m | \u001b[0m 0.01523 \u001b[0m | \u001b[0m 0.3594  \u001b[0m | \u001b[0m 2.433   \u001b[0m | \u001b[0m 593.3   \u001b[0m | \u001b[0m 126.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1347  \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 0.517   \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 0.09298 \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 583.4   \u001b[0m | \u001b[0m 123.1   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1365  \u001b[0m | \u001b[0m 0.957   \u001b[0m | \u001b[0m 0.5047  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.2706  \u001b[0m | \u001b[0m 8.573   \u001b[0m | \u001b[0m 757.1   \u001b[0m | \u001b[0m 17.0    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1577  \u001b[0m | \u001b[0m 0.2656  \u001b[0m | \u001b[0m 0.04668 \u001b[0m | \u001b[0m 0.03001 \u001b[0m | \u001b[0m 0.1727  \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 861.6   \u001b[0m | \u001b[0m 139.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1393  \u001b[0m | \u001b[0m 0.8199  \u001b[0m | \u001b[0m 0.4933  \u001b[0m | \u001b[0m 0.7328  \u001b[0m | \u001b[0m 0.2643  \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 398.9   \u001b[0m | \u001b[0m 92.87   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2032  \u001b[0m | \u001b[0m 0.5136  \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 0.06973 \u001b[0m | \u001b[0m 0.4773  \u001b[0m | \u001b[0m 10.62   \u001b[0m | \u001b[0m 642.0   \u001b[0m | \u001b[0m 97.73   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1485  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.371   \u001b[0m | \u001b[0m 9.194   \u001b[0m | \u001b[0m 969.5   \u001b[0m | \u001b[0m 23.1    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1558  \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.0695  \u001b[0m | \u001b[0m 0.3948  \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 27.02   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1381  \u001b[0m | \u001b[0m 0.9134  \u001b[0m | \u001b[0m 0.3416  \u001b[0m | \u001b[0m 0.2057  \u001b[0m | \u001b[0m 0.2121  \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 418.8   \u001b[0m | \u001b[0m 120.2   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1376  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.5603  \u001b[0m | \u001b[0m 0.4809  \u001b[0m | \u001b[0m 0.09778 \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 351.6   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1435  \u001b[0m | \u001b[0m 0.5316  \u001b[0m | \u001b[0m 0.3662  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.377   \u001b[0m | \u001b[0m 2.832   \u001b[0m | \u001b[0m 855.2   \u001b[0m | \u001b[0m 24.01   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1573  \u001b[0m | \u001b[0m 0.3696  \u001b[0m | \u001b[0m 0.9666  \u001b[0m | \u001b[0m 0.0882  \u001b[0m | \u001b[0m 0.3123  \u001b[0m | \u001b[0m 22.58   \u001b[0m | \u001b[0m 694.0   \u001b[0m | \u001b[0m 115.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1554  \u001b[0m | \u001b[0m 0.2374  \u001b[0m | \u001b[0m 0.5845  \u001b[0m | \u001b[0m 0.6013  \u001b[0m | \u001b[0m 0.06929 \u001b[0m | \u001b[0m 24.59   \u001b[0m | \u001b[0m 646.7   \u001b[0m | \u001b[0m 126.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1344  \u001b[0m | \u001b[0m 0.6942  \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.7711  \u001b[0m | \u001b[0m 0.1554  \u001b[0m | \u001b[0m 16.79   \u001b[0m | \u001b[0m 331.1   \u001b[0m | \u001b[0m 40.78   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1683  \u001b[0m | \u001b[0m 0.1268  \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 0.7912  \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 18.31   \u001b[0m | \u001b[0m 255.6   \u001b[0m | \u001b[0m 68.42   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.142   \u001b[0m | \u001b[0m 0.7789  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.5176  \u001b[0m | \u001b[0m 0.2534  \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 925.9   \u001b[0m | \u001b[0m 114.4   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1378  \u001b[0m | \u001b[0m 0.5703  \u001b[0m | \u001b[0m 0.1937  \u001b[0m | \u001b[0m 0.677   \u001b[0m | \u001b[0m 0.2474  \u001b[0m | \u001b[0m 2.781   \u001b[0m | \u001b[0m 583.6   \u001b[0m | \u001b[0m 123.5   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1614  \u001b[0m | \u001b[0m 0.4295  \u001b[0m | \u001b[0m 0.5138  \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 0.3808  \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 471.2   \u001b[0m | \u001b[0m 24.53   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1412  \u001b[0m | \u001b[0m 0.9737  \u001b[0m | \u001b[0m 0.6132  \u001b[0m | \u001b[0m 0.2585  \u001b[0m | \u001b[0m 0.3116  \u001b[0m | \u001b[0m 16.09   \u001b[0m | \u001b[0m 332.1   \u001b[0m | \u001b[0m 43.31   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.144   \u001b[0m | \u001b[0m 0.2755  \u001b[0m | \u001b[0m 0.8272  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.401   \u001b[0m | \u001b[0m 2.293   \u001b[0m | \u001b[0m 582.6   \u001b[0m | \u001b[0m 121.0   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.37021090771695964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.37021090771695964\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1233648126674155, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1233648126674155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01577891310835551, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01577891310835551\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5011760296102477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5011760296102477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b89adc4e7bc4290b685cac5d8b3d748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9621dfb21504e4d8299c4aa989a6c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty list to save PI data frames\n",
    "rand_clust_test_pred_int = list()\n",
    "# Loop through the list of prediction data frames\n",
    "for i in range(len(rand_clust_mods_bayes_test_preds)):\n",
    "    # For each one, compute bootstrap PIs and save that data frame to the above list\n",
    "    rand_clust_test_pred_int.append(compute_lgbm_boostrap_int(rand_clust_mods_bayes_test_preds[i], \n",
    "                                                              rand_clust_mods_bayes_resid[i], \n",
    "                                                              n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9655a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster\n",
    "for n in range(1, len(rand_clust_test_pred_int)+1):\n",
    "    # Get the true values for the target for that cluster\n",
    "    y_actual_sub = test_df_full_rand.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    # Add those true values as a column to that cluster's PI data frame\n",
    "    rand_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74bee8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all prediction interval data frames from each cluster into one data frame\n",
    "rand_clust_test_pred_int_df = pd.concat(rand_clust_test_pred_int)\n",
    "# for clust_test_pred_int_df in rand_clust_test_pred_int:\n",
    "#     rand_clust_test_pred_int_df = rand_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "605c4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For that one data frame, add columns which compute the 95% and 80% PI scores for each prediction\n",
    "rand_clust_test_pred_int_df['int_95_score'] = interval_score(rand_clust_test_pred_int_df['actual'],\n",
    "                                                             rand_clust_test_pred_int_df['lo_95'],\n",
    "                                                             rand_clust_test_pred_int_df['hi_95'],\n",
    "                                                             0.95\n",
    "                                                            )\n",
    "\n",
    "rand_clust_test_pred_int_df['int_80_score'] = interval_score(rand_clust_test_pred_int_df['actual'],\n",
    "                                                             rand_clust_test_pred_int_df['lo_80'],\n",
    "                                                             rand_clust_test_pred_int_df['hi_80'],\n",
    "                                                             0.80\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "078814c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.709929\n",
       "lo_95           212.058140\n",
       "hi_95           321.068173\n",
       "lo_80           238.401754\n",
       "hi_80           293.847885\n",
       "actual          265.435072\n",
       "int_95_score    233.998928\n",
       "int_80_score    123.902825\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of those PI scores\n",
    "rand_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7674645c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_clust_test_pred_int_df.ts_index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b88acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_clust_test_pred_int_df_grouped = rand_clust_test_pred_int_df.groupby(\"ts_index\")\\\n",
    ".agg({'int_95_score':'mean', 'int_80_score':'mean', 'actual':'mean'}).reset_index()\n",
    "\n",
    "rand_clust_test_pred_int_df_grouped['int_95_score_scaled'] = rand_clust_test_pred_int_df_grouped['int_95_score']/rand_clust_test_pred_int_df_grouped['actual']\n",
    "rand_clust_test_pred_int_df_grouped['int_80_score_scaled'] = rand_clust_test_pred_int_df_grouped['int_80_score']/rand_clust_test_pred_int_df_grouped['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a396be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_80_score_scaled    0.588199\n",
       "int_95_score_scaled    1.052794\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_clust_test_pred_int_df_grouped[['int_80_score_scaled', 'int_95_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "76644479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI data frame to a csv file\n",
    "rand_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/Random Cluster/test_pred_intervals.csv\", \n",
    "                                   index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65877c3",
   "metadata": {},
   "source": [
    "# Train and Test - Highway System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d01939ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused variables\n",
    "del train_df_rand_clust_ls\n",
    "del train_df_rand_clust\n",
    "del val_df_rand_clust_ls\n",
    "del val_df_rand_clust\n",
    "del rand_clust_mods_bayes\n",
    "del rand_clust\n",
    "del train_val_df_rand\n",
    "del train_val_df_rand_ls\n",
    "del rand_clust_mods_bayes_final\n",
    "del rand_clust_mods_bayes_resid\n",
    "del test_df_full_rand\n",
    "del test_df_full_rand_ls\n",
    "del rand_clust_mods_bayes_test_preds\n",
    "del rand_clust_bayes_test_preds_df\n",
    "del rand_clust_bayes_test_perf\n",
    "del rand_clust_test_pred_int\n",
    "del rand_clust_test_pred_int_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6b579e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "283bc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster assignments for the highway systems based on the no of sensors for each system\n",
    "highway_clust = pd.DataFrame({\"ts_index\": np.arange(1, 77),\n",
    "                                    \"cluster\": [1]*38 + [2]*19 + [3]*19}\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29f1beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge training, validation, train_val, and test data with cluster assignments\n",
    "train_df_full_highway = train_df_full.merge(highway_clust, on=\"ts_index\")\n",
    "val_df_full_highway = val_df_full.merge(highway_clust, on=\"ts_index\")\n",
    "train_val_df_full_highway = train_val_df_full.merge(highway_clust, on=\"ts_index\")\n",
    "test_df_full_highway = test_df_full.merge(highway_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d9656ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and validation data frames into a list of data frames which each contain data for 1 cluster\n",
    "train_df_highway_clust_ls = [df.reset_index(drop=True) for _,df in train_df_full_highway.groupby(\"cluster\")]\n",
    "val_df_highway_clust_ls = [df.reset_index(drop=True) for _,df in val_df_full_highway.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a5ad172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway System LGBM Models Bayes:  67%|██████▋   | 2/3 [18:55<08:36, 516.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1667  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1687  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1949  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2138  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.186   \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.163   \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.8959  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5833  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 8.072   \u001b[0m | \u001b[0m 842.2   \u001b[0m | \u001b[0m 145.5   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1727  \u001b[0m | \u001b[0m 0.7325  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.9323  \u001b[0m | \u001b[0m 0.2438  \u001b[0m | \u001b[0m 11.23   \u001b[0m | \u001b[0m 464.7   \u001b[0m | \u001b[0m 31.1    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1961  \u001b[0m | \u001b[0m 0.5005  \u001b[0m | \u001b[0m 0.01999 \u001b[0m | \u001b[0m 0.6197  \u001b[0m | \u001b[0m 0.4357  \u001b[0m | \u001b[0m 14.53   \u001b[0m | \u001b[0m 458.2   \u001b[0m | \u001b[0m 21.54   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.1592  \u001b[0m | \u001b[95m 0.6376  \u001b[0m | \u001b[95m 0.4625  \u001b[0m | \u001b[95m 0.1236  \u001b[0m | \u001b[95m 0.1021  \u001b[0m | \u001b[95m 23.37   \u001b[0m | \u001b[95m 468.1   \u001b[0m | \u001b[95m 32.42   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1806  \u001b[0m | \u001b[0m 0.6459  \u001b[0m | \u001b[0m 0.5022  \u001b[0m | \u001b[0m 0.3833  \u001b[0m | \u001b[0m 0.2998  \u001b[0m | \u001b[0m 14.91   \u001b[0m | \u001b[0m 478.1   \u001b[0m | \u001b[0m 34.38   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1735  \u001b[0m | \u001b[0m 0.4375  \u001b[0m | \u001b[0m 0.04202 \u001b[0m | \u001b[0m 0.7955  \u001b[0m | \u001b[0m 0.237   \u001b[0m | \u001b[0m 20.64   \u001b[0m | \u001b[0m 455.9   \u001b[0m | \u001b[0m 39.71   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1733  \u001b[0m | \u001b[0m 0.1885  \u001b[0m | \u001b[0m 0.8531  \u001b[0m | \u001b[0m 0.4953  \u001b[0m | \u001b[0m 0.1927  \u001b[0m | \u001b[0m 16.33   \u001b[0m | \u001b[0m 466.8   \u001b[0m | \u001b[0m 46.48   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1619  \u001b[0m | \u001b[0m 0.1772  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.02178 \u001b[0m | \u001b[0m 8.134   \u001b[0m | \u001b[0m 454.9   \u001b[0m | \u001b[0m 48.16   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1836  \u001b[0m | \u001b[0m 0.6612  \u001b[0m | \u001b[0m 0.2922  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.3089  \u001b[0m | \u001b[0m 9.861   \u001b[0m | \u001b[0m 445.1   \u001b[0m | \u001b[0m 35.89   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1714  \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 0.1672  \u001b[0m | \u001b[0m 0.2896  \u001b[0m | \u001b[0m 0.1998  \u001b[0m | \u001b[0m 17.96   \u001b[0m | \u001b[0m 445.2   \u001b[0m | \u001b[0m 50.18   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1992  \u001b[0m | \u001b[0m 0.2151  \u001b[0m | \u001b[0m 0.2711  \u001b[0m | \u001b[0m 0.9424  \u001b[0m | \u001b[0m 0.3469  \u001b[0m | \u001b[0m 18.57   \u001b[0m | \u001b[0m 459.4   \u001b[0m | \u001b[0m 59.82   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1804  \u001b[0m | \u001b[0m 0.4512  \u001b[0m | \u001b[0m 0.9963  \u001b[0m | \u001b[0m 0.5604  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 3.478   \u001b[0m | \u001b[0m 441.4   \u001b[0m | \u001b[0m 50.45   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1666  \u001b[0m | \u001b[0m 0.568   \u001b[0m | \u001b[0m 0.1615  \u001b[0m | \u001b[0m 0.5732  \u001b[0m | \u001b[0m 0.4128  \u001b[0m | \u001b[0m 2.141   \u001b[0m | \u001b[0m 466.2   \u001b[0m | \u001b[0m 42.57   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1648  \u001b[0m | \u001b[0m 0.4613  \u001b[0m | \u001b[0m 0.3655  \u001b[0m | \u001b[0m 0.2477  \u001b[0m | \u001b[0m 0.1746  \u001b[0m | \u001b[0m 6.519   \u001b[0m | \u001b[0m 476.4   \u001b[0m | \u001b[0m 53.09   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1811  \u001b[0m | \u001b[0m 0.7953  \u001b[0m | \u001b[0m 0.1656  \u001b[0m | \u001b[0m 0.5413  \u001b[0m | \u001b[0m 0.3684  \u001b[0m | \u001b[0m 5.001   \u001b[0m | \u001b[0m 462.3   \u001b[0m | \u001b[0m 58.62   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.2079  \u001b[0m | \u001b[0m 0.862   \u001b[0m | \u001b[0m 0.7388  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.4933  \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 481.8   \u001b[0m | \u001b[0m 23.02   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.217   \u001b[0m | \u001b[0m 0.8796  \u001b[0m | \u001b[0m 0.6485  \u001b[0m | \u001b[0m 0.6202  \u001b[0m | \u001b[0m 0.4539  \u001b[0m | \u001b[0m 18.24   \u001b[0m | \u001b[0m 483.6   \u001b[0m | \u001b[0m 49.97   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.2164  \u001b[0m | \u001b[0m 0.1114  \u001b[0m | \u001b[0m 0.807   \u001b[0m | \u001b[0m 0.09881 \u001b[0m | \u001b[0m 0.393   \u001b[0m | \u001b[0m 9.621   \u001b[0m | \u001b[0m 446.7   \u001b[0m | \u001b[0m 63.57   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1905  \u001b[0m | \u001b[0m 0.9631  \u001b[0m | \u001b[0m 0.4367  \u001b[0m | \u001b[0m 0.06037 \u001b[0m | \u001b[0m 0.347   \u001b[0m | \u001b[0m 12.01   \u001b[0m | \u001b[0m 431.7   \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1643  \u001b[0m | \u001b[0m 0.6455  \u001b[0m | \u001b[0m 0.00226 \u001b[0m | \u001b[0m 0.6205  \u001b[0m | \u001b[0m 0.2957  \u001b[0m | \u001b[0m 2.822   \u001b[0m | \u001b[0m 478.6   \u001b[0m | \u001b[0m 38.75   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.164   \u001b[0m | \u001b[0m 0.9739  \u001b[0m | \u001b[0m 0.2994  \u001b[0m | \u001b[0m 0.4194  \u001b[0m | \u001b[0m 0.2489  \u001b[0m | \u001b[0m 3.131   \u001b[0m | \u001b[0m 480.1   \u001b[0m | \u001b[0m 23.44   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1634  \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.8183  \u001b[0m | \u001b[0m 0.8931  \u001b[0m | \u001b[0m 0.01516 \u001b[0m | \u001b[0m 2.636   \u001b[0m | \u001b[0m 468.6   \u001b[0m | \u001b[0m 16.99   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1785  \u001b[0m | \u001b[0m 0.2869  \u001b[0m | \u001b[0m 0.211   \u001b[0m | \u001b[0m 0.2732  \u001b[0m | \u001b[0m 0.3585  \u001b[0m | \u001b[0m 11.7    \u001b[0m | \u001b[0m 481.3   \u001b[0m | \u001b[0m 12.1    \u001b[0m |\n",
      "| \u001b[95m 30      \u001b[0m | \u001b[95m-0.1565  \u001b[0m | \u001b[95m 0.6636  \u001b[0m | \u001b[95m 0.5676  \u001b[0m | \u001b[95m 0.4519  \u001b[0m | \u001b[95m 0.01803 \u001b[0m | \u001b[95m 7.207   \u001b[0m | \u001b[95m 493.8   \u001b[0m | \u001b[95m 33.42   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway System LGBM Models Bayes: 100%|██████████| 3/3 [20:03<00:00, 401.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# In parallel, loop through the lists of training and validation data, subset theminto X and y, and run the \n",
    "# Bayesian optimizer. Save the best model params for each cluster to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Highway System LGBM Models Bayes\", \n",
    "                      total=len(train_df_highway_clust_ls))) as progress_bar:\n",
    "    highway_clust_mods_bayes = Parallel(n_jobs=3)(delayed(optimize_lgbm_w_bayes)(train_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                 train_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                                 val_df_highway_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                                 val_df_highway_clust_ls[i].iloc[:,0]) for i in range(len(train_df_highway_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "100466ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each set of params in the list\n",
    "for n in range(len(highway_clust_mods_bayes)):\n",
    "    # Round and cast to int the LGBM model params which must be integers\n",
    "    highway_clust_mods_bayes[n][\"max_depth\"] = int(round(highway_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    highway_clust_mods_bayes[n][\"n_estimators\"] = int(round(highway_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    highway_clust_mods_bayes[n][\"num_leaves\"] = int(round(highway_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ad614bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of train_val data frames which only contain data for each cluster\n",
    "train_val_df_highway_clust_ls = [df.reset_index(drop=True) for _,df in train_val_df_full_highway.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e58bdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway System LGBM Models Bayes Final: 100%|█████| 3/3 [01:14<00:00, 24.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# Using the above list and the list of best model params, loop in parallel across the clusters and create a \n",
    "# model for each one. Save those models to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Highway System LGBM Models Bayes Final\", \n",
    "                      total=len(highway_clust_mods_bayes))) as progress_bar:\n",
    "    highway_clust_mods_bayes_final = Parallel(n_jobs=3)(delayed(train_lgbm)(highway_clust_mods_bayes[i], \n",
    "                                                                            train_val_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                            train_val_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(highway_clust_mods_bayes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f0102a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each of those models to a file \n",
    "for model_no in range(len(highway_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/Highway System/model_{model_no}\"\n",
    "    joblib.dump(highway_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e10acd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_clust_mods_bayes_final = list()\n",
    "\n",
    "for model_no in range(len(train_val_df_highway_clust_ls)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/Highway System/model_{model_no}\"\n",
    "    highway_clust_mods_bayes_final.append(joblib.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5c550fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway LGBM Models Bayes Residuals: 100%|████████| 3/3 [00:09<00:00,  3.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each of the newly created models, in paralle, loop through the models and training data and\n",
    "# compute the model residuals. Save the residuals from each model to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Highway LGBM Models Bayes Residuals\", \n",
    "                      total=len(highway_clust_mods_bayes_final))) as progress_bar:\n",
    "    highway_clust_mods_bayes_resid = Parallel(n_jobs=3)(delayed(compute_lgbm_residuals)(highway_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_highway_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(highway_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5ca17388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[-10.47253259660829, 0.40237954593237646, -48....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[18.899379177321606, -8.598041296536792, 19.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[-27.959469759999138, 2.9877836473597768, 11.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                           residual\n",
       "0        1  [-10.47253259660829, 0.40237954593237646, -48....\n",
       "1        2  [18.899379177321606, -8.598041296536792, 19.29...\n",
       "2        3  [-27.959469759999138, 2.9877836473597768, 11.8..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway_res_df = pd.DataFrame({'cluster': list({(i+1): highway_clust_mods_bayes_resid[i] for i in range(len(highway_clust_mods_bayes_resid))}.keys()),\n",
    "                               'residual': list({(i+1): highway_clust_mods_bayes_resid[i] for i in range(len(highway_clust_mods_bayes_resid))}.values())})\n",
    "\n",
    "highway_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aa3a5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_res_df.to_csv(\"Results/Global/LightGBM Bayes/Highway System/residual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7cc166a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of test data frames where each entry in the list is the test data frame for one cluster\n",
    "test_df_full_highway_clust_ls = [df.reset_index(drop=True) for _,df in test_df_full_highway.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "83b13f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Highway LGBM Models Bayes Test Preds:   0%|               | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.12    \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1194  \u001b[0m | \u001b[95m 0.7999  \u001b[0m | \u001b[95m 0.4889  \u001b[0m | \u001b[95m 0.05053 \u001b[0m | \u001b[95m 0.2692  \u001b[0m | \u001b[95m 2.954   \u001b[0m | \u001b[95m 827.3   \u001b[0m | \u001b[95m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1317  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1451  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.128   \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1239  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1635  \u001b[0m | \u001b[0m 0.9697  \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.4162  \u001b[0m | \u001b[0m 0.4815  \u001b[0m | \u001b[0m 10.06   \u001b[0m | \u001b[0m 820.2   \u001b[0m | \u001b[0m 147.2   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1157  \u001b[0m | \u001b[95m 0.5048  \u001b[0m | \u001b[95m 0.1897  \u001b[0m | \u001b[95m 0.9395  \u001b[0m | \u001b[95m 0.06436 \u001b[0m | \u001b[95m 10.9    \u001b[0m | \u001b[95m 474.2   \u001b[0m | \u001b[95m 25.27   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1182  \u001b[0m | \u001b[0m 0.4901  \u001b[0m | \u001b[0m 0.8833  \u001b[0m | \u001b[0m 0.8702  \u001b[0m | \u001b[0m 0.1799  \u001b[0m | \u001b[0m 7.472   \u001b[0m | \u001b[0m 468.2   \u001b[0m | \u001b[0m 22.02   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1182  \u001b[0m | \u001b[0m 0.6715  \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 0.7347  \u001b[0m | \u001b[0m 0.1921  \u001b[0m | \u001b[0m 7.175   \u001b[0m | \u001b[0m 477.5   \u001b[0m | \u001b[0m 18.71   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.117   \u001b[0m | \u001b[0m 0.564   \u001b[0m | \u001b[0m 0.2216  \u001b[0m | \u001b[0m 0.9552  \u001b[0m | \u001b[0m 0.1315  \u001b[0m | \u001b[0m 3.257   \u001b[0m | \u001b[0m 476.8   \u001b[0m | \u001b[0m 29.66   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1163  \u001b[0m | \u001b[0m 0.3634  \u001b[0m | \u001b[0m 0.7308  \u001b[0m | \u001b[0m 0.9633  \u001b[0m | \u001b[0m 0.08772 \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 483.7   \u001b[0m | \u001b[0m 25.75   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1575  \u001b[0m | \u001b[0m 0.1464  \u001b[0m | \u001b[0m 0.7348  \u001b[0m | \u001b[0m 0.007833\u001b[0m | \u001b[0m 0.4735  \u001b[0m | \u001b[0m 9.63    \u001b[0m | \u001b[0m 483.4   \u001b[0m | \u001b[0m 35.53   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1259  \u001b[0m | \u001b[0m 0.1344  \u001b[0m | \u001b[0m 0.5043  \u001b[0m | \u001b[0m 0.4524  \u001b[0m | \u001b[0m 0.3762  \u001b[0m | \u001b[0m 2.052   \u001b[0m | \u001b[0m 481.9   \u001b[0m | \u001b[0m 22.56   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1204  \u001b[0m | \u001b[0m 0.1712  \u001b[0m | \u001b[0m 0.9336  \u001b[0m | \u001b[0m 0.1298  \u001b[0m | \u001b[0m 0.1405  \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 485.2   \u001b[0m | \u001b[0m 20.86   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.9486  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 469.8   \u001b[0m | \u001b[0m 27.97   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1176  \u001b[0m | \u001b[0m 0.206   \u001b[0m | \u001b[0m 0.9642  \u001b[0m | \u001b[0m 0.5305  \u001b[0m | \u001b[0m 0.07462 \u001b[0m | \u001b[0m 15.8    \u001b[0m | \u001b[0m 480.6   \u001b[0m | \u001b[0m 23.64   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1249  \u001b[0m | \u001b[0m 0.3524  \u001b[0m | \u001b[0m 0.7884  \u001b[0m | \u001b[0m 0.09994 \u001b[0m | \u001b[0m 0.4937  \u001b[0m | \u001b[0m 3.381   \u001b[0m | \u001b[0m 482.6   \u001b[0m | \u001b[0m 29.38   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1314  \u001b[0m | \u001b[0m 0.1133  \u001b[0m | \u001b[0m 0.7165  \u001b[0m | \u001b[0m 0.5914  \u001b[0m | \u001b[0m 0.01684 \u001b[0m | \u001b[0m 7.683   \u001b[0m | \u001b[0m 485.5   \u001b[0m | \u001b[0m 17.54   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1386  \u001b[0m | \u001b[0m 0.695   \u001b[0m | \u001b[0m 0.6792  \u001b[0m | \u001b[0m 0.7813  \u001b[0m | \u001b[0m 0.4987  \u001b[0m | \u001b[0m 8.472   \u001b[0m | \u001b[0m 478.7   \u001b[0m | \u001b[0m 30.99   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1227  \u001b[0m | \u001b[0m 0.3129  \u001b[0m | \u001b[0m 0.42    \u001b[0m | \u001b[0m 0.8768  \u001b[0m | \u001b[0m 0.2503  \u001b[0m | \u001b[0m 14.07   \u001b[0m | \u001b[0m 464.4   \u001b[0m | \u001b[0m 18.34   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1192  \u001b[0m | \u001b[0m 0.4327  \u001b[0m | \u001b[0m 0.05727 \u001b[0m | \u001b[0m 0.342   \u001b[0m | \u001b[0m 0.2066  \u001b[0m | \u001b[0m 7.131   \u001b[0m | \u001b[0m 470.0   \u001b[0m | \u001b[0m 15.73   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1208  \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.6139  \u001b[0m | \u001b[0m 0.2184  \u001b[0m | \u001b[0m 0.2842  \u001b[0m | \u001b[0m 5.978   \u001b[0m | \u001b[0m 462.5   \u001b[0m | \u001b[0m 12.4    \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1173  \u001b[0m | \u001b[0m 0.4148  \u001b[0m | \u001b[0m 0.4723  \u001b[0m | \u001b[0m 0.4455  \u001b[0m | \u001b[0m 0.1467  \u001b[0m | \u001b[0m 16.54   \u001b[0m | \u001b[0m 473.6   \u001b[0m | \u001b[0m 14.13   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1273  \u001b[0m | \u001b[0m 0.4118  \u001b[0m | \u001b[0m 0.5937  \u001b[0m | \u001b[0m 0.6171  \u001b[0m | \u001b[0m 0.3045  \u001b[0m | \u001b[0m 16.94   \u001b[0m | \u001b[0m 489.3   \u001b[0m | \u001b[0m 27.81   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1207  \u001b[0m | \u001b[0m 0.2214  \u001b[0m | \u001b[0m 0.2257  \u001b[0m | \u001b[0m 0.3428  \u001b[0m | \u001b[0m 0.191   \u001b[0m | \u001b[0m 6.038   \u001b[0m | \u001b[0m 461.9   \u001b[0m | \u001b[0m 18.6    \u001b[0m |\n",
      "| \u001b[95m 27      \u001b[0m | \u001b[95m-0.1154  \u001b[0m | \u001b[95m 0.9581  \u001b[0m | \u001b[95m 0.9679  \u001b[0m | \u001b[95m 0.5078  \u001b[0m | \u001b[95m 0.01829 \u001b[0m | \u001b[95m 10.13   \u001b[0m | \u001b[95m 493.4   \u001b[0m | \u001b[95m 23.88   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1169  \u001b[0m | \u001b[0m 0.7784  \u001b[0m | \u001b[0m 0.3144  \u001b[0m | \u001b[0m 0.69    \u001b[0m | \u001b[0m 0.1599  \u001b[0m | \u001b[0m 16.46   \u001b[0m | \u001b[0m 481.0   \u001b[0m | \u001b[0m 14.71   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1212  \u001b[0m | \u001b[0m 0.7866  \u001b[0m | \u001b[0m 0.919   \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 0.2462  \u001b[0m | \u001b[0m 22.75   \u001b[0m | \u001b[0m 484.2   \u001b[0m | \u001b[0m 21.66   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1211  \u001b[0m | \u001b[0m 0.6775  \u001b[0m | \u001b[0m 0.7226  \u001b[0m | \u001b[0m 0.9055  \u001b[0m | \u001b[0m 0.2857  \u001b[0m | \u001b[0m 23.79   \u001b[0m | \u001b[0m 476.3   \u001b[0m | \u001b[0m 18.38   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5675523554930122, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5675523554930122\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4518956759681497, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4518956759681497\n",
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1522  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1536  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1688  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2121  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1614  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1953  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1923  \u001b[0m | \u001b[0m 0.1823  \u001b[0m | \u001b[0m 0.2334  \u001b[0m | \u001b[0m 0.3629  \u001b[0m | \u001b[0m 0.06587 \u001b[0m | \u001b[0m 17.26   \u001b[0m | \u001b[0m 859.2   \u001b[0m | \u001b[0m 141.3   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1567  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.2829  \u001b[0m | \u001b[0m 0.9203  \u001b[0m | \u001b[0m 0.08668 \u001b[0m | \u001b[0m 8.428   \u001b[0m | \u001b[0m 942.3   \u001b[0m | \u001b[0m 106.7   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1769  \u001b[0m | \u001b[0m 0.6154  \u001b[0m | \u001b[0m 0.5809  \u001b[0m | \u001b[0m 0.5974  \u001b[0m | \u001b[0m 0.3896  \u001b[0m | \u001b[0m 23.0    \u001b[0m | \u001b[0m 433.1   \u001b[0m | \u001b[0m 83.41   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1927  \u001b[0m | \u001b[0m 0.2707  \u001b[0m | \u001b[0m 0.3919  \u001b[0m | \u001b[0m 0.8713  \u001b[0m | \u001b[0m 0.2398  \u001b[0m | \u001b[0m 21.29   \u001b[0m | \u001b[0m 182.6   \u001b[0m | \u001b[0m 128.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1541  \u001b[0m | \u001b[0m 0.5174  \u001b[0m | \u001b[0m 0.2394  \u001b[0m | \u001b[0m 0.01523 \u001b[0m | \u001b[0m 0.3594  \u001b[0m | \u001b[0m 2.433   \u001b[0m | \u001b[0m 593.3   \u001b[0m | \u001b[0m 126.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1545  \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 0.517   \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 0.09298 \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 583.4   \u001b[0m | \u001b[0m 123.1   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1641  \u001b[0m | \u001b[0m 0.957   \u001b[0m | \u001b[0m 0.5047  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.2706  \u001b[0m | \u001b[0m 8.573   \u001b[0m | \u001b[0m 757.1   \u001b[0m | \u001b[0m 17.0    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1788  \u001b[0m | \u001b[0m 0.2656  \u001b[0m | \u001b[0m 0.04668 \u001b[0m | \u001b[0m 0.03001 \u001b[0m | \u001b[0m 0.1727  \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 861.6   \u001b[0m | \u001b[0m 139.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1583  \u001b[0m | \u001b[0m 0.8199  \u001b[0m | \u001b[0m 0.4933  \u001b[0m | \u001b[0m 0.7328  \u001b[0m | \u001b[0m 0.2643  \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 398.9   \u001b[0m | \u001b[0m 92.87   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2312  \u001b[0m | \u001b[0m 0.5136  \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 0.06973 \u001b[0m | \u001b[0m 0.4773  \u001b[0m | \u001b[0m 10.62   \u001b[0m | \u001b[0m 642.0   \u001b[0m | \u001b[0m 97.73   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1712  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.371   \u001b[0m | \u001b[0m 9.194   \u001b[0m | \u001b[0m 969.5   \u001b[0m | \u001b[0m 23.1    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1772  \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.0695  \u001b[0m | \u001b[0m 0.3948  \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 27.02   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1556  \u001b[0m | \u001b[0m 0.9134  \u001b[0m | \u001b[0m 0.3416  \u001b[0m | \u001b[0m 0.2057  \u001b[0m | \u001b[0m 0.2121  \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 418.8   \u001b[0m | \u001b[0m 120.2   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1632  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.5603  \u001b[0m | \u001b[0m 0.4809  \u001b[0m | \u001b[0m 0.09778 \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 351.6   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1587  \u001b[0m | \u001b[0m 0.5316  \u001b[0m | \u001b[0m 0.3662  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.377   \u001b[0m | \u001b[0m 2.832   \u001b[0m | \u001b[0m 855.2   \u001b[0m | \u001b[0m 24.01   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1891  \u001b[0m | \u001b[0m 0.3696  \u001b[0m | \u001b[0m 0.9666  \u001b[0m | \u001b[0m 0.0882  \u001b[0m | \u001b[0m 0.3123  \u001b[0m | \u001b[0m 22.58   \u001b[0m | \u001b[0m 694.0   \u001b[0m | \u001b[0m 115.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1856  \u001b[0m | \u001b[0m 0.2374  \u001b[0m | \u001b[0m 0.5845  \u001b[0m | \u001b[0m 0.6013  \u001b[0m | \u001b[0m 0.06929 \u001b[0m | \u001b[0m 24.59   \u001b[0m | \u001b[0m 646.7   \u001b[0m | \u001b[0m 126.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1533  \u001b[0m | \u001b[0m 0.6942  \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.7711  \u001b[0m | \u001b[0m 0.1554  \u001b[0m | \u001b[0m 16.79   \u001b[0m | \u001b[0m 331.1   \u001b[0m | \u001b[0m 40.78   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2014  \u001b[0m | \u001b[0m 0.1268  \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 0.7912  \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 18.31   \u001b[0m | \u001b[0m 255.6   \u001b[0m | \u001b[0m 68.42   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1615  \u001b[0m | \u001b[0m 0.7789  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.5176  \u001b[0m | \u001b[0m 0.2534  \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 925.9   \u001b[0m | \u001b[0m 114.4   \u001b[0m |\n",
      "| \u001b[95m 27      \u001b[0m | \u001b[95m-0.1512  \u001b[0m | \u001b[95m 0.5703  \u001b[0m | \u001b[95m 0.1937  \u001b[0m | \u001b[95m 0.677   \u001b[0m | \u001b[95m 0.2474  \u001b[0m | \u001b[95m 2.781   \u001b[0m | \u001b[95m 583.6   \u001b[0m | \u001b[95m 123.5   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1878  \u001b[0m | \u001b[0m 0.4295  \u001b[0m | \u001b[0m 0.5138  \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 0.3808  \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 471.2   \u001b[0m | \u001b[0m 24.53   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1556  \u001b[0m | \u001b[0m 0.9737  \u001b[0m | \u001b[0m 0.6132  \u001b[0m | \u001b[0m 0.2585  \u001b[0m | \u001b[0m 0.3116  \u001b[0m | \u001b[0m 16.09   \u001b[0m | \u001b[0m 332.1   \u001b[0m | \u001b[0m 43.31   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1972  \u001b[0m | \u001b[0m 0.9304  \u001b[0m | \u001b[0m 0.5238  \u001b[0m | \u001b[0m 0.3005  \u001b[0m | \u001b[0m 0.4599  \u001b[0m | \u001b[0m 12.76   \u001b[0m | \u001b[0m 418.5   \u001b[0m | \u001b[0m 119.4   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.967946330671444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.967946330671444\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5077729079737244, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5077729079737244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19373553408774502, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19373553408774502\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6769592763361791, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6769592763361791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Highway LGBM Models Bayes Test Preds: 100%|███████| 3/3 [00:05<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the models and the list of test data frames, create test predictions, and save those to a list of \n",
    "# data frames\n",
    "with tqdm_joblib(tqdm(desc=\"Highway LGBM Models Bayes Test Preds\", \n",
    "                      total=len(highway_clust_mods_bayes_final))) as progress_bar:\n",
    "    highway_clust_mods_bayes_test_preds = Parallel(n_jobs=4)(delayed(compute_lgbm_test_preds)(highway_clust_mods_bayes_final[i],\n",
    "                                                                                           test_df_full_highway_clust_ls[i],\n",
    "                                                                                           lag_n\n",
    "                                                                                          ) for i in range(len(highway_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f7b72078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one data frame from the above list of test pred data frames\n",
    "highway_clust_bayes_test_preds_df = pd.concat(highway_clust_mods_bayes_test_preds)\n",
    "# for clust_test_pred_df in highway_clust_mods_bayes_test_preds:\n",
    "#     highway_clust_bayes_test_preds_df = highway_clust_bayes_test_preds_df.append(clust_test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1ef36230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance metrics on the full data frame of test predictions\n",
    "highway_clust_bayes_test_perf = compute_lgbm_test_perf(highway_clust_bayes_test_preds_df,\n",
    "                                                       test_df_full_highway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da9a9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized/scaled perf metrics\n",
    "highway_clust_bayes_test_perf['nrmse'] = highway_clust_bayes_test_perf['rmse']/highway_clust_bayes_test_perf['mean']\n",
    "highway_clust_bayes_test_perf['smae'] = highway_clust_bayes_test_perf['mae']/highway_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "044e0ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      31.115161\n",
       "mae       20.665621\n",
       "mean     265.435072\n",
       "nrmse      0.141108\n",
       "smae       0.095555\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print means of performance metrics\n",
    "highway_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d6784d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2265f30a59e40a68c99507f0bfbb729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/51072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a1301a170043278bf378a9112c4ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3402e96b1341468c1ea88c35d75a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/25536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through each set of preds and compute the bootstrap PIs for those preds/cluster\n",
    "highway_clust_test_pred_int = list()\n",
    "for i in range(len(highway_clust_mods_bayes_test_preds)):\n",
    "    highway_clust_test_pred_int.append(compute_lgbm_boostrap_int(highway_clust_mods_bayes_test_preds[i], \n",
    "                                                                 highway_clust_mods_bayes_resid[i], \n",
    "                                                                 n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc0d8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster, add the true values to the data frame of preds\n",
    "for n in range(1, len(highway_clust_test_pred_int)+1):\n",
    "    y_actual_sub = test_df_full_highway.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    highway_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "20f7ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all PI data frames into one data frame\n",
    "highway_clust_test_pred_int_df = pd.concat(highway_clust_test_pred_int)\n",
    "# for clust_test_pred_int_df in highway_clust_test_pred_int:\n",
    "#     highway_clust_test_pred_int_df = highway_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6cfa0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every prediction in the PI data frame, compute the 95% and 80% PI score\n",
    "highway_clust_test_pred_int_df['int_95_score'] = interval_score(highway_clust_test_pred_int_df['actual'],\n",
    "                                                                highway_clust_test_pred_int_df['lo_95'],\n",
    "                                                                highway_clust_test_pred_int_df['hi_95'],\n",
    "                                                                0.95\n",
    "                                                               )\n",
    "\n",
    "highway_clust_test_pred_int_df['int_80_score'] = interval_score(highway_clust_test_pred_int_df['actual'],\n",
    "                                                                highway_clust_test_pred_int_df['lo_80'],\n",
    "                                                                highway_clust_test_pred_int_df['hi_80'],\n",
    "                                                                0.80\n",
    "                                                               )\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "25e95ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.684829\n",
       "lo_95           205.315901\n",
       "hi_95           328.288360\n",
       "lo_80           236.420271\n",
       "hi_80           296.055512\n",
       "actual          265.435072\n",
       "int_95_score    221.862267\n",
       "int_80_score    122.267072\n",
       "dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of the PI scores\n",
    "highway_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7582d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_clust_test_pred_int_df_grouped = highway_clust_test_pred_int_df.groupby(\"ts_index\")\\\n",
    ".agg({\"int_95_score\":'mean', 'int_80_score':'mean', 'actual':'mean'}).reset_index()\n",
    "\n",
    "highway_clust_test_pred_int_df_grouped['int_95_score_scaled'] = highway_clust_test_pred_int_df_grouped['int_95_score']/highway_clust_test_pred_int_df_grouped['actual']\n",
    "highway_clust_test_pred_int_df_grouped['int_80_score_scaled'] = highway_clust_test_pred_int_df_grouped['int_80_score']/highway_clust_test_pred_int_df_grouped['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b3c04dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_80_score_scaled    0.589390\n",
       "int_95_score_scaled    1.058783\n",
       "dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway_clust_test_pred_int_df_grouped[['int_80_score_scaled', 'int_95_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e2ee25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI data frame to a csv file\n",
    "highway_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/Highway System/test_pred_intervals.csv\",\n",
    "                                      index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de0ced",
   "metadata": {},
   "source": [
    "# Test and Train - Catch22 KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3ae0ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused variables\n",
    "del highway_clust_test_pred_int_df\n",
    "del highway_clust_test_pred_int\n",
    "del y_actual_sub\n",
    "del highway_clust_bayes_test_perf\n",
    "del highway_clust_bayes_test_preds_df\n",
    "del highway_clust_mods_bayes_test_preds\n",
    "del test_df_full_highway_clust_ls\n",
    "del test_df_full_highway\n",
    "del highway_clust_mods_bayes_resid\n",
    "del highway_clust_mods_bayes_final\n",
    "del train_val_df_highway_clust_ls\n",
    "del train_val_df_full_highway\n",
    "del highway_clust_mods_bayes\n",
    "del train_df_highway_clust_ls\n",
    "del val_df_highway_clust_ls \n",
    "del train_df_full_highway\n",
    "del val_df_full_highway\n",
    "del highway_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "561b1011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7314cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cluster assignmed from the Catch22-based KMeans clusters\n",
    "catch22_clust = pd.read_csv(\"Results/Clustering/KMeans/kmeans_catch22_clustering_assign.csv\")\n",
    "catch22_clust['cluster'] = catch22_clust['kmeans_catch22_clust_assign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e3815528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the training, validation, train_val, and test data with the cluster assignments\n",
    "train_df_full_catch22 = train_df_full.merge(catch22_clust, on=\"ts_index\")\n",
    "val_df_full_catch22 = val_df_full.merge(catch22_clust, on=\"ts_index\")\n",
    "train_val_df_full_catch22 = train_val_df_full.merge(catch22_clust, on=\"ts_index\")\n",
    "test_df_full_catch22 = test_df_full.merge(catch22_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6fc54eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of training and validation data frames which contain data for only one cluster each\n",
    "train_df_catch22_clust_ls = [df.reset_index(drop=True) for _,df in train_df_full_catch22.groupby(\"cluster\")]\n",
    "val_df_catch22_clust_ls = [df.reset_index(drop=True) for _,df in val_df_full_catch22.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "75db6d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes:  40%|██████▊          | 2/5 [05:18<06:59, 139.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1674  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1725  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2048  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2554  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1814  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1631  \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.031   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 4.597   \u001b[0m | \u001b[0m 845.3   \u001b[0m | \u001b[0m 145.6   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1803  \u001b[0m | \u001b[0m 0.1015  \u001b[0m | \u001b[0m 0.06701 \u001b[0m | \u001b[0m 0.6858  \u001b[0m | \u001b[0m 0.01904 \u001b[0m | \u001b[0m 16.86   \u001b[0m | \u001b[0m 459.6   \u001b[0m | \u001b[0m 26.69   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2126  \u001b[0m | \u001b[0m 0.7425  \u001b[0m | \u001b[0m 0.9865  \u001b[0m | \u001b[0m 0.1373  \u001b[0m | \u001b[0m 0.4415  \u001b[0m | \u001b[0m 5.347   \u001b[0m | \u001b[0m 460.7   \u001b[0m | \u001b[0m 20.97   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1786  \u001b[0m | \u001b[0m 0.8629  \u001b[0m | \u001b[0m 0.8418  \u001b[0m | \u001b[0m 0.8826  \u001b[0m | \u001b[0m 0.3036  \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 472.7   \u001b[0m | \u001b[0m 36.18   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-1.034   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 472.0   \u001b[0m | \u001b[0m 31.27   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2078  \u001b[0m | \u001b[0m 0.6595  \u001b[0m | \u001b[0m 0.273   \u001b[0m | \u001b[0m 0.668   \u001b[0m | \u001b[0m 0.4198  \u001b[0m | \u001b[0m 9.344   \u001b[0m | \u001b[0m 461.5   \u001b[0m | \u001b[0m 31.78   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-0.1587  \u001b[0m | \u001b[95m 0.3714  \u001b[0m | \u001b[95m 0.6943  \u001b[0m | \u001b[95m 0.03396 \u001b[0m | \u001b[95m 0.08815 \u001b[0m | \u001b[95m 5.266   \u001b[0m | \u001b[95m 470.4   \u001b[0m | \u001b[95m 29.83   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1766  \u001b[0m | \u001b[0m 0.772   \u001b[0m | \u001b[0m 0.01462 \u001b[0m | \u001b[0m 0.4074  \u001b[0m | \u001b[0m 0.3378  \u001b[0m | \u001b[0m 2.894   \u001b[0m | \u001b[0m 474.4   \u001b[0m | \u001b[0m 17.6    \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m-0.1517  \u001b[0m | \u001b[95m 0.7006  \u001b[0m | \u001b[95m 0.6602  \u001b[0m | \u001b[95m 0.196   \u001b[0m | \u001b[95m 0.01431 \u001b[0m | \u001b[95m 12.8    \u001b[0m | \u001b[95m 468.6   \u001b[0m | \u001b[95m 11.1    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1789  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 475.2   \u001b[0m | \u001b[0m 43.3    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1545  \u001b[0m | \u001b[0m 0.755   \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 0.1985  \u001b[0m | \u001b[0m 0.1254  \u001b[0m | \u001b[0m 4.282   \u001b[0m | \u001b[0m 482.9   \u001b[0m | \u001b[0m 32.46   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1682  \u001b[0m | \u001b[0m 0.3568  \u001b[0m | \u001b[0m 0.3645  \u001b[0m | \u001b[0m 0.4417  \u001b[0m | \u001b[0m 0.2138  \u001b[0m | \u001b[0m 17.61   \u001b[0m | \u001b[0m 449.2   \u001b[0m | \u001b[0m 16.5    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1564  \u001b[0m | \u001b[0m 0.7868  \u001b[0m | \u001b[0m 0.1667  \u001b[0m | \u001b[0m 0.4901  \u001b[0m | \u001b[0m 0.1572  \u001b[0m | \u001b[0m 11.35   \u001b[0m | \u001b[0m 486.2   \u001b[0m | \u001b[0m 16.43   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2022  \u001b[0m | \u001b[0m 0.2002  \u001b[0m | \u001b[0m 0.07462 \u001b[0m | \u001b[0m 0.02793 \u001b[0m | \u001b[0m 0.268   \u001b[0m | \u001b[0m 18.36   \u001b[0m | \u001b[0m 442.0   \u001b[0m | \u001b[0m 29.27   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1575  \u001b[0m | \u001b[0m 0.6895  \u001b[0m | \u001b[0m 0.1925  \u001b[0m | \u001b[0m 0.7741  \u001b[0m | \u001b[0m 0.1183  \u001b[0m | \u001b[0m 2.278   \u001b[0m | \u001b[0m 500.7   \u001b[0m | \u001b[0m 21.73   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.2161  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 11.66   \u001b[0m | \u001b[0m 500.7   \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.196   \u001b[0m | \u001b[0m 0.5133  \u001b[0m | \u001b[0m 0.7034  \u001b[0m | \u001b[0m 0.7677  \u001b[0m | \u001b[0m 0.3078  \u001b[0m | \u001b[0m 9.587   \u001b[0m | \u001b[0m 498.6   \u001b[0m | \u001b[0m 35.55   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1992  \u001b[0m | \u001b[0m 0.9651  \u001b[0m | \u001b[0m 0.2647  \u001b[0m | \u001b[0m 0.2805  \u001b[0m | \u001b[0m 0.4108  \u001b[0m | \u001b[0m 16.3    \u001b[0m | \u001b[0m 507.6   \u001b[0m | \u001b[0m 24.28   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1635  \u001b[0m | \u001b[0m 0.8849  \u001b[0m | \u001b[0m 0.9623  \u001b[0m | \u001b[0m 0.7141  \u001b[0m | \u001b[0m 0.2311  \u001b[0m | \u001b[0m 3.197   \u001b[0m | \u001b[0m 489.7   \u001b[0m | \u001b[0m 48.08   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1737  \u001b[0m | \u001b[0m 0.5389  \u001b[0m | \u001b[0m 0.4181  \u001b[0m | \u001b[0m 0.8952  \u001b[0m | \u001b[0m 0.2082  \u001b[0m | \u001b[0m 9.944   \u001b[0m | \u001b[0m 481.7   \u001b[0m | \u001b[0m 60.74   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.2274  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 14.68   \u001b[0m | \u001b[0m 496.2   \u001b[0m | \u001b[0m 55.77   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1614  \u001b[0m | \u001b[0m 0.4911  \u001b[0m | \u001b[0m 0.1964  \u001b[0m | \u001b[0m 0.5628  \u001b[0m | \u001b[0m 0.1578  \u001b[0m | \u001b[0m 2.296   \u001b[0m | \u001b[0m 516.0   \u001b[0m | \u001b[0m 27.32   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1557  \u001b[0m | \u001b[0m 0.5115  \u001b[0m | \u001b[0m 0.8584  \u001b[0m | \u001b[0m 0.3747  \u001b[0m | \u001b[0m 0.05853 \u001b[0m | \u001b[0m 3.034   \u001b[0m | \u001b[0m 512.8   \u001b[0m | \u001b[0m 43.21   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1773  \u001b[0m | \u001b[0m 0.4732  \u001b[0m | \u001b[0m 0.8086  \u001b[0m | \u001b[0m 0.5849  \u001b[0m | \u001b[0m 0.005016\u001b[0m | \u001b[0m 14.98   \u001b[0m | \u001b[0m 517.7   \u001b[0m | \u001b[0m 39.25   \u001b[0m |\n",
      "=============================================================================================================\n",
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1415  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1464  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1646  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1844  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1596  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.138   \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1467  \u001b[0m | \u001b[0m 0.4405  \u001b[0m | \u001b[0m 0.1374  \u001b[0m | \u001b[0m 0.64    \u001b[0m | \u001b[0m 0.3496  \u001b[0m | \u001b[0m 2.775   \u001b[0m | \u001b[0m 837.2   \u001b[0m | \u001b[0m 144.8   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2048  \u001b[0m | \u001b[0m 0.3042  \u001b[0m | \u001b[0m 0.2077  \u001b[0m | \u001b[0m 0.9202  \u001b[0m | \u001b[0m 0.4747  \u001b[0m | \u001b[0m 9.414   \u001b[0m | \u001b[0m 832.9   \u001b[0m | \u001b[0m 144.7   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1702  \u001b[0m | \u001b[0m 0.3771  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.3656  \u001b[0m | \u001b[0m 0.399   \u001b[0m | \u001b[0m 11.8    \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 20.04   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1389  \u001b[0m | \u001b[0m 0.1802  \u001b[0m | \u001b[0m 0.4693  \u001b[0m | \u001b[0m 0.2619  \u001b[0m | \u001b[0m 0.1751  \u001b[0m | \u001b[0m 3.532   \u001b[0m | \u001b[0m 834.1   \u001b[0m | \u001b[0m 143.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1584  \u001b[0m | \u001b[0m 0.6136  \u001b[0m | \u001b[0m 0.5149  \u001b[0m | \u001b[0m 0.06413 \u001b[0m | \u001b[0m 0.4502  \u001b[0m | \u001b[0m 2.997   \u001b[0m | \u001b[0m 826.7   \u001b[0m | \u001b[0m 145.0   \u001b[0m |\n",
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.3284  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.3362  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.4042  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.4488  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.3623  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.2975  \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.3247  \u001b[0m | \u001b[0m 0.4892  \u001b[0m | \u001b[0m 0.1292  \u001b[0m | \u001b[0m 0.7004  \u001b[0m | \u001b[0m 0.1635  \u001b[0m | \u001b[0m 6.494   \u001b[0m | \u001b[0m 832.8   \u001b[0m | \u001b[0m 149.1   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2987  \u001b[0m | \u001b[0m 0.5206  \u001b[0m | \u001b[0m 0.6055  \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 0.08544 \u001b[0m | \u001b[0m 2.594   \u001b[0m | \u001b[0m 828.8   \u001b[0m | \u001b[0m 143.6   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.3828  \u001b[0m | \u001b[0m 0.556   \u001b[0m | \u001b[0m 0.928   \u001b[0m | \u001b[0m 0.4007  \u001b[0m | \u001b[0m 0.3702  \u001b[0m | \u001b[0m 3.922   \u001b[0m | \u001b[0m 835.8   \u001b[0m | \u001b[0m 145.1   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.355   \u001b[0m | \u001b[0m 0.7923  \u001b[0m | \u001b[0m 0.1342  \u001b[0m | \u001b[0m 0.7217  \u001b[0m | \u001b[0m 0.3794  \u001b[0m | \u001b[0m 2.874   \u001b[0m | \u001b[0m 822.8   \u001b[0m | \u001b[0m 142.5   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.3888  \u001b[0m | \u001b[0m 0.9358  \u001b[0m | \u001b[0m 0.6799  \u001b[0m | \u001b[0m 0.178   \u001b[0m | \u001b[0m 0.3728  \u001b[0m | \u001b[0m 10.04   \u001b[0m | \u001b[0m 824.8   \u001b[0m | \u001b[0m 144.6   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.4072  \u001b[0m | \u001b[0m 0.2025  \u001b[0m | \u001b[0m 0.8666  \u001b[0m | \u001b[0m 0.1903  \u001b[0m | \u001b[0m 0.3913  \u001b[0m | \u001b[0m 5.745   \u001b[0m | \u001b[0m 830.3   \u001b[0m | \u001b[0m 147.3   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.3016  \u001b[0m | \u001b[0m 0.9414  \u001b[0m | \u001b[0m 0.8376  \u001b[0m | \u001b[0m 0.004513\u001b[0m | \u001b[0m 0.07853 \u001b[0m | \u001b[0m 5.527   \u001b[0m | \u001b[0m 832.1   \u001b[0m | \u001b[0m 149.5   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.32    \u001b[0m | \u001b[0m 0.7728  \u001b[0m | \u001b[0m 0.1275  \u001b[0m | \u001b[0m 0.8038  \u001b[0m | \u001b[0m 0.1575  \u001b[0m | \u001b[0m 17.51   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 24.3    \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.3428  \u001b[0m | \u001b[0m 0.6578  \u001b[0m | \u001b[0m 0.187   \u001b[0m | \u001b[0m 0.6576  \u001b[0m | \u001b[0m 0.2629  \u001b[0m | \u001b[0m 14.74   \u001b[0m | \u001b[0m 469.8   \u001b[0m | \u001b[0m 21.43   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.3264  \u001b[0m | \u001b[0m 0.6349  \u001b[0m | \u001b[0m 0.2124  \u001b[0m | \u001b[0m 0.6755  \u001b[0m | \u001b[0m 0.1853  \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 471.5   \u001b[0m | \u001b[0m 23.32   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.3351  \u001b[0m | \u001b[0m 0.7022  \u001b[0m | \u001b[0m 0.6405  \u001b[0m | \u001b[0m 0.313   \u001b[0m | \u001b[0m 0.2284  \u001b[0m | \u001b[0m 13.21   \u001b[0m | \u001b[0m 473.2   \u001b[0m | \u001b[0m 18.61   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.45    \u001b[0m | \u001b[0m 0.1737  \u001b[0m | \u001b[0m 0.2246  \u001b[0m | \u001b[0m 0.9779  \u001b[0m | \u001b[0m 0.4613  \u001b[0m | \u001b[0m 11.09   \u001b[0m | \u001b[0m 471.6   \u001b[0m | \u001b[0m 22.01   \u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-0.2929  \u001b[0m | \u001b[95m 0.4944  \u001b[0m | \u001b[95m 0.3307  \u001b[0m | \u001b[95m 0.4453  \u001b[0m | \u001b[95m 0.03993 \u001b[0m | \u001b[95m 16.18   \u001b[0m | \u001b[95m 472.7   \u001b[0m | \u001b[95m 25.08   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.3264  \u001b[0m | \u001b[0m 0.1812  \u001b[0m | \u001b[0m 0.9955  \u001b[0m | \u001b[0m 0.9632  \u001b[0m | \u001b[0m 0.2494  \u001b[0m | \u001b[0m 2.578   \u001b[0m | \u001b[0m 828.1   \u001b[0m | \u001b[0m 144.8   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.3465  \u001b[0m | \u001b[0m 0.1017  \u001b[0m | \u001b[0m 0.6679  \u001b[0m | \u001b[0m 0.536   \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 16.54   \u001b[0m | \u001b[0m 476.9   \u001b[0m | \u001b[0m 23.6    \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.2962  \u001b[0m | \u001b[0m 0.3324  \u001b[0m | \u001b[0m 0.5674  \u001b[0m | \u001b[0m 0.3411  \u001b[0m | \u001b[0m 0.01824 \u001b[0m | \u001b[0m 2.645   \u001b[0m | \u001b[0m 832.6   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.3091  \u001b[0m | \u001b[0m 0.6098  \u001b[0m | \u001b[0m 0.4088  \u001b[0m | \u001b[0m 0.2748  \u001b[0m | \u001b[0m 0.1032  \u001b[0m | \u001b[0m 17.53   \u001b[0m | \u001b[0m 471.8   \u001b[0m | \u001b[0m 26.53   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.3617  \u001b[0m | \u001b[0m 0.7482  \u001b[0m | \u001b[0m 0.6901  \u001b[0m | \u001b[0m 0.916   \u001b[0m | \u001b[0m 0.2831  \u001b[0m | \u001b[0m 17.15   \u001b[0m | \u001b[0m 474.7   \u001b[0m | \u001b[0m 27.44   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2962  \u001b[0m | \u001b[0m 0.2632  \u001b[0m | \u001b[0m 0.1395  \u001b[0m | \u001b[0m 0.0201  \u001b[0m | \u001b[0m 0.06582 \u001b[0m | \u001b[0m 17.68   \u001b[0m | \u001b[0m 472.2   \u001b[0m | \u001b[0m 17.89   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.4443  \u001b[0m | \u001b[0m 0.6755  \u001b[0m | \u001b[0m 0.2202  \u001b[0m | \u001b[0m 0.9378  \u001b[0m | \u001b[0m 0.4817  \u001b[0m | \u001b[0m 19.51   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 20.37   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.3257  \u001b[0m | \u001b[0m 0.574   \u001b[0m | \u001b[0m 0.8446  \u001b[0m | \u001b[0m 0.1088  \u001b[0m | \u001b[0m 0.379   \u001b[0m | \u001b[0m 2.37    \u001b[0m | \u001b[0m 828.5   \u001b[0m | \u001b[0m 140.9   \u001b[0m |\n",
      "| \u001b[95m 28      \u001b[0m | \u001b[95m-0.2926  \u001b[0m | \u001b[95m 0.4827  \u001b[0m | \u001b[95m 0.4679  \u001b[0m | \u001b[95m 0.7444  \u001b[0m | \u001b[95m 0.02728 \u001b[0m | \u001b[95m 16.48   \u001b[0m | \u001b[95m 468.1   \u001b[0m | \u001b[95m 16.8    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.2937  \u001b[0m | \u001b[0m 0.7423  \u001b[0m | \u001b[0m 0.9472  \u001b[0m | \u001b[0m 0.7972  \u001b[0m | \u001b[0m 0.06285 \u001b[0m | \u001b[0m 18.89   \u001b[0m | \u001b[0m 473.1   \u001b[0m | \u001b[0m 16.7    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.311   \u001b[0m | \u001b[0m 0.5014  \u001b[0m | \u001b[0m 0.6456  \u001b[0m | \u001b[0m 0.8737  \u001b[0m | \u001b[0m 0.1372  \u001b[0m | \u001b[0m 18.23   \u001b[0m | \u001b[0m 472.9   \u001b[0m | \u001b[0m 13.41   \u001b[0m |\n",
      "=============================================================================================================\n",
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1071  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1098  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1219  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1411  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1176  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.117   \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1095  \u001b[0m | \u001b[0m 0.2156  \u001b[0m | \u001b[0m 0.3367  \u001b[0m | \u001b[0m 0.7178  \u001b[0m | \u001b[0m 0.0614  \u001b[0m | \u001b[0m 13.95   \u001b[0m | \u001b[0m 470.8   \u001b[0m | \u001b[0m 26.37   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1111  \u001b[0m | \u001b[0m 0.3317  \u001b[0m | \u001b[0m 0.3163  \u001b[0m | \u001b[0m 0.0553  \u001b[0m | \u001b[0m 0.2377  \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 464.7   \u001b[0m | \u001b[0m 17.71   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.1067  \u001b[0m | \u001b[95m 0.8521  \u001b[0m | \u001b[95m 0.4544  \u001b[0m | \u001b[95m 0.5726  \u001b[0m | \u001b[95m 0.1448  \u001b[0m | \u001b[95m 11.39   \u001b[0m | \u001b[95m 817.2   \u001b[0m | \u001b[95m 148.9   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.1063  \u001b[0m | \u001b[95m 0.9605  \u001b[0m | \u001b[95m 0.05814 \u001b[0m | \u001b[95m 0.8876  \u001b[0m | \u001b[95m 0.1146  \u001b[0m | \u001b[95m 2.666   \u001b[0m | \u001b[95m 817.0   \u001b[0m | \u001b[95m 145.5   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1288  \u001b[0m | \u001b[0m 0.1272  \u001b[0m | \u001b[0m 0.4665  \u001b[0m | \u001b[0m 0.5408  \u001b[0m | \u001b[0m 0.4776  \u001b[0m | \u001b[0m 4.766   \u001b[0m | \u001b[0m 481.4   \u001b[0m | \u001b[0m 17.8    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Catch22 LGBM Models Bayes:  60%|██████████▏      | 3/5 [16:37<12:51, 385.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1757  \u001b[0m | \u001b[0m 0.1508  \u001b[0m | \u001b[0m 0.1469  \u001b[0m | \u001b[0m 0.486   \u001b[0m | \u001b[0m 0.3686  \u001b[0m | \u001b[0m 14.24   \u001b[0m | \u001b[0m 471.9   \u001b[0m | \u001b[0m 26.13   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-0.1364  \u001b[0m | \u001b[95m 0.9414  \u001b[0m | \u001b[95m 0.8376  \u001b[0m | \u001b[95m 0.004513\u001b[0m | \u001b[95m 0.07853 \u001b[0m | \u001b[95m 5.527   \u001b[0m | \u001b[95m 832.1   \u001b[0m | \u001b[95m 149.5   \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.1362  \u001b[0m | \u001b[95m 0.2685  \u001b[0m | \u001b[95m 0.5623  \u001b[0m | \u001b[95m 0.2073  \u001b[0m | \u001b[95m 0.1042  \u001b[0m | \u001b[95m 2.002   \u001b[0m | \u001b[95m 833.9   \u001b[0m | \u001b[95m 141.2   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1793  \u001b[0m | \u001b[0m 0.114   \u001b[0m | \u001b[0m 0.6266  \u001b[0m | \u001b[0m 0.4696  \u001b[0m | \u001b[0m 0.3756  \u001b[0m | \u001b[0m 5.003   \u001b[0m | \u001b[0m 836.3   \u001b[0m | \u001b[0m 140.7   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.9224  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7244  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 16.56   \u001b[0m | \u001b[0m 470.8   \u001b[0m | \u001b[0m 20.49   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1669  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.371   \u001b[0m | \u001b[0m 9.194   \u001b[0m | \u001b[0m 969.5   \u001b[0m | \u001b[0m 23.1    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1365  \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.0695  \u001b[0m | \u001b[0m 0.3948  \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 27.02   \u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-0.1318  \u001b[0m | \u001b[95m 0.4944  \u001b[0m | \u001b[95m 0.3307  \u001b[0m | \u001b[95m 0.4453  \u001b[0m | \u001b[95m 0.03993 \u001b[0m | \u001b[95m 16.18   \u001b[0m | \u001b[95m 472.7   \u001b[0m | \u001b[95m 25.08   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1375  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.5603  \u001b[0m | \u001b[0m 0.4809  \u001b[0m | \u001b[0m 0.09778 \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 351.6   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1513  \u001b[0m | \u001b[0m 0.5316  \u001b[0m | \u001b[0m 0.3662  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.377   \u001b[0m | \u001b[0m 2.832   \u001b[0m | \u001b[0m 855.2   \u001b[0m | \u001b[0m 24.01   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1544  \u001b[0m | \u001b[0m 0.655   \u001b[0m | \u001b[0m 0.4522  \u001b[0m | \u001b[0m 0.1929  \u001b[0m | \u001b[0m 0.2485  \u001b[0m | \u001b[0m 16.63   \u001b[0m | \u001b[0m 352.9   \u001b[0m | \u001b[0m 70.89   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1335  \u001b[0m | \u001b[0m 0.9695  \u001b[0m | \u001b[0m 0.5002  \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.08577 \u001b[0m | \u001b[0m 5.507   \u001b[0m | \u001b[0m 762.1   \u001b[0m | \u001b[0m 125.5   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1521  \u001b[0m | \u001b[0m 0.586   \u001b[0m | \u001b[0m 0.9535  \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 0.2778  \u001b[0m | \u001b[0m 5.883   \u001b[0m | \u001b[0m 764.1   \u001b[0m | \u001b[0m 124.9   \u001b[0m |\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m-0.1315  \u001b[0m | \u001b[95m 0.8763  \u001b[0m | \u001b[95m 0.08871 \u001b[0m | \u001b[95m 0.3772  \u001b[0m | \u001b[95m 0.05716 \u001b[0m | \u001b[95m 3.656   \u001b[0m | \u001b[95m 827.8   \u001b[0m | \u001b[95m 147.5   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1329  \u001b[0m | \u001b[0m 0.9879  \u001b[0m | \u001b[0m 0.4557  \u001b[0m | \u001b[0m 0.1368  \u001b[0m | \u001b[0m 0.05397 \u001b[0m | \u001b[0m 5.867   \u001b[0m | \u001b[0m 834.5   \u001b[0m | \u001b[0m 148.2   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1596  \u001b[0m | \u001b[0m 0.1394  \u001b[0m | \u001b[0m 0.2824  \u001b[0m | \u001b[0m 0.7947  \u001b[0m | \u001b[0m 0.2847  \u001b[0m | \u001b[0m 19.85   \u001b[0m | \u001b[0m 354.0   \u001b[0m | \u001b[0m 71.43   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1405  \u001b[0m | \u001b[0m 0.1774  \u001b[0m | \u001b[0m 0.1874  \u001b[0m | \u001b[0m 0.5187  \u001b[0m | \u001b[0m 0.1335  \u001b[0m | \u001b[0m 18.91   \u001b[0m | \u001b[0m 354.8   \u001b[0m | \u001b[0m 74.93   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1416  \u001b[0m | \u001b[0m 0.3864  \u001b[0m | \u001b[0m 0.8575  \u001b[0m | \u001b[0m 0.6644  \u001b[0m | \u001b[0m 0.02377 \u001b[0m | \u001b[0m 9.036   \u001b[0m | \u001b[0m 131.8   \u001b[0m | \u001b[0m 27.97   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1322  \u001b[0m | \u001b[0m 0.9808  \u001b[0m | \u001b[0m 0.9829  \u001b[0m | \u001b[0m 0.6088  \u001b[0m | \u001b[0m 0.05625 \u001b[0m | \u001b[0m 5.834   \u001b[0m | \u001b[0m 835.3   \u001b[0m | \u001b[0m 145.8   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes: 100%|█████████████████| 5/5 [24:14<00:00, 291.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1078  \u001b[0m | \u001b[0m 0.9342  \u001b[0m | \u001b[0m 0.859   \u001b[0m | \u001b[0m 0.258   \u001b[0m | \u001b[0m 0.1979  \u001b[0m | \u001b[0m 23.89   \u001b[0m | \u001b[0m 473.3   \u001b[0m | \u001b[0m 20.39   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1103  \u001b[0m | \u001b[0m 0.957   \u001b[0m | \u001b[0m 0.5047  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.2706  \u001b[0m | \u001b[0m 8.573   \u001b[0m | \u001b[0m 757.1   \u001b[0m | \u001b[0m 17.0    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1191  \u001b[0m | \u001b[0m 0.2656  \u001b[0m | \u001b[0m 0.04668 \u001b[0m | \u001b[0m 0.03001 \u001b[0m | \u001b[0m 0.1727  \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 861.6   \u001b[0m | \u001b[0m 139.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1143  \u001b[0m | \u001b[0m 0.8199  \u001b[0m | \u001b[0m 0.4933  \u001b[0m | \u001b[0m 0.7328  \u001b[0m | \u001b[0m 0.2643  \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 398.9   \u001b[0m | \u001b[0m 92.87   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1183  \u001b[0m | \u001b[0m 0.4781  \u001b[0m | \u001b[0m 0.1134  \u001b[0m | \u001b[0m 0.3489  \u001b[0m | \u001b[0m 0.2055  \u001b[0m | \u001b[0m 10.65   \u001b[0m | \u001b[0m 821.2   \u001b[0m | \u001b[0m 137.4   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.12    \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.371   \u001b[0m | \u001b[0m 9.194   \u001b[0m | \u001b[0m 969.5   \u001b[0m | \u001b[0m 23.1    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1123  \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.0695  \u001b[0m | \u001b[0m 0.3948  \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 27.02   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1097  \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.1576  \u001b[0m | \u001b[0m 0.9077  \u001b[0m | \u001b[0m 0.2679  \u001b[0m | \u001b[0m 24.11   \u001b[0m | \u001b[0m 463.7   \u001b[0m | \u001b[0m 20.85   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1066  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.5603  \u001b[0m | \u001b[0m 0.4809  \u001b[0m | \u001b[0m 0.09778 \u001b[0m | \u001b[0m 17.32   \u001b[0m | \u001b[0m 351.6   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1089  \u001b[0m | \u001b[0m 0.4213  \u001b[0m | \u001b[0m 0.03239 \u001b[0m | \u001b[0m 0.9495  \u001b[0m | \u001b[0m 0.03877 \u001b[0m | \u001b[0m 20.56   \u001b[0m | \u001b[0m 344.4   \u001b[0m | \u001b[0m 78.39   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1253  \u001b[0m | \u001b[0m 0.3696  \u001b[0m | \u001b[0m 0.9666  \u001b[0m | \u001b[0m 0.0882  \u001b[0m | \u001b[0m 0.3123  \u001b[0m | \u001b[0m 22.58   \u001b[0m | \u001b[0m 694.0   \u001b[0m | \u001b[0m 115.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.112   \u001b[0m | \u001b[0m 0.2374  \u001b[0m | \u001b[0m 0.5845  \u001b[0m | \u001b[0m 0.6013  \u001b[0m | \u001b[0m 0.06929 \u001b[0m | \u001b[0m 24.59   \u001b[0m | \u001b[0m 646.7   \u001b[0m | \u001b[0m 126.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1068  \u001b[0m | \u001b[0m 0.6942  \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.7711  \u001b[0m | \u001b[0m 0.1554  \u001b[0m | \u001b[0m 16.79   \u001b[0m | \u001b[0m 331.1   \u001b[0m | \u001b[0m 40.78   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.127   \u001b[0m | \u001b[0m 0.1268  \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 0.7912  \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 18.31   \u001b[0m | \u001b[0m 255.6   \u001b[0m | \u001b[0m 68.42   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1159  \u001b[0m | \u001b[0m 0.7789  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.5176  \u001b[0m | \u001b[0m 0.2534  \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 925.9   \u001b[0m | \u001b[0m 114.4   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1114  \u001b[0m | \u001b[0m 0.7465  \u001b[0m | \u001b[0m 0.5076  \u001b[0m | \u001b[0m 0.4674  \u001b[0m | \u001b[0m 0.1711  \u001b[0m | \u001b[0m 22.92   \u001b[0m | \u001b[0m 806.4   \u001b[0m | \u001b[0m 121.4   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1079  \u001b[0m | \u001b[0m 0.5223  \u001b[0m | \u001b[0m 0.86    \u001b[0m | \u001b[0m 0.6945  \u001b[0m | \u001b[0m 0.01284 \u001b[0m | \u001b[0m 4.377   \u001b[0m | \u001b[0m 979.3   \u001b[0m | \u001b[0m 48.22   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1131  \u001b[0m | \u001b[0m 0.43    \u001b[0m | \u001b[0m 0.5958  \u001b[0m | \u001b[0m 0.8619  \u001b[0m | \u001b[0m 0.2839  \u001b[0m | \u001b[0m 3.467   \u001b[0m | \u001b[0m 115.4   \u001b[0m | \u001b[0m 28.4    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1088  \u001b[0m | \u001b[0m 0.3907  \u001b[0m | \u001b[0m 0.0659  \u001b[0m | \u001b[0m 0.6367  \u001b[0m | \u001b[0m 0.07079 \u001b[0m | \u001b[0m 10.75   \u001b[0m | \u001b[0m 349.4   \u001b[0m | \u001b[0m 77.46   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# In parallel, loop through the clusters and run the optimizer for a model for each cluster. Save best model\n",
    "# params for each cluster to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Catch22 LGBM Models Bayes\", \n",
    "                      total=len(train_df_catch22_clust_ls))) as progress_bar:\n",
    "    catch22_clust_mods_bayes = Parallel(n_jobs=3)(delayed(optimize_lgbm_w_bayes)(train_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                 train_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                                 val_df_catch22_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                                 val_df_catch22_clust_ls[i].iloc[:,0]) for i in range(len(train_df_catch22_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ee93870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert params for each model to integer where necessary \n",
    "for n in range(len(catch22_clust_mods_bayes)):\n",
    "    catch22_clust_mods_bayes[n][\"max_depth\"] = int(round(catch22_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    catch22_clust_mods_bayes[n][\"n_estimators\"] = int(round(catch22_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    catch22_clust_mods_bayes[n][\"num_leaves\"] = int(round(catch22_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eee28548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train_val data into a list of data frames as well\n",
    "train_val_df_catch22_clust_ls = [df.reset_index(drop=True) for _,df in train_val_df_full_catch22.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "816e0183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes Final:  80%|█████████▌  | 4/5 [00:42<00:10, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.6601896078816399, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6601896078816399\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1960251279136741, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1960251279136741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes Final: 100%|████████████| 5/5 [00:49<00:00,  9.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# Using the train_val data, compute a final model for each cluster\n",
    "with tqdm_joblib(tqdm(desc=\"Catch22 LGBM Models Bayes Final\", \n",
    "                      total=len(catch22_clust_mods_bayes))) as progress_bar:\n",
    "    catch22_clust_mods_bayes_final = Parallel(n_jobs=3)(delayed(train_lgbm)(catch22_clust_mods_bayes[i], \n",
    "                                                                            train_val_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                            train_val_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(catch22_clust_mods_bayes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d50db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final models to files\n",
    "for model_no in range(len(catch22_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/Catch22 KMeans/model_{model_no}\"\n",
    "    joblib.dump(catch22_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e01a528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_clust_mods_bayes_final = list()\n",
    "\n",
    "for model_no in range(len(train_val_df_catch22_clust_ls)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/Catch22 KMeans/model_{model_no}\"\n",
    "    catch22_clust_mods_bayes_final.append(joblib.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "afee447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes Residuals: 100%|████████| 5/5 [00:09<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each model, compute the model's residuals and save to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Catch22 LGBM Models Bayes Residuals\", \n",
    "                      total=len(catch22_clust_mods_bayes_final))) as progress_bar:\n",
    "    catch22_clust_mods_bayes_resid = Parallel(n_jobs=3)(delayed(compute_lgbm_residuals)(catch22_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_catch22_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(catch22_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b9044d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[3.1674887922998707, -3.919883131163189, -8.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1.3179691192486302, -23.649895182220007, -13....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.12009538735095271, -1.0302712135609917, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[8.409688232619374, 26.361903022045055, -33.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[13.271590985891493, 15.492001013611684, 9.594...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                           residual\n",
       "0        1  [3.1674887922998707, -3.919883131163189, -8.96...\n",
       "1        2  [1.3179691192486302, -23.649895182220007, -13....\n",
       "2        3  [0.12009538735095271, -1.0302712135609917, -0....\n",
       "3        4  [8.409688232619374, 26.361903022045055, -33.31...\n",
       "4        5  [13.271590985891493, 15.492001013611684, 9.594..."
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch22_res_df = pd.DataFrame({'cluster': list({(i+1): catch22_clust_mods_bayes_resid[i] for i in range(len(catch22_clust_mods_bayes_resid))}.keys()),\n",
    "                               'residual': list({(i+1): catch22_clust_mods_bayes_resid[i] for i in range(len(catch22_clust_mods_bayes_resid))}.values())})\n",
    "\n",
    "catch22_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4f3cfcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_res_df.to_csv(\"Results/Global/LightGBM Bayes/Catch22 KMeans/residual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6fd544af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test data into a list of data frames, one for each cluster\n",
    "test_df_full_catch22_clust_ls = [df.reset_index(drop=True) for _,df in test_df_full_catch22.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e9782c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Catch22 LGBM Models Bayes Test Preds:   0%|               | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1453  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.1481  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1646  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1794  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1578  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1453  \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.036   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.7869  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 10.13   \u001b[0m | \u001b[0m 848.5   \u001b[0m | \u001b[0m 143.9   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1421  \u001b[0m | \u001b[95m 0.4175  \u001b[0m | \u001b[95m 0.3447  \u001b[0m | \u001b[95m 0.3538  \u001b[0m | \u001b[95m 0.132   \u001b[0m | \u001b[95m 21.01   \u001b[0m | \u001b[95m 487.2   \u001b[0m | \u001b[95m 12.95   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1637  \u001b[0m | \u001b[0m 0.7583  \u001b[0m | \u001b[0m 0.7091  \u001b[0m | \u001b[0m 0.3882  \u001b[0m | \u001b[0m 0.4061  \u001b[0m | \u001b[0m 11.24   \u001b[0m | \u001b[0m 492.4   \u001b[0m | \u001b[0m 29.95   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.144   \u001b[0m | \u001b[0m 0.8232  \u001b[0m | \u001b[0m 0.8092  \u001b[0m | \u001b[0m 0.2382  \u001b[0m | \u001b[0m 0.06136 \u001b[0m | \u001b[0m 2.454   \u001b[0m | \u001b[0m 482.1   \u001b[0m | \u001b[0m 12.18   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1426  \u001b[0m | \u001b[0m 0.8122  \u001b[0m | \u001b[0m 0.888   \u001b[0m | \u001b[0m 0.6548  \u001b[0m | \u001b[0m 0.1651  \u001b[0m | \u001b[0m 6.523   \u001b[0m | \u001b[0m 505.1   \u001b[0m | \u001b[0m 10.52   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-0.141   \u001b[0m | \u001b[95m 0.2858  \u001b[0m | \u001b[95m 0.065   \u001b[0m | \u001b[95m 0.5467  \u001b[0m | \u001b[95m 0.1058  \u001b[0m | \u001b[95m 21.81   \u001b[0m | \u001b[95m 509.0   \u001b[0m | \u001b[95m 23.7    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1447  \u001b[0m | \u001b[0m 0.4643  \u001b[0m | \u001b[0m 0.1812  \u001b[0m | \u001b[0m 0.7827  \u001b[0m | \u001b[0m 0.2177  \u001b[0m | \u001b[0m 3.899   \u001b[0m | \u001b[0m 516.1   \u001b[0m | \u001b[0m 30.19   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1527  \u001b[0m | \u001b[0m 0.4882  \u001b[0m | \u001b[0m 0.2471  \u001b[0m | \u001b[0m 0.6967  \u001b[0m | \u001b[0m 0.3534  \u001b[0m | \u001b[0m 12.85   \u001b[0m | \u001b[0m 527.4   \u001b[0m | \u001b[0m 12.94   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1642  \u001b[0m | \u001b[0m 0.8848  \u001b[0m | \u001b[0m 0.9812  \u001b[0m | \u001b[0m 0.07917 \u001b[0m | \u001b[0m 0.3448  \u001b[0m | \u001b[0m 23.44   \u001b[0m | \u001b[0m 527.2   \u001b[0m | \u001b[0m 34.39   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1414  \u001b[0m | \u001b[0m 0.474   \u001b[0m | \u001b[0m 0.3503  \u001b[0m | \u001b[0m 0.177   \u001b[0m | \u001b[0m 0.1008  \u001b[0m | \u001b[0m 18.88   \u001b[0m | \u001b[0m 509.8   \u001b[0m | \u001b[0m 48.48   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1439  \u001b[0m | \u001b[0m 0.5659  \u001b[0m | \u001b[0m 0.1043  \u001b[0m | \u001b[0m 0.6215  \u001b[0m | \u001b[0m 0.1686  \u001b[0m | \u001b[0m 4.478   \u001b[0m | \u001b[0m 531.1   \u001b[0m | \u001b[0m 48.02   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1502  \u001b[0m | \u001b[0m 0.6346  \u001b[0m | \u001b[0m 0.4827  \u001b[0m | \u001b[0m 0.1923  \u001b[0m | \u001b[0m 0.2672  \u001b[0m | \u001b[0m 5.446   \u001b[0m | \u001b[0m 544.2   \u001b[0m | \u001b[0m 27.93   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1689  \u001b[0m | \u001b[0m 0.1777  \u001b[0m | \u001b[0m 0.8063  \u001b[0m | \u001b[0m 0.02467 \u001b[0m | \u001b[0m 0.3243  \u001b[0m | \u001b[0m 23.72   \u001b[0m | \u001b[0m 530.7   \u001b[0m | \u001b[0m 62.5    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1605  \u001b[0m | \u001b[0m 0.2489  \u001b[0m | \u001b[0m 0.2532  \u001b[0m | \u001b[0m 0.005826\u001b[0m | \u001b[0m 0.4074  \u001b[0m | \u001b[0m 4.283   \u001b[0m | \u001b[0m 513.0   \u001b[0m | \u001b[0m 63.22   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1526  \u001b[0m | \u001b[0m 0.9164  \u001b[0m | \u001b[0m 0.5227  \u001b[0m | \u001b[0m 0.319   \u001b[0m | \u001b[0m 0.2524  \u001b[0m | \u001b[0m 15.67   \u001b[0m | \u001b[0m 550.4   \u001b[0m | \u001b[0m 45.62   \u001b[0m |\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m-0.1406  \u001b[0m | \u001b[95m 0.261   \u001b[0m | \u001b[95m 0.8889  \u001b[0m | \u001b[95m 0.05705 \u001b[0m | \u001b[95m 0.06345 \u001b[0m | \u001b[95m 3.827   \u001b[0m | \u001b[95m 545.0   \u001b[0m | \u001b[95m 67.19   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1577  \u001b[0m | \u001b[0m 0.1441  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.23    \u001b[0m | \u001b[0m 21.73   \u001b[0m | \u001b[0m 557.8   \u001b[0m | \u001b[0m 67.96   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1692  \u001b[0m | \u001b[0m 0.9993  \u001b[0m | \u001b[0m 0.9103  \u001b[0m | \u001b[0m 0.7928  \u001b[0m | \u001b[0m 0.4237  \u001b[0m | \u001b[0m 6.964   \u001b[0m | \u001b[0m 532.6   \u001b[0m | \u001b[0m 83.85   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1543  \u001b[0m | \u001b[0m 0.8043  \u001b[0m | \u001b[0m 0.5248  \u001b[0m | \u001b[0m 0.3997  \u001b[0m | \u001b[0m 0.3545  \u001b[0m | \u001b[0m 4.489   \u001b[0m | \u001b[0m 570.3   \u001b[0m | \u001b[0m 50.97   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1485  \u001b[0m | \u001b[0m 0.9505  \u001b[0m | \u001b[0m 0.2204  \u001b[0m | \u001b[0m 0.1435  \u001b[0m | \u001b[0m 0.3142  \u001b[0m | \u001b[0m 3.399   \u001b[0m | \u001b[0m 570.8   \u001b[0m | \u001b[0m 76.66   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.164   \u001b[0m | \u001b[0m 0.8545  \u001b[0m | \u001b[0m 0.6339  \u001b[0m | \u001b[0m 0.5968  \u001b[0m | \u001b[0m 0.3191  \u001b[0m | \u001b[0m 14.5    \u001b[0m | \u001b[0m 558.5   \u001b[0m | \u001b[0m 90.77   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1475  \u001b[0m | \u001b[0m 0.264   \u001b[0m | \u001b[0m 0.9138  \u001b[0m | \u001b[0m 0.6217  \u001b[0m | \u001b[0m 0.1657  \u001b[0m | \u001b[0m 19.63   \u001b[0m | \u001b[0m 580.9   \u001b[0m | \u001b[0m 65.27   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1953  \u001b[0m | \u001b[0m 0.1536  \u001b[0m | \u001b[0m 0.4596  \u001b[0m | \u001b[0m 0.8216  \u001b[0m | \u001b[0m 0.4134  \u001b[0m | \u001b[0m 24.88   \u001b[0m | \u001b[0m 582.3   \u001b[0m | \u001b[0m 88.01   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1612  \u001b[0m | \u001b[0m 0.5453  \u001b[0m | \u001b[0m 0.8285  \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.4767  \u001b[0m | \u001b[0m 4.372   \u001b[0m | \u001b[0m 593.5   \u001b[0m | \u001b[0m 61.06   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8888689122221809, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8888689122221809\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05704819489576585, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05704819489576585\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.467929430333169, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.467929430333169\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7443938547415976, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7443938547415976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catch22 LGBM Models Bayes Test Preds: 100%|███████| 5/5 [00:05<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each cluster, compute the model's test predictions\n",
    "with tqdm_joblib(tqdm(desc=\"Catch22 LGBM Models Bayes Test Preds\", \n",
    "                      total=len(catch22_clust_mods_bayes_final))) as progress_bar:\n",
    "    catch22_clust_mods_bayes_test_preds = Parallel(n_jobs=4)(delayed(compute_lgbm_test_preds)(catch22_clust_mods_bayes_final[i],\n",
    "                                                                                              test_df_full_catch22_clust_ls[i],\n",
    "                                                                                              lag_n\n",
    "                                                                                             ) for i in range(len(catch22_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ff70f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all data frames from the above list into one data frame of test predictions\n",
    "catch22_clust_bayes_test_preds_df = pd.concat(catch22_clust_mods_bayes_test_preds)\n",
    "# for clust_test_pred_df in catch22_clust_mods_bayes_test_preds:\n",
    "#     catch22_clust_bayes_test_preds_df = catch22_clust_bayes_test_preds_df.append(clust_test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "50450afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test pred performance\n",
    "catch22_clust_bayes_test_perf = compute_lgbm_test_perf(catch22_clust_bayes_test_preds_df,\n",
    "                                                       test_df_full_catch22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e3507fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add normalized performance metrics to the performance data frame\n",
    "catch22_clust_bayes_test_perf['nrmse'] = catch22_clust_bayes_test_perf['rmse']/catch22_clust_bayes_test_perf['mean']\n",
    "catch22_clust_bayes_test_perf['smae'] = catch22_clust_bayes_test_perf['mae']/catch22_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f923d1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      31.191387\n",
       "mae       20.734501\n",
       "mean     265.435072\n",
       "nrmse      0.140589\n",
       "smae       0.095014\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of perf metrics\n",
    "catch22_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2aa188bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0ab0ee35b94466b891118f08a91636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/49728 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6ed71b833144268827a755590542dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/4032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bec050d63184f70a7cef51bf9a7267e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a101dfd7154fb79131dd7fb551dea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/26880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d31cc43010c41999bbf01adedf79cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/16128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through the model preds and residuals, and create a df of bootstrap PIs for each prediction\n",
    "# save to a list of data frames\n",
    "catch22_clust_test_pred_int = list()\n",
    "for i in range(len(catch22_clust_mods_bayes_test_preds)):\n",
    "    catch22_clust_test_pred_int.append(compute_lgbm_boostrap_int(catch22_clust_mods_bayes_test_preds[i], \n",
    "                                                                 catch22_clust_mods_bayes_resid[i], \n",
    "                                                                 n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6d189e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster, add the true values for y to the data frame in a new column called actual\n",
    "for n in range(1, len(catch22_clust_test_pred_int)+1):\n",
    "    y_actual_sub = test_df_full_catch22.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    catch22_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c79e7407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all PI data frames into one data frame\n",
    "catch22_clust_test_pred_int_df = pd.concat(catch22_clust_test_pred_int)\n",
    "# for clust_test_pred_int_df in catch22_clust_test_pred_int:\n",
    "#     catch22_clust_test_pred_int_df = catch22_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "56567026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On that one data frame, compute the 95% and 80% PI scores for each observation\n",
    "catch22_clust_test_pred_int_df['int_95_score'] = interval_score(catch22_clust_test_pred_int_df['actual'],\n",
    "                                                                catch22_clust_test_pred_int_df['lo_95'],\n",
    "                                                                catch22_clust_test_pred_int_df['hi_95'],\n",
    "                                                                0.95\n",
    "                                                               )\n",
    "\n",
    "catch22_clust_test_pred_int_df['int_80_score'] = interval_score(catch22_clust_test_pred_int_df['actual'],\n",
    "                                                                catch22_clust_test_pred_int_df['lo_80'],\n",
    "                                                                catch22_clust_test_pred_int_df['hi_80'],\n",
    "                                                                0.80\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6524ae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.756515\n",
       "lo_95           208.958208\n",
       "hi_95           324.605175\n",
       "lo_80           236.785350\n",
       "hi_80           295.399973\n",
       "actual          265.435072\n",
       "int_95_score    216.345320\n",
       "int_80_score    120.236059\n",
       "dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean of the PI scores\n",
    "catch22_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7d230c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22_clust_test_pred_int_df_grouped = catch22_clust_test_pred_int_df.groupby(\"ts_index\")\\\n",
    ".agg({\"int_95_score\": \"mean\", \"int_80_score\": \"mean\", \"actual\": \"mean\"}).reset_index()\n",
    "\n",
    "catch22_clust_test_pred_int_df_grouped['int_95_score_scaled'] = catch22_clust_test_pred_int_df_grouped['int_95_score']/catch22_clust_test_pred_int_df_grouped['actual']\n",
    "catch22_clust_test_pred_int_df_grouped['int_80_score_scaled'] = catch22_clust_test_pred_int_df_grouped['int_80_score']/catch22_clust_test_pred_int_df_grouped['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8a39a0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_80_score_scaled    0.545119\n",
       "int_95_score_scaled    0.943197\n",
       "dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch22_clust_test_pred_int_df_grouped[['int_80_score_scaled', 'int_95_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b9612fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PI df to csv\n",
    "catch22_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/Catch22 KMeans/test_pred_intervals.csv\",\n",
    "                                      index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cefa76",
   "metadata": {},
   "source": [
    "# Test and Train - TSFeat KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "977a2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete variables that are no longer needed\n",
    "del catch22_clust_test_pred_int_df\n",
    "del catch22_clust_test_pred_int\n",
    "del y_actual_sub\n",
    "del catch22_clust_bayes_test_perf\n",
    "del catch22_clust_bayes_test_preds_df\n",
    "del catch22_clust_mods_bayes_test_preds\n",
    "del test_df_full_catch22_clust_ls\n",
    "del test_df_full_catch22\n",
    "del catch22_clust_mods_bayes_resid\n",
    "del catch22_clust_mods_bayes_final\n",
    "del train_val_df_catch22_clust_ls\n",
    "del train_val_df_full_catch22\n",
    "del catch22_clust_mods_bayes\n",
    "del train_df_catch22_clust_ls\n",
    "del val_df_catch22_clust_ls \n",
    "del train_df_full_catch22\n",
    "del val_df_full_catch22\n",
    "del catch22_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "75798c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the garbage collector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5dd301f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cluster assignments for the KMeans clusted based on tsfeat feature set\n",
    "tsfeat_clust = pd.read_csv(\"Results/Clustering/KMeans/kmeans_tsfeat_clustering_assign.csv\")\n",
    "tsfeat_clust['cluster'] =  tsfeat_clust['kmeans_tsfeat_clust_assign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0bf13e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the train, val, train_val, and test data frames with the cluster assignments\n",
    "train_df_full_tsfeat = train_df_full.merge(tsfeat_clust, on=\"ts_index\")\n",
    "val_df_full_tsfeat = val_df_full.merge(tsfeat_clust, on=\"ts_index\")\n",
    "train_val_df_full_tsfeat = train_val_df_full.merge(tsfeat_clust, on=\"ts_index\")\n",
    "test_df_full_tsfeat = test_df_full.merge(tsfeat_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "03acc555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of data frames for training and validation, where each df in the list is data for one cluster\n",
    "train_df_tsfeat_clust_ls = [df.reset_index(drop=True) for _,df in train_df_full_tsfeat.groupby(\"cluster\")]\n",
    "val_df_tsfeat_clust_ls = [df.reset_index(drop=True) for _,df in val_df_full_tsfeat.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "44004b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes:  50%|█████████         | 1/2 [12:08<12:08, 728.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2024  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2063  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.229   \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2466  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.219   \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1964  \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2111  \u001b[0m | \u001b[0m 0.4405  \u001b[0m | \u001b[0m 0.1374  \u001b[0m | \u001b[0m 0.64    \u001b[0m | \u001b[0m 0.3496  \u001b[0m | \u001b[0m 2.775   \u001b[0m | \u001b[0m 837.2   \u001b[0m | \u001b[0m 144.8   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.1936  \u001b[0m | \u001b[95m 0.5206  \u001b[0m | \u001b[95m 0.6055  \u001b[0m | \u001b[95m 0.7878  \u001b[0m | \u001b[95m 0.08544 \u001b[0m | \u001b[95m 2.594   \u001b[0m | \u001b[95m 828.8   \u001b[0m | \u001b[95m 143.6   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2185  \u001b[0m | \u001b[0m 0.6033  \u001b[0m | \u001b[0m 0.3261  \u001b[0m | \u001b[0m 0.8998  \u001b[0m | \u001b[0m 0.289   \u001b[0m | \u001b[0m 7.527   \u001b[0m | \u001b[0m 820.7   \u001b[0m | \u001b[0m 140.6   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2682  \u001b[0m | \u001b[0m 0.1865  \u001b[0m | \u001b[0m 0.5425  \u001b[0m | \u001b[0m 0.7288  \u001b[0m | \u001b[0m 0.4342  \u001b[0m | \u001b[0m 9.795   \u001b[0m | \u001b[0m 832.5   \u001b[0m | \u001b[0m 139.1   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.1895  \u001b[0m | \u001b[95m 0.879   \u001b[0m | \u001b[95m 0.2281  \u001b[0m | \u001b[95m 0.4638  \u001b[0m | \u001b[95m 0.01206 \u001b[0m | \u001b[95m 12.72   \u001b[0m | \u001b[95m 468.8   \u001b[0m | \u001b[95m 26.12   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2143  \u001b[0m | \u001b[0m 0.192   \u001b[0m | \u001b[0m 0.7131  \u001b[0m | \u001b[0m 0.6829  \u001b[0m | \u001b[0m 0.2629  \u001b[0m | \u001b[0m 11.72   \u001b[0m | \u001b[0m 473.6   \u001b[0m | \u001b[0m 28.32   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2449  \u001b[0m | \u001b[0m 0.7003  \u001b[0m | \u001b[0m 0.6221  \u001b[0m | \u001b[0m 0.09056 \u001b[0m | \u001b[0m 0.4959  \u001b[0m | \u001b[0m 14.93   \u001b[0m | \u001b[0m 465.5   \u001b[0m | \u001b[0m 24.21   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1964  \u001b[0m | \u001b[0m 0.7728  \u001b[0m | \u001b[0m 0.1275  \u001b[0m | \u001b[0m 0.8038  \u001b[0m | \u001b[0m 0.1575  \u001b[0m | \u001b[0m 17.51   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 24.3    \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1917  \u001b[0m | \u001b[0m 0.6437  \u001b[0m | \u001b[0m 0.3762  \u001b[0m | \u001b[0m 0.7553  \u001b[0m | \u001b[0m 0.08379 \u001b[0m | \u001b[0m 13.04   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 24.04   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.295   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 15.36   \u001b[0m | \u001b[0m 470.7   \u001b[0m | \u001b[0m 27.74   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1998  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 0.381   \u001b[0m | \u001b[0m 0.1797  \u001b[0m | \u001b[0m 0.1494  \u001b[0m | \u001b[0m 5.927   \u001b[0m | \u001b[0m 819.3   \u001b[0m | \u001b[0m 141.6   \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m-0.189   \u001b[0m | \u001b[95m 0.8973  \u001b[0m | \u001b[95m 0.531   \u001b[0m | \u001b[95m 0.2387  \u001b[0m | \u001b[95m 0.08109 \u001b[0m | \u001b[95m 11.57   \u001b[0m | \u001b[95m 475.3   \u001b[0m | \u001b[95m 28.99   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2301  \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 0.7699  \u001b[0m | \u001b[0m 0.7385  \u001b[0m | \u001b[0m 0.4304  \u001b[0m | \u001b[0m 10.19   \u001b[0m | \u001b[0m 466.6   \u001b[0m | \u001b[0m 27.07   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2056  \u001b[0m | \u001b[0m 0.1942  \u001b[0m | \u001b[0m 0.1678  \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.2678  \u001b[0m | \u001b[0m 3.474   \u001b[0m | \u001b[0m 827.0   \u001b[0m | \u001b[0m 147.3   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1974  \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 0.7935  \u001b[0m | \u001b[0m 0.3818  \u001b[0m | \u001b[0m 0.1722  \u001b[0m | \u001b[0m 9.563   \u001b[0m | \u001b[0m 474.6   \u001b[0m | \u001b[0m 27.73   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1915  \u001b[0m | \u001b[0m 0.2744  \u001b[0m | \u001b[0m 0.8207  \u001b[0m | \u001b[0m 0.4659  \u001b[0m | \u001b[0m 0.07158 \u001b[0m | \u001b[0m 4.72    \u001b[0m | \u001b[0m 829.4   \u001b[0m | \u001b[0m 146.7   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1981  \u001b[0m | \u001b[0m 0.4321  \u001b[0m | \u001b[0m 0.03347 \u001b[0m | \u001b[0m 0.9627  \u001b[0m | \u001b[0m 0.1894  \u001b[0m | \u001b[0m 17.2    \u001b[0m | \u001b[0m 475.4   \u001b[0m | \u001b[0m 23.44   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.2028  \u001b[0m | \u001b[0m 0.1379  \u001b[0m | \u001b[0m 0.2242  \u001b[0m | \u001b[0m 0.7955  \u001b[0m | \u001b[0m 0.2345  \u001b[0m | \u001b[0m 3.194   \u001b[0m | \u001b[0m 825.6   \u001b[0m | \u001b[0m 143.4   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2348  \u001b[0m | \u001b[0m 0.3983  \u001b[0m | \u001b[0m 0.4026  \u001b[0m | \u001b[0m 0.9185  \u001b[0m | \u001b[0m 0.3664  \u001b[0m | \u001b[0m 6.985   \u001b[0m | \u001b[0m 829.4   \u001b[0m | \u001b[0m 149.2   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.2363  \u001b[0m | \u001b[0m 0.6755  \u001b[0m | \u001b[0m 0.2202  \u001b[0m | \u001b[0m 0.9378  \u001b[0m | \u001b[0m 0.4817  \u001b[0m | \u001b[0m 19.51   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 20.37   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.2317  \u001b[0m | \u001b[0m 0.5839  \u001b[0m | \u001b[0m 0.6596  \u001b[0m | \u001b[0m 0.242   \u001b[0m | \u001b[0m 0.4371  \u001b[0m | \u001b[0m 10.42   \u001b[0m | \u001b[0m 474.8   \u001b[0m | \u001b[0m 22.16   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1912  \u001b[0m | \u001b[0m 0.6514  \u001b[0m | \u001b[0m 0.428   \u001b[0m | \u001b[0m 0.7843  \u001b[0m | \u001b[0m 0.07997 \u001b[0m | \u001b[0m 9.17    \u001b[0m | \u001b[0m 469.3   \u001b[0m | \u001b[0m 24.92   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.2362  \u001b[0m | \u001b[0m 0.6573  \u001b[0m | \u001b[0m 0.7202  \u001b[0m | \u001b[0m 0.7779  \u001b[0m | \u001b[0m 0.4688  \u001b[0m | \u001b[0m 11.22   \u001b[0m | \u001b[0m 469.0   \u001b[0m | \u001b[0m 22.42   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1902  \u001b[0m | \u001b[0m 0.5844  \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.7799  \u001b[0m | \u001b[0m 0.07564 \u001b[0m | \u001b[0m 10.05   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 24.99   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes: 100%|██████████████████| 2/2 [18:01<00:00, 540.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run the Bayesian optimizer, in parallel, for each cluster\n",
    "with tqdm_joblib(tqdm(desc=\"TSFeat LGBM Models Bayes\", \n",
    "                      total=len(train_df_tsfeat_clust_ls))) as progress_bar:\n",
    "    tsfeat_clust_mods_bayes = Parallel(n_jobs=2)(delayed(optimize_lgbm_w_bayes)(train_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                 train_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                                 val_df_tsfeat_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                                 val_df_tsfeat_clust_ls[i].iloc[:,0]) for i in range(len(train_df_tsfeat_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5b52c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each set of params returned by the optimizer, convert the required parameters to integers\n",
    "for n in range(len(tsfeat_clust_mods_bayes)):\n",
    "    tsfeat_clust_mods_bayes[n][\"max_depth\"] = int(round(tsfeat_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    tsfeat_clust_mods_bayes[n][\"n_estimators\"] = int(round(tsfeat_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    tsfeat_clust_mods_bayes[n][\"num_leaves\"] = int(round(tsfeat_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ac45426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train_val df into a list of data frames, one df per cluster\n",
    "train_val_df_tsfeat_clust_ls = [df.reset_index(drop=True) for _,df in train_val_df_full_tsfeat.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4b1361e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes Final: 100%|█████████████| 2/2 [00:53<00:00, 26.94s/it]\n"
     ]
    }
   ],
   "source": [
    "# In parallel, fit a model to each train_val df using the params found by the Bayesian optimizer\n",
    "with tqdm_joblib(tqdm(desc=\"TSFeat LGBM Models Bayes Final\", \n",
    "                      total=len(tsfeat_clust_mods_bayes))) as progress_bar:\n",
    "    tsfeat_clust_mods_bayes_final = Parallel(n_jobs=2)(delayed(train_lgbm)(tsfeat_clust_mods_bayes[i], \n",
    "                                                                            train_val_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                            train_val_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(tsfeat_clust_mods_bayes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "07fa938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save those models to files\n",
    "for model_no in range(len(tsfeat_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/TSFeat KMeans/model_{model_no}\"\n",
    "    joblib.dump(tsfeat_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ea0d522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_clust_mods_bayes_final = list()\n",
    "\n",
    "for model_no in range(len(train_val_df_tsfeat_clust_ls)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/TSFeat KMeans/model_{model_no}\"\n",
    "    tsfeat_clust_mods_bayes_final.append(joblib.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4f1da27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes Residuals: 100%|█████████| 2/2 [00:11<00:00,  5.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each model, compute the residuals and save the results into a list\n",
    "with tqdm_joblib(tqdm(desc=\"TSFeat LGBM Models Bayes Residuals\", \n",
    "                      total=len(tsfeat_clust_mods_bayes_final))) as progress_bar:\n",
    "    tsfeat_clust_mods_bayes_resid = Parallel(n_jobs=2)(delayed(compute_lgbm_residuals)(tsfeat_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_tsfeat_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(tsfeat_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c7b581dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[-4.4743312200740775, 12.246247882660498, -37....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[36.57535456378076, -10.735407496008037, 15.87...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                           residual\n",
       "0        1  [-4.4743312200740775, 12.246247882660498, -37....\n",
       "1        2  [36.57535456378076, -10.735407496008037, 15.87..."
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsfeat_clust_res_df = pd.DataFrame({'cluster': list({(i+1): tsfeat_clust_mods_bayes_resid[i] for i in range(len(tsfeat_clust_mods_bayes_resid))}.keys()),\n",
    "                                    'residual': list({(i+1): tsfeat_clust_mods_bayes_resid[i] for i in range(len(tsfeat_clust_mods_bayes_resid))}.values())})\n",
    "\n",
    "tsfeat_clust_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b5ea3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_clust_res_df.to_csv(\"Results/Global/LightGBM Bayes/TSFeat KMeans/residual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1c94246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test df into a list of data frames as well, one df per cluster\n",
    "test_df_full_tsfeat_clust_ls = [df.reset_index(drop=True) for _,df in test_df_full_tsfeat.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ad497a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSFeat LGBM Models Bayes Test Preds: 100%|████████| 2/2 [00:03<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the models and test data frames and compute the test predictions\n",
    "with tqdm_joblib(tqdm(desc=\"TSFeat LGBM Models Bayes Test Preds\", \n",
    "                      total=len(tsfeat_clust_mods_bayes_final))) as progress_bar:\n",
    "    tsfeat_clust_mods_bayes_test_preds = Parallel(n_jobs=2)(delayed(compute_lgbm_test_preds)(tsfeat_clust_mods_bayes_final[i],\n",
    "                                                                                           test_df_full_tsfeat_clust_ls[i],\n",
    "                                                                                           lag_n\n",
    "                                                                                          ) for i in range(len(tsfeat_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3990aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame to which the test preds from each cluster are appened\n",
    "tsfeat_clust_bayes_test_preds_df = pd.concat(tsfeat_clust_mods_bayes_test_preds)\n",
    "# for clust_test_pred_df in tsfeat_clust_mods_bayes_test_preds:\n",
    "#     tsfeat_clust_bayes_test_preds_df = tsfeat_clust_bayes_test_preds_df.append(clust_test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "03892d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test pred performance\n",
    "tsfeat_clust_bayes_test_perf = compute_lgbm_test_perf(tsfeat_clust_bayes_test_preds_df,\n",
    "                                                       test_df_full_tsfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5552a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized performance metrics\n",
    "tsfeat_clust_bayes_test_perf['nrmse'] = tsfeat_clust_bayes_test_perf['rmse']/tsfeat_clust_bayes_test_perf['mean']\n",
    "tsfeat_clust_bayes_test_perf['smae'] = tsfeat_clust_bayes_test_perf['mae']/tsfeat_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bb4388d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      30.818267\n",
       "mae       20.440862\n",
       "mean     265.435072\n",
       "nrmse      0.139726\n",
       "smae       0.094355\n",
       "dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the normalized performance metrics\n",
    "tsfeat_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a02c48b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106a7e2e30e7455ba64c66ad2bd92602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/69888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa3676656db45aa94eb1f509419da15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/32256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each model/cluster, compute the PIs for the test preds via residual bootstrap. \n",
    "# Save the resulting data frames to a list\n",
    "tsfeat_clust_test_pred_int = list()\n",
    "for i in range(len(tsfeat_clust_mods_bayes_test_preds)):\n",
    "    tsfeat_clust_test_pred_int.append(compute_lgbm_boostrap_int(tsfeat_clust_mods_bayes_test_preds[i], \n",
    "                                                                 tsfeat_clust_mods_bayes_resid[i], \n",
    "                                                                 n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "90f0fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each PI data frame, grab the true value of the target for that cluster and add a df column for the true data\n",
    "for n in range(1, len(tsfeat_clust_test_pred_int)+1):\n",
    "    y_actual_sub = test_df_full_tsfeat.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    tsfeat_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1cf309e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all PI data frames into one\n",
    "tsfeat_clust_test_pred_int_df = pd.concat(tsfeat_clust_test_pred_int)\n",
    "# for clust_test_pred_int_df in tsfeat_clust_test_pred_int:\n",
    "#     tsfeat_clust_test_pred_int_df = tsfeat_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "42d9da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the interval scores for each observation in that one df\n",
    "tsfeat_clust_test_pred_int_df['int_95_score'] = interval_score(tsfeat_clust_test_pred_int_df['actual'],\n",
    "                                                                tsfeat_clust_test_pred_int_df['lo_95'],\n",
    "                                                                tsfeat_clust_test_pred_int_df['hi_95'],\n",
    "                                                                0.95\n",
    "                                                               )\n",
    "\n",
    "tsfeat_clust_test_pred_int_df['int_80_score'] = interval_score(tsfeat_clust_test_pred_int_df['actual'],\n",
    "                                                                tsfeat_clust_test_pred_int_df['lo_80'],\n",
    "                                                                tsfeat_clust_test_pred_int_df['hi_80'],\n",
    "                                                                0.80\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9efe3841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.591002\n",
       "lo_95           208.690311\n",
       "hi_95           324.623149\n",
       "lo_80           236.951486\n",
       "hi_80           295.044808\n",
       "actual          265.435072\n",
       "int_95_score    224.184974\n",
       "int_80_score    121.068634\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean PI scores\n",
    "tsfeat_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f0af5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeat_clust_test_pred_int_df_grouped = tsfeat_clust_test_pred_int_df.groupby(\"ts_index\")\\\n",
    ".agg({\"int_95_score\":\"mean\", \"int_80_score\":\"mean\", \"actual\":\"mean\"}).reset_index()\n",
    "\n",
    "tsfeat_clust_test_pred_int_df_grouped['int_95_score_scaled'] = tsfeat_clust_test_pred_int_df_grouped['int_95_score']/tsfeat_clust_test_pred_int_df_grouped['actual']\n",
    "tsfeat_clust_test_pred_int_df_grouped['int_80_score_scaled'] = tsfeat_clust_test_pred_int_df_grouped['int_80_score']/tsfeat_clust_test_pred_int_df_grouped['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4aff2ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_80_score_scaled    0.566261\n",
       "int_95_score_scaled    1.003587\n",
       "dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsfeat_clust_test_pred_int_df_grouped[['int_80_score_scaled', 'int_95_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a506a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI df to a csv file\n",
    "tsfeat_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/TSFeat KMeans/test_pred_intervals.csv\",\n",
    "                                     index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694140f",
   "metadata": {},
   "source": [
    "# Train and Test - DTW Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7c258d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete variable which will no longer be used\n",
    "del tsfeat_clust_test_pred_int_df\n",
    "del tsfeat_clust_test_pred_int\n",
    "del y_actual_sub\n",
    "del tsfeat_clust_bayes_test_perf\n",
    "del tsfeat_clust_bayes_test_preds_df\n",
    "del tsfeat_clust_mods_bayes_test_preds\n",
    "del test_df_full_tsfeat_clust_ls\n",
    "del test_df_full_tsfeat\n",
    "del tsfeat_clust_mods_bayes_resid\n",
    "del tsfeat_clust_mods_bayes_final\n",
    "del train_val_df_tsfeat_clust_ls\n",
    "del train_val_df_full_tsfeat\n",
    "del tsfeat_clust_mods_bayes\n",
    "del train_df_tsfeat_clust_ls\n",
    "del val_df_tsfeat_clust_ls \n",
    "del train_df_full_tsfeat\n",
    "del val_df_full_tsfeat\n",
    "del tsfeat_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "76001181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the garbage collector to ensure we are freeing up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6e162c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cluster assignments for the DTW based clusters\n",
    "dtw_clust = pd.read_csv(\"Results/Clustering/DTW/dtw_clustering_assign.csv\")\n",
    "dtw_clust['cluster'] =  dtw_clust['dtw_clust_assign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "15dbb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train, val, train_val, and test data with cluster assignments\n",
    "train_df_full_dtw = train_df_full.merge(dtw_clust, on=\"ts_index\")\n",
    "val_df_full_dtw = val_df_full.merge(dtw_clust, on=\"ts_index\")\n",
    "train_val_df_full_dtw = train_val_df_full.merge(dtw_clust, on=\"ts_index\")\n",
    "test_df_full_dtw = test_df_full.merge(dtw_clust, on=\"ts_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5d5455db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the above data frames into lists of data frames where there is one df per cluster\n",
    "train_df_dtw_clust_ls = [df.reset_index(drop=True) for _,df in train_df_full_dtw.groupby(\"cluster\")]\n",
    "val_df_dtw_clust_ls = [df.reset_index(drop=True) for _,df in val_df_full_dtw.groupby(\"cluster\")]\n",
    "train_val_df_dtw_clust_ls = [df.reset_index(drop=True) for _,df in train_val_df_full_dtw.groupby(\"cluster\")]\n",
    "test_df_full_dtw_clust_ls = [df.reset_index(drop=True) for _,df in test_df_full_dtw.groupby(\"cluster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c1af4b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes:  50%|██████████▌          | 1/2 [12:15<12:15, 735.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1062  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1053  \u001b[0m | \u001b[95m 0.7999  \u001b[0m | \u001b[95m 0.4889  \u001b[0m | \u001b[95m 0.05053 \u001b[0m | \u001b[95m 0.2692  \u001b[0m | \u001b[95m 2.954   \u001b[0m | \u001b[95m 827.3   \u001b[0m | \u001b[95m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1186  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1347  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1158  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1117  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.112   \u001b[0m | \u001b[0m 0.7862  \u001b[0m | \u001b[0m 0.2396  \u001b[0m | \u001b[0m 0.6049  \u001b[0m | \u001b[0m 0.3277  \u001b[0m | \u001b[0m 7.432   \u001b[0m | \u001b[0m 473.9   \u001b[0m | \u001b[0m 22.69   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1345  \u001b[0m | \u001b[0m 0.1855  \u001b[0m | \u001b[0m 0.0744  \u001b[0m | \u001b[0m 0.6661  \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 6.813   \u001b[0m | \u001b[0m 822.9   \u001b[0m | \u001b[0m 145.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1162  \u001b[0m | \u001b[0m 0.3771  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.3656  \u001b[0m | \u001b[0m 0.399   \u001b[0m | \u001b[0m 11.8    \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 20.04   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.1017  \u001b[0m | \u001b[95m 0.9591  \u001b[0m | \u001b[95m 0.1986  \u001b[0m | \u001b[95m 0.1924  \u001b[0m | \u001b[95m 0.08383 \u001b[0m | \u001b[95m 9.679   \u001b[0m | \u001b[95m 471.5   \u001b[0m | \u001b[95m 26.8    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1038  \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.2281  \u001b[0m | \u001b[0m 0.4638  \u001b[0m | \u001b[0m 0.01206 \u001b[0m | \u001b[0m 12.72   \u001b[0m | \u001b[0m 468.8   \u001b[0m | \u001b[0m 26.12   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1034  \u001b[0m | \u001b[0m 0.6713  \u001b[0m | \u001b[0m 0.4853  \u001b[0m | \u001b[0m 0.7558  \u001b[0m | \u001b[0m 0.1096  \u001b[0m | \u001b[0m 16.73   \u001b[0m | \u001b[0m 471.9   \u001b[0m | \u001b[0m 27.24   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1038  \u001b[0m | \u001b[0m 0.3714  \u001b[0m | \u001b[0m 0.6943  \u001b[0m | \u001b[0m 0.03396 \u001b[0m | \u001b[0m 0.08815 \u001b[0m | \u001b[0m 5.266   \u001b[0m | \u001b[0m 470.4   \u001b[0m | \u001b[0m 29.83   \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-0.1016  \u001b[0m | \u001b[95m 0.7327  \u001b[0m | \u001b[95m 0.3213  \u001b[0m | \u001b[95m 0.451   \u001b[0m | \u001b[95m 0.07224 \u001b[0m | \u001b[95m 10.52   \u001b[0m | \u001b[95m 477.8   \u001b[0m | \u001b[95m 28.91   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1056  \u001b[0m | \u001b[0m 0.5513  \u001b[0m | \u001b[0m 0.1443  \u001b[0m | \u001b[0m 0.03297 \u001b[0m | \u001b[0m 0.1204  \u001b[0m | \u001b[0m 14.76   \u001b[0m | \u001b[0m 473.2   \u001b[0m | \u001b[0m 33.4    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1072  \u001b[0m | \u001b[0m 0.5561  \u001b[0m | \u001b[0m 0.2134  \u001b[0m | \u001b[0m 0.5187  \u001b[0m | \u001b[0m 0.02851 \u001b[0m | \u001b[0m 3.242   \u001b[0m | \u001b[0m 476.4   \u001b[0m | \u001b[0m 36.88   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1209  \u001b[0m | \u001b[0m 0.4771  \u001b[0m | \u001b[0m 0.7687  \u001b[0m | \u001b[0m 0.7201  \u001b[0m | \u001b[0m 0.005915\u001b[0m | \u001b[0m 9.767   \u001b[0m | \u001b[0m 483.3   \u001b[0m | \u001b[0m 32.84   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1091  \u001b[0m | \u001b[0m 0.154   \u001b[0m | \u001b[0m 0.7117  \u001b[0m | \u001b[0m 0.2027  \u001b[0m | \u001b[0m 0.06436 \u001b[0m | \u001b[0m 8.336   \u001b[0m | \u001b[0m 470.2   \u001b[0m | \u001b[0m 35.98   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1031  \u001b[0m | \u001b[0m 0.6389  \u001b[0m | \u001b[0m 0.04805 \u001b[0m | \u001b[0m 0.8311  \u001b[0m | \u001b[0m 0.02567 \u001b[0m | \u001b[0m 18.6    \u001b[0m | \u001b[0m 477.8   \u001b[0m | \u001b[0m 28.88   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1087  \u001b[0m | \u001b[0m 0.3299  \u001b[0m | \u001b[0m 0.4504  \u001b[0m | \u001b[0m 0.3306  \u001b[0m | \u001b[0m 0.2092  \u001b[0m | \u001b[0m 24.4    \u001b[0m | \u001b[0m 475.7   \u001b[0m | \u001b[0m 21.68   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1108  \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 0.6214  \u001b[0m | \u001b[0m 0.988   \u001b[0m | \u001b[0m 0.2937  \u001b[0m | \u001b[0m 22.06   \u001b[0m | \u001b[0m 465.9   \u001b[0m | \u001b[0m 24.44   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.7432  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 13.72   \u001b[0m | \u001b[0m 475.6   \u001b[0m | \u001b[0m 27.29   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1046  \u001b[0m | \u001b[0m 0.3193  \u001b[0m | \u001b[0m 0.8502  \u001b[0m | \u001b[0m 0.5868  \u001b[0m | \u001b[0m 0.09619 \u001b[0m | \u001b[0m 9.96    \u001b[0m | \u001b[0m 474.8   \u001b[0m | \u001b[0m 21.16   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1119  \u001b[0m | \u001b[0m 0.5702  \u001b[0m | \u001b[0m 0.9034  \u001b[0m | \u001b[0m 0.2301  \u001b[0m | \u001b[0m 0.347   \u001b[0m | \u001b[0m 4.905   \u001b[0m | \u001b[0m 468.4   \u001b[0m | \u001b[0m 27.7    \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1263  \u001b[0m | \u001b[0m 0.346   \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.4711  \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 471.1   \u001b[0m | \u001b[0m 28.04   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1196  \u001b[0m | \u001b[0m 0.5472  \u001b[0m | \u001b[0m 0.9107  \u001b[0m | \u001b[0m 0.8717  \u001b[0m | \u001b[0m 0.3795  \u001b[0m | \u001b[0m 9.884   \u001b[0m | \u001b[0m 480.9   \u001b[0m | \u001b[0m 30.19   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1137  \u001b[0m | \u001b[0m 0.6416  \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 0.3494  \u001b[0m | \u001b[0m 0.3292  \u001b[0m | \u001b[0m 7.29    \u001b[0m | \u001b[0m 479.5   \u001b[0m | \u001b[0m 28.66   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.103   \u001b[0m | \u001b[0m 0.6514  \u001b[0m | \u001b[0m 0.428   \u001b[0m | \u001b[0m 0.7843  \u001b[0m | \u001b[0m 0.07997 \u001b[0m | \u001b[0m 9.17    \u001b[0m | \u001b[0m 469.3   \u001b[0m | \u001b[0m 24.92   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1212  \u001b[0m | \u001b[0m 0.6573  \u001b[0m | \u001b[0m 0.7202  \u001b[0m | \u001b[0m 0.7779  \u001b[0m | \u001b[0m 0.4688  \u001b[0m | \u001b[0m 11.22   \u001b[0m | \u001b[0m 469.0   \u001b[0m | \u001b[0m 22.42   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1056  \u001b[0m | \u001b[0m 0.2418  \u001b[0m | \u001b[0m 0.734   \u001b[0m | \u001b[0m 0.6067  \u001b[0m | \u001b[0m 0.1081  \u001b[0m | \u001b[0m 12.09   \u001b[0m | \u001b[0m 465.7   \u001b[0m | \u001b[0m 26.71   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes: 100%|█████████████████████| 2/2 [20:22<00:00, 611.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the clusters and run the optimizer for each cluster. Return a list of best model params\n",
    "with tqdm_joblib(tqdm(desc=\"DTW LGBM Models Bayes\", \n",
    "                      total=len(train_df_dtw_clust_ls))) as progress_bar:\n",
    "    dtw_clust_mods_bayes = Parallel(n_jobs=2)(delayed(optimize_lgbm_w_bayes)(train_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                 train_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0],  \n",
    "                                                                                 val_df_dtw_clust_ls[i].iloc[:,1:(lag_n+1)],\n",
    "                                                                                 val_df_dtw_clust_ls[i].iloc[:,0]) for i in range(len(train_df_dtw_clust_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "42d12e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the list of model params and convert to int where required\n",
    "for n in range(len(dtw_clust_mods_bayes)):\n",
    "    dtw_clust_mods_bayes[n][\"max_depth\"] = int(round(dtw_clust_mods_bayes[n][\"max_depth\"]))\n",
    "    dtw_clust_mods_bayes[n][\"n_estimators\"] = int(round(dtw_clust_mods_bayes[n][\"n_estimators\"]))\n",
    "    dtw_clust_mods_bayes[n][\"num_leaves\"] = int(round(dtw_clust_mods_bayes[n][\"num_leaves\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fc8b3867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes Final:  50%|████████        | 1/2 [00:37<00:37, 37.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1471  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.146   \u001b[0m | \u001b[95m 0.7999  \u001b[0m | \u001b[95m 0.4889  \u001b[0m | \u001b[95m 0.05053 \u001b[0m | \u001b[95m 0.2692  \u001b[0m | \u001b[95m 2.954   \u001b[0m | \u001b[95m 827.3   \u001b[0m | \u001b[95m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.163   \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1788  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1595  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1498  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1532  \u001b[0m | \u001b[0m 0.6992  \u001b[0m | \u001b[0m 0.5316  \u001b[0m | \u001b[0m 0.5757  \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 12.38   \u001b[0m | \u001b[0m 818.6   \u001b[0m | \u001b[0m 142.7   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1521  \u001b[0m | \u001b[0m 0.6896  \u001b[0m | \u001b[0m 0.294   \u001b[0m | \u001b[0m 0.4966  \u001b[0m | \u001b[0m 0.2649  \u001b[0m | \u001b[0m 18.57   \u001b[0m | \u001b[0m 482.9   \u001b[0m | \u001b[0m 30.68   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.1432  \u001b[0m | \u001b[95m 0.8418  \u001b[0m | \u001b[95m 0.9842  \u001b[0m | \u001b[95m 0.6839  \u001b[0m | \u001b[95m 0.1345  \u001b[0m | \u001b[95m 22.78   \u001b[0m | \u001b[95m 479.1   \u001b[0m | \u001b[95m 11.61   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.144   \u001b[0m | \u001b[0m 0.5074  \u001b[0m | \u001b[0m 0.199   \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.1149  \u001b[0m | \u001b[0m 11.03   \u001b[0m | \u001b[0m 487.9   \u001b[0m | \u001b[0m 10.83   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.9001  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 498.6   \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1479  \u001b[0m | \u001b[0m 0.5863  \u001b[0m | \u001b[0m 0.1335  \u001b[0m | \u001b[0m 0.915   \u001b[0m | \u001b[0m 0.2828  \u001b[0m | \u001b[0m 5.158   \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 12.72   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1492  \u001b[0m | \u001b[0m 0.1261  \u001b[0m | \u001b[0m 0.7298  \u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m 0.2367  \u001b[0m | \u001b[0m 2.177   \u001b[0m | \u001b[0m 485.0   \u001b[0m | \u001b[0m 32.12   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.154   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1442  \u001b[0m | \u001b[0m 0.286   \u001b[0m | \u001b[0m 0.1659  \u001b[0m | \u001b[0m 11.6    \u001b[0m | \u001b[0m 471.6   \u001b[0m | \u001b[0m 47.98   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1432  \u001b[0m | \u001b[0m 0.6858  \u001b[0m | \u001b[0m 0.5742  \u001b[0m | \u001b[0m 0.1694  \u001b[0m | \u001b[0m 0.08158 \u001b[0m | \u001b[0m 23.42   \u001b[0m | \u001b[0m 455.5   \u001b[0m | \u001b[0m 12.52   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.9006  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 457.8   \u001b[0m | \u001b[0m 35.21   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1787  \u001b[0m | \u001b[0m 0.3102  \u001b[0m | \u001b[0m 0.07752 \u001b[0m | \u001b[0m 0.9577  \u001b[0m | \u001b[0m 0.4793  \u001b[0m | \u001b[0m 9.427   \u001b[0m | \u001b[0m 492.1   \u001b[0m | \u001b[0m 49.06   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1487  \u001b[0m | \u001b[0m 0.1881  \u001b[0m | \u001b[0m 0.3715  \u001b[0m | \u001b[0m 0.7474  \u001b[0m | \u001b[0m 0.4946  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 476.7   \u001b[0m | \u001b[0m 62.26   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1655  \u001b[0m | \u001b[0m 0.3978  \u001b[0m | \u001b[0m 0.2229  \u001b[0m | \u001b[0m 0.3288  \u001b[0m | \u001b[0m 0.3232  \u001b[0m | \u001b[0m 20.08   \u001b[0m | \u001b[0m 484.3   \u001b[0m | \u001b[0m 70.32   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1551  \u001b[0m | \u001b[0m 0.6286  \u001b[0m | \u001b[0m 0.4397  \u001b[0m | \u001b[0m 0.5292  \u001b[0m | \u001b[0m 0.4438  \u001b[0m | \u001b[0m 3.606   \u001b[0m | \u001b[0m 497.4   \u001b[0m | \u001b[0m 73.17   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1557  \u001b[0m | \u001b[0m 0.8921  \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 0.103   \u001b[0m | \u001b[0m 0.2658  \u001b[0m | \u001b[0m 7.005   \u001b[0m | \u001b[0m 482.9   \u001b[0m | \u001b[0m 87.19   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1682  \u001b[0m | \u001b[0m 0.8288  \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.3568  \u001b[0m | \u001b[0m 11.33   \u001b[0m | \u001b[0m 465.1   \u001b[0m | \u001b[0m 76.27   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.159   \u001b[0m | \u001b[0m 0.5019  \u001b[0m | \u001b[0m 0.8098  \u001b[0m | \u001b[0m 0.3777  \u001b[0m | \u001b[0m 0.2384  \u001b[0m | \u001b[0m 16.35   \u001b[0m | \u001b[0m 504.8   \u001b[0m | \u001b[0m 93.26   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.2214  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 485.9   \u001b[0m | \u001b[0m 92.97   \u001b[0m |\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m-0.1414  \u001b[0m | \u001b[95m 0.5048  \u001b[0m | \u001b[95m 0.2038  \u001b[0m | \u001b[95m 0.4583  \u001b[0m | \u001b[95m 0.05108 \u001b[0m | \u001b[95m 9.595   \u001b[0m | \u001b[95m 516.6   \u001b[0m | \u001b[95m 77.73   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1714  \u001b[0m | \u001b[0m 0.6189  \u001b[0m | \u001b[0m 0.008488\u001b[0m | \u001b[0m 0.5034  \u001b[0m | \u001b[0m 0.3726  \u001b[0m | \u001b[0m 21.28   \u001b[0m | \u001b[0m 506.1   \u001b[0m | \u001b[0m 66.14   \u001b[0m |\n",
      "| \u001b[95m 27      \u001b[0m | \u001b[95m-0.1401  \u001b[0m | \u001b[95m 0.8347  \u001b[0m | \u001b[95m 0.6349  \u001b[0m | \u001b[95m 0.8289  \u001b[0m | \u001b[95m 0.03747 \u001b[0m | \u001b[95m 24.83   \u001b[0m | \u001b[95m 522.1   \u001b[0m | \u001b[95m 85.04   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1408  \u001b[0m | \u001b[0m 0.9949  \u001b[0m | \u001b[0m 0.4589  \u001b[0m | \u001b[0m 0.8708  \u001b[0m | \u001b[0m 0.06433 \u001b[0m | \u001b[0m 8.597   \u001b[0m | \u001b[0m 524.8   \u001b[0m | \u001b[0m 96.07   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1765  \u001b[0m | \u001b[0m 0.2178  \u001b[0m | \u001b[0m 0.8709  \u001b[0m | \u001b[0m 0.08685 \u001b[0m | \u001b[0m 0.3714  \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 536.1   \u001b[0m | \u001b[0m 78.97   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1935  \u001b[0m | \u001b[0m 0.755   \u001b[0m | \u001b[0m 0.03285 \u001b[0m | \u001b[0m 0.8255  \u001b[0m | \u001b[0m 0.4615  \u001b[0m | \u001b[0m 23.85   \u001b[0m | \u001b[0m 538.0   \u001b[0m | \u001b[0m 99.88   \u001b[0m |\n",
      "=============================================================================================================\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3212994785101474, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3212994785101474\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.45103270481577384, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.45103270481577384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes Final: 100%|████████████████| 2/2 [01:20<00:00, 40.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the clusters, and using the params found by the optimizer, train a final model for each cluster.\n",
    "# Save to a list of models\n",
    "with tqdm_joblib(tqdm(desc=\"DTW LGBM Models Bayes Final\", \n",
    "                      total=len(dtw_clust_mods_bayes))) as progress_bar:\n",
    "    dtw_clust_mods_bayes_final = Parallel(n_jobs=2)(delayed(train_lgbm)(dtw_clust_mods_bayes[i], \n",
    "                                                                            train_val_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                            train_val_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]\n",
    "                                                                        ) for i in range(len(dtw_clust_mods_bayes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5e219c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the models to files\n",
    "for model_no in range(len(dtw_clust_mods_bayes_final)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/DTW/model_{model_no}\"\n",
    "    joblib.dump(dtw_clust_mods_bayes_final[model_no], fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7c592be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_clust_mods_bayes_final = list()\n",
    "\n",
    "for model_no in range(len(train_val_df_dtw_clust_ls)):\n",
    "    fname = f\"Results/Global/LightGBM Bayes/DTW/model_{model_no}\"\n",
    "    dtw_clust_mods_bayes_final.append(joblib.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7afefb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "DTW LGBM Models Bayes Residuals:   0%|                    | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.6349494738732795, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6349494738732795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8289230437300075, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8289230437300075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes Residuals: 100%|████████████| 2/2 [00:14<00:00,  7.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each model and train_val data used to train the model, compute the residuals. Save the residual list for\n",
    "# each model as an entry in a list\n",
    "with tqdm_joblib(tqdm(desc=\"DTW LGBM Models Bayes Residuals\", \n",
    "                      total=len(dtw_clust_mods_bayes_final))) as progress_bar:\n",
    "    dtw_clust_mods_bayes_resid = Parallel(n_jobs=3)(delayed(compute_lgbm_residuals)(dtw_clust_mods_bayes_final[i],\n",
    "                                                                                     train_val_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,1:],\n",
    "                                                                                     train_val_df_dtw_clust_ls[i].iloc[:,0:(lag_n+1)].dropna().iloc[:,0]) for i in range(len(dtw_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "dde0a9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[8.044222078269485, 12.507955502283068, -28.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.254609650429302, 27.416773801694262, -23.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                           residual\n",
       "0        1  [8.044222078269485, 12.507955502283068, -28.70...\n",
       "1        2  [-2.254609650429302, 27.416773801694262, -23.1..."
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_clust_res_df = pd.DataFrame({'cluster': list({(i+1): dtw_clust_mods_bayes_resid[i] for i in range(len(dtw_clust_mods_bayes_resid))}.keys()),\n",
    "                                 'residual': list({(i+1): dtw_clust_mods_bayes_resid[i] for i in range(len(dtw_clust_mods_bayes_resid))}.values())})\n",
    "\n",
    "dtw_clust_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8913b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_clust_res_df.to_csv(\"Results/Global/LightGBM Bayes/DTW/residual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4104eb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DTW LGBM Models Bayes Test Preds: 100%|███████████| 2/2 [00:05<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each model, compute the predictions on the test data\n",
    "with tqdm_joblib(tqdm(desc=\"DTW LGBM Models Bayes Test Preds\", \n",
    "                      total=len(dtw_clust_mods_bayes_final))) as progress_bar:\n",
    "    dtw_clust_mods_bayes_test_preds = Parallel(n_jobs=2)(delayed(compute_lgbm_test_preds)(dtw_clust_mods_bayes_final[i],\n",
    "                                                                                           test_df_full_dtw_clust_ls[i],\n",
    "                                                                                           lag_n\n",
    "                                                                                          ) for i in range(len(dtw_clust_mods_bayes_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a201f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one data frame of test preds from the list created above\n",
    "dtw_clust_bayes_test_preds_df = pd.concat(dtw_clust_mods_bayes_test_preds)\n",
    "# for clust_test_pred_df in dtw_clust_mods_bayes_test_preds:\n",
    "#     dtw_clust_bayes_test_preds_df = dtw_clust_bayes_test_preds_df.append(clust_test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9f369f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test pred performance\n",
    "dtw_clust_bayes_test_perf = compute_lgbm_test_perf(dtw_clust_bayes_test_preds_df,\n",
    "                                                       test_df_full_dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "017448c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized performance metrics as well\n",
    "dtw_clust_bayes_test_perf['nrmse'] = dtw_clust_bayes_test_perf['rmse']/dtw_clust_bayes_test_perf['mean']\n",
    "dtw_clust_bayes_test_perf['smae'] = dtw_clust_bayes_test_perf['mae']/dtw_clust_bayes_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "264dcd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse      30.315943\n",
       "mae       20.017162\n",
       "mean     265.435072\n",
       "nrmse      0.136072\n",
       "smae       0.091482\n",
       "dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print means of perf metrics\n",
    "dtw_clust_bayes_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2b067c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9232cf807da743efb2428fb2d87e98d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/33600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6b05c5f2f44936be95069bb9637606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/68544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each model/cluster, compute bootstrap PIs for each prediction from the test set. Save the data frames of PI's\n",
    "# to a lift\n",
    "dtw_clust_test_pred_int = list()\n",
    "for i in range(len(dtw_clust_mods_bayes_test_preds)):\n",
    "    dtw_clust_test_pred_int.append(compute_lgbm_boostrap_int(dtw_clust_mods_bayes_test_preds[i], \n",
    "                                                                 dtw_clust_mods_bayes_resid[i], \n",
    "                                                                 n_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "189b2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster's PI DF, add a column with the true value for each observation\n",
    "for n in range(1, len(dtw_clust_test_pred_int)+1):\n",
    "    y_actual_sub = test_df_full_dtw.query(\"cluster==@n\").copy().iloc[:,0].to_list()\n",
    "    dtw_clust_test_pred_int[n-1]['actual'] = y_actual_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5985331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all PI data frames into one data frame\n",
    "dtw_clust_test_pred_int_df = pd.concat(dtw_clust_test_pred_int)\n",
    "# for clust_test_pred_int_df in dtw_clust_test_pred_int:\n",
    "#     dtw_clust_test_pred_int_df = dtw_clust_test_pred_int_df.append(clust_test_pred_int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d8799ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the interval score for each observation's 95% and 80% PI\n",
    "dtw_clust_test_pred_int_df['int_95_score'] = interval_score(dtw_clust_test_pred_int_df['actual'],\n",
    "                                                                dtw_clust_test_pred_int_df['lo_95'],\n",
    "                                                                dtw_clust_test_pred_int_df['hi_95'],\n",
    "                                                                0.95\n",
    "                                                               )\n",
    "\n",
    "dtw_clust_test_pred_int_df['int_80_score'] = interval_score(dtw_clust_test_pred_int_df['actual'],\n",
    "                                                                dtw_clust_test_pred_int_df['lo_80'],\n",
    "                                                                dtw_clust_test_pred_int_df['hi_80'],\n",
    "                                                                0.80\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "79201c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index         38.500000\n",
       "test_preds      265.597540\n",
       "lo_95           215.006362\n",
       "hi_95           317.885495\n",
       "lo_80           238.362433\n",
       "hi_80           293.575718\n",
       "actual          265.435072\n",
       "int_95_score    202.360985\n",
       "int_80_score    114.056671\n",
       "dtype: float64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean interval scores\n",
    "dtw_clust_test_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c00ae9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_clust_test_pred_int_df_grouped = dtw_clust_test_pred_int_df.groupby(\"ts_index\")\\\n",
    ".agg({\"int_95_score\":\"mean\", \"int_80_score\":\"mean\", \"actual\":\"mean\"}).reset_index()\n",
    "\n",
    "dtw_clust_test_pred_int_df_grouped['int_95_score_scaled'] = dtw_clust_test_pred_int_df_grouped['int_95_score']/dtw_clust_test_pred_int_df_grouped['actual']\n",
    "dtw_clust_test_pred_int_df_grouped['int_80_score_scaled'] = dtw_clust_test_pred_int_df_grouped['int_80_score']/dtw_clust_test_pred_int_df_grouped['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a15bbf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_80_score_scaled    0.536127\n",
       "int_95_score_scaled    0.923342\n",
       "dtype: float64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_clust_test_pred_int_df_grouped[['int_80_score_scaled', 'int_95_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c503a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PI df to a csv file\n",
    "dtw_clust_test_pred_int_df.to_csv(\"Results/Global/LightGBM Bayes/DTW/test_pred_intervals.csv\",\n",
    "                                     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d772e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
