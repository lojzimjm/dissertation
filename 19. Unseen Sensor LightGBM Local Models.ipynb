{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the libraries are not yet installed, they can be installed in this notebook using commands similar to the below\n",
    "# %conda install numpy\n",
    "# %conda install pandas\n",
    "# %conda install matplotlib\n",
    "# %conda install scikit-learn\n",
    "# %conda install -c conda-forge lightgbm \n",
    "# %conda install -c conda-forge swifter\n",
    "# %conda install -c conda-forge bayesian-optimization \n",
    "# %conda install -c conda-forge scipy\n",
    "# %conda install joblib\n",
    "# %conda install tdqm\n",
    "\n",
    "# Something like the following may also work if the above does not\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} numpy\n",
    "# !conda install --yes --prefix {sys.prefix} pandas\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} lightgbm\n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} swifter\n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} bayesian-optimization \n",
    "# !conda install -c conda-forge --yes --prefix {sys.prefix} scipy \n",
    "# !conda install --yes --prefix {sys.prefix} joblib\n",
    "# !conda install --yes --prefix {sys.prefix} tdqm\n",
    "\n",
    "# To install a specific version, add the version to the install command\n",
    "# E.g., %conda install numpy=1.20.3\n",
    "\n",
    "# If all else fails, use pip or follow additional advice such as found at\n",
    "# https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "\n",
    "# If your plan to use pip (especially if you are not working within a specified conda environment), \n",
    "# the pip commands might look like:\n",
    "# pip install numpy\n",
    "# pip install pandas\n",
    "# pip install scikit-learn\n",
    "# pip install lightgbm\n",
    "# pip install swifter\n",
    "# pip install bayesian-optimization \n",
    "# pip install scipy\n",
    "# pip install joblib\n",
    "# pip install tdqm\n",
    "\n",
    "# To install a specific version, add the version to the pip install command\n",
    "# E.g., pip install numpy==1.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import glob\n",
    "from lightgbm import LGBMRegressor\n",
    "import random\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import scipy\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "import contextlib\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from bayes_opt import BayesianOptimization\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data and Prepare for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Unseen Sensor/Processed/A19-9336-1_Northbound_2019_Processed.csv\n",
      "Reading Data/Unseen Sensor/Processed/A66-9521-1_Westbound_Processed.csv\n",
      "Reading Data/Unseen Sensor/Processed/M40-7048-2_Southbound_Processed.csv\n",
      "Reading Data/Unseen Sensor/Processed/M62-2056A_Eastbound_Processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to hold the dataframes of highways england data\n",
    "total_df_list = list()\n",
    "\n",
    "# Loop through the files, sorted in alphabetical order\n",
    "# Read them into a df, make sure they are sorted by timestamp, and append to the list\n",
    "for fname in sorted(glob.glob(\"Data/Unseen Sensor/Processed/*.csv\")):\n",
    "    print(\"Reading {}\".format(fname))\n",
    "    df = pd.read_csv(fname) #, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "    df = df.sort_values(by=\"timestamp\")\n",
    "    total_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the start and end points csv, and subtract 1 to deal with index differences between R and python\n",
    "start_end = pd.read_csv(\"start_end_points_unseen.csv\")\n",
    "start_end[\"start\"] = start_end[\"start\"] - 1\n",
    "start_end[\"end\"] = start_end[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to hold the subset data frames (those with only 12 weeks of data per highway)\n",
    "subset_df_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each df in our original total df list\n",
    "for idx, df in enumerate(total_df_list):\n",
    "        \n",
    "    # Filter the timeframe based on the start_end_points csv files\n",
    "    subset_df = df.iloc[start_end.iloc[idx,0]:start_end.iloc[idx,1], ]\\\n",
    "    .reset_index(drop=True).reset_index(drop=False)\\\n",
    "    .rename(columns={\"index\":\"rn\"})\n",
    "    \n",
    "    # Create a new field called train_val_test to differentiate each set of data\n",
    "    subset_df[\"train_val_test\"] = np.where(subset_df[\"rn\"]<(96*7*8),\n",
    "                                           \"train\",\n",
    "                                           np.where(subset_df[\"rn\"]<(96*7*10),\n",
    "                                                    \"val\",\n",
    "                                                    \"test\"\n",
    "                                                   )\n",
    "                                       )\n",
    "    \n",
    "    # Append to list\n",
    "    subset_df_list.append(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of df's with only fields we need\n",
    "\n",
    "# Initialize empty list\n",
    "model_df_list = list()\n",
    "\n",
    "# For df in subset list\n",
    "for df in subset_df_list:\n",
    "       \n",
    "    # Extract the timestamp, the volume, and the train_val_test assignment\n",
    "    model_df = df[['timestamp', 'total_volume', \"train_val_test\"]]\\\n",
    "    .rename(columns={'timestamp':'start', 'total_volume':'target'})\n",
    "    \n",
    "    # Append this df to the new list\n",
    "    model_df_list.append(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Lag Emebedded Matrices for each TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our final lag value to be 840\n",
    "lag_n = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14101/3230010149.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = df['target'].shift(n)\n"
     ]
    }
   ],
   "source": [
    "# # Lag embed the data frames and save to a list\n",
    "lag_embed_df_list = list()\n",
    "\n",
    "for df in model_df_list:\n",
    "    # For each df in our list\n",
    "    for n in range(1, (lag_n+1)):\n",
    "        # For each lag level, up to 840\n",
    "        # Create a new column called target-n\n",
    "        name = f\"target-{n}\"\n",
    "        # Save the target shifted n values into this colume\n",
    "        df[name] = df['target'].shift(n)\n",
    "    # Append to list\n",
    "    lag_embed_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the lag embedded list into train, val, and test lists\n",
    "\n",
    "# First, initialize empty lists for each train, val, and test\n",
    "train_df_list = list()\n",
    "val_df_list = list()\n",
    "test_df_list = list()\n",
    "\n",
    "for i in range(len(lag_embed_df_list)):\n",
    "    # For each df in our list\n",
    "    df = lag_embed_df_list[i].copy()\n",
    "\n",
    "    # Add a ts_index of i+1 to join with clustering data from R\n",
    "    df['ts_index'] = i + 1\n",
    "    \n",
    "    # Subset into train, val, and test df's based on the train_val_test_field\n",
    "    train_df = df.query(\"train_val_test == 'train'\").copy()\n",
    "    val_df = df.query(\"train_val_test=='val'\").copy()\n",
    "    test_df = df.query(\"train_val_test=='test'\").copy()\n",
    "    \n",
    "    # Append to appropriate lists\n",
    "    train_df_list.append(train_df)\n",
    "    val_df_list.append(val_df)\n",
    "    test_df_list.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all dfs from the lists together to create one full train, val, and test df\n",
    "train_df_full = pd.concat(train_df_list)\n",
    "val_df_full = pd.concat(val_df_list)\n",
    "test_df_full = pd.concat(test_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "train_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "val_df_full.drop(columns=['start', 'train_val_test'], inplace=True)\n",
    "test_df_full.drop(columns=['start', 'train_val_test'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the training and validation data together for later use\n",
    "train_val_df_full = train_df_full.append(val_df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Each Time Series Using Default LightGBM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train a light gbm model\n",
    "def train_local_lgbm(m, data, n):\n",
    "    \"\"\"Function which takes a time series index m, a training data frame, and a lag value n and trains a model\"\"\"\n",
    "    \n",
    "    # Create y and X data frames from the trianing data for ts_index m and lag embedding n \n",
    "    y_train_sub = data.query(\"ts_index==@m\").iloc[n:,0]\n",
    "    X_train_sub = data.query(\"ts_index==@m\").iloc[n:,0:(n+1)].iloc[:,1:]\n",
    "    \n",
    "    # Create the model object and fit it\n",
    "    mod_sub = LGBMRegressor(boosting_type='goss', random_state=54321)\n",
    "    mod_sub.fit(X_train_sub, y_train_sub)\n",
    "    \n",
    "    # Return the fitted model\n",
    "    return mod_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for progress bar:\n",
    "# https://stackoverflow.com/questions/24983493/tracking-progress-of-joblib-parallel-execution\n",
    "# This allows us to print a progress bar while running parallel loops using joblib \n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Models - Default Params: 100%|██████████████| 4/4 [00:06<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the list of time series in parallel and train a LGBM model for each, saving models to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Local Models - Default Params\", total=4)) as progress_bar:\n",
    "    results = Parallel(n_jobs=4)(delayed(train_local_lgbm)(i, train_val_df_full, lag_n) for i in range(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predicitons on the test data\n",
    "def predict_test_lgbm(model, m, data, n):\n",
    "    \"\"\"Function which takes in a trained model, time series index, test data frame, and lag embedding\n",
    "    and returns a dictionary of model test prediction performance\"\"\"\n",
    "    \n",
    "    # Create y and X data frames for the given ts index and lag embedding\n",
    "    y_test_sub = data.query(\"ts_index==@m\").iloc[:,0]\n",
    "    X_test_sub = data.query(\"ts_index==@m\").iloc[:,1:(n+1)]\n",
    "    \n",
    "    # Predict on the test data\n",
    "    test_preds_sub = model.predict(X_test_sub)\n",
    "    \n",
    "    # Compute the mean of the true test data as well as the mae and rmse of the predictions\n",
    "    test_mean = np.mean(y_test_sub)\n",
    "    test_mae = mean_absolute_error(y_test_sub, test_preds_sub)\n",
    "    test_rmse = mean_squared_error(y_test_sub, test_preds_sub, squared=False)\n",
    "    \n",
    "    # Save the mean, mae, and rmse into a dictionary\n",
    "    pred_perf = {\"mean\": test_mean, \"mae\": test_mae, \"rmse\": test_rmse}\n",
    "    \n",
    "    # Return the dictionary\n",
    "    return pred_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Models - Test Preds: 100%|██████████████████| 4/4 [00:00<00:00,  8.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop through all time series and save the prediction performance dictionaries for each to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Local Models - Test Preds\", total=4)) as progress_bar:\n",
    "    test_results = Parallel(n_jobs=4)(delayed(predict_test_lgbm)(results[i], i+1, test_df_full, lag_n) for i in range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame from that list of dictionaries\n",
    "local_model_test_perf = pd.DataFrame(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled metrics to that data frame\n",
    "local_model_test_perf['nrmse'] = local_model_test_perf['rmse']/local_model_test_perf['mean']\n",
    "local_model_test_perf['smae'] = local_model_test_perf['mae']/local_model_test_perf['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean     377.058594\n",
       "mae       25.965267\n",
       "rmse      38.541254\n",
       "nrmse      0.123419\n",
       "smae       0.083644\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of the prediction performance metrics\n",
    "local_model_test_perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store residuals in\n",
    "base_mod_resiudal_dict = dict()\n",
    "\n",
    "# Loop through each time series index\n",
    "for i in range(1, 5):\n",
    "    # Extract the y and X train for each index\n",
    "    y_train_sub = train_val_df_full.query(\"ts_index==@i\").iloc[:,0:(lag_n+1)].dropna().iloc[:,0].copy()\n",
    "    X_train_sub = train_val_df_full.query(\"ts_index==@i\").iloc[:,0:(lag_n+1)].dropna().iloc[:,1:].copy()\n",
    "    \n",
    "    # Make predictions on the training data\n",
    "    train_preds_sub = results[i-1].predict(X_train_sub)\n",
    "    \n",
    "    # Compute residuals and convery to list\n",
    "    res_sub = (y_train_sub - train_preds_sub).to_list()\n",
    "    \n",
    "    # Save that list into the dictionary, with key equal to the ts index\n",
    "    base_mod_resiudal_dict[i] = res_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an emptry dictionary for test preds\n",
    "base_mod_test_preds = dict()\n",
    "\n",
    "# For each ts index\n",
    "for i in range(1,5):\n",
    "    # Create the X data frame from the test data for that ts\n",
    "    X_test_sub = test_df_full.query(\"ts_index==@i\").iloc[:,1:(lag_n+1)]\n",
    "    \n",
    "    # Predict on the test data\n",
    "    test_pred_sub = results[i-1].predict(X_test_sub)\n",
    "    \n",
    "    # Save those preds to the dictionary\n",
    "    base_mod_test_preds[i] = test_pred_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Set n_boot to 1000\n",
    "n_boot = 1000\n",
    "\n",
    "# Create an empty df to store pred intervals\n",
    "pred_int_df = pd.DataFrame()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)\n",
    "\n",
    "# Loop through all ts indexes\n",
    "for i in range(1,5):\n",
    "\n",
    "    # Print i to monitor progress\n",
    "    print(i)\n",
    "    \n",
    "    # Get the true/target value of y for the test data for that ts\n",
    "    y_test_sub = test_df_full.query(\"ts_index==@i\").iloc[:,0]\n",
    "    \n",
    "    # Create empty lists to store PIs in\n",
    "    percent_95_lo_ls = list()\n",
    "    percent_95_hi_ls = list()\n",
    "    percent_80_lo_ls = list()\n",
    "    percent_80_hi_ls = list()\n",
    "    \n",
    "    # Loop through the number of observations in the test set\n",
    "    for j in range(1344):\n",
    "        \n",
    "        # Grab the test pred for the given ts index and observation number\n",
    "        pred = base_mod_test_preds[i][j]\n",
    "        # Sample n_boot times from the appropriate model's residuals\n",
    "        resid_boot = np.random.choice(base_mod_resiudal_dict[i], size=n_boot, replace=True)\n",
    "        # Add the test pred to the residuals\n",
    "        resid_preds = pred+resid_boot\n",
    "        \n",
    "        # Compute the percentiles of resid_preds for the 95% PI\n",
    "        percent_95_lo = np.percentile(resid_preds, 2.5)\n",
    "        percent_95_hi = np.percentile(resid_preds, 97.5)\n",
    "        percent_95_lo_ls.append(percent_95_lo)\n",
    "        percent_95_hi_ls.append(percent_95_hi)\n",
    "        \n",
    "        # Compute the percentiles of resid_preds for the 80% PI\n",
    "        percent_80_lo = np.percentile(resid_preds, 10)\n",
    "        percent_80_hi = np.percentile(resid_preds, 90)\n",
    "        percent_80_lo_ls.append(percent_80_lo)\n",
    "        percent_80_hi_ls.append(percent_80_hi)\n",
    "    \n",
    "    # Create a temp data frame with the ts_index, true values, and PIs\n",
    "    pred_int_df_sub = pd.DataFrame({\"ts_index\": i,\n",
    "                                    \"actual\": y_test_sub,\n",
    "                                    \"pct_95_lo\": percent_95_lo_ls,\n",
    "                                    \"pct_95_hi\": percent_95_hi_ls,                                   \n",
    "                                    \"pct_80_lo\": percent_80_lo_ls,\n",
    "                                    \"pct_80_hi\": percent_80_hi_ls\n",
    "                                   })\n",
    "    \n",
    "    # Append to the full data frame\n",
    "    pred_int_df = pred_int_df.append(pred_int_df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_index</th>\n",
       "      <th>actual</th>\n",
       "      <th>pct_95_lo</th>\n",
       "      <th>pct_95_hi</th>\n",
       "      <th>pct_80_lo</th>\n",
       "      <th>pct_80_hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6720</th>\n",
       "      <td>1</td>\n",
       "      <td>221.0</td>\n",
       "      <td>233.558565</td>\n",
       "      <td>276.405711</td>\n",
       "      <td>240.604273</td>\n",
       "      <td>268.331318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>1</td>\n",
       "      <td>323.0</td>\n",
       "      <td>223.017549</td>\n",
       "      <td>265.066333</td>\n",
       "      <td>230.213948</td>\n",
       "      <td>259.488536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722</th>\n",
       "      <td>1</td>\n",
       "      <td>298.0</td>\n",
       "      <td>279.402182</td>\n",
       "      <td>321.410465</td>\n",
       "      <td>287.489184</td>\n",
       "      <td>315.676443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>1</td>\n",
       "      <td>305.0</td>\n",
       "      <td>256.025554</td>\n",
       "      <td>298.615415</td>\n",
       "      <td>264.264211</td>\n",
       "      <td>291.793449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1</td>\n",
       "      <td>238.0</td>\n",
       "      <td>267.300907</td>\n",
       "      <td>309.638195</td>\n",
       "      <td>274.520606</td>\n",
       "      <td>303.200311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ts_index  actual   pct_95_lo   pct_95_hi   pct_80_lo   pct_80_hi\n",
       "6720         1   221.0  233.558565  276.405711  240.604273  268.331318\n",
       "6721         1   323.0  223.017549  265.066333  230.213948  259.488536\n",
       "6722         1   298.0  279.402182  321.410465  287.489184  315.676443\n",
       "6723         1   305.0  256.025554  298.615415  264.264211  291.793449\n",
       "6724         1   238.0  267.300907  309.638195  274.520606  303.200311"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print head to sanity check\n",
    "pred_int_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to compute the interval score\n",
    "def interval_score(true_values, lower, upper, interval_range):\n",
    "    \"\"\" Function which takes in the true values, the upper and lower bounds of PIs, and the PI level (e.g., 90%)\n",
    "        and from these inputs, computes the interval score for each prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute alpha from the interval range\n",
    "    alpha = 1-interval_range\n",
    "    \n",
    "    # Save the upper, lower, and true_values as numpy arrays for computation purposes\n",
    "    upper = np.array(upper)\n",
    "    lower = np.array(lower)\n",
    "    true_values = np.array(true_values)\n",
    "    \n",
    "    # Compute the lower component of the interval score - just a boolean for true below interval\n",
    "    def lower_ind(true,low):\n",
    "        if true<low:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the upper component of the interval score - similar boolean for true above interval\n",
    "    def upper_ind(true,up):\n",
    "        if true>up:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Computer the actual score for each obsveration - formula here: https://epiforecasts.io/scoringutils/reference/interval_score.html\n",
    "    scores = (upper-lower) + (2/alpha)*(lower-true_values)*(lower > true_values) + (2/alpha)*(true_values-upper)*(true_values > upper)\n",
    "    \n",
    "    # Return the scores array\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 80% and 95% PI scores using the above function\n",
    "pred_int_df['int_80_score'] = interval_score(pred_int_df['actual'], \n",
    "                                             pred_int_df['pct_80_lo'], \n",
    "                                             pred_int_df['pct_80_hi'],\n",
    "                                             0.8\n",
    "                                            )\n",
    "\n",
    "pred_int_df['int_95_score'] = interval_score(pred_int_df['actual'], \n",
    "                                             pred_int_df['pct_95_lo'], \n",
    "                                             pred_int_df['pct_95_hi'],\n",
    "                                             0.95\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "actual          377.058594\n",
       "pct_95_lo       343.454157\n",
       "pct_95_hi       414.783086\n",
       "pct_80_lo       356.117900\n",
       "pct_80_hi       402.027249\n",
       "int_80_score    158.110497\n",
       "int_95_score    357.412391\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean of the PI scores\n",
    "pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the PI results by time series index, compute the mean of the interval scores and true data\n",
    "pred_int_df_grouped = pred_int_df.groupby(\"ts_index\")\\\n",
    ".agg({\"int_95_score\":\"mean\", \"int_80_score\":\"mean\", \"actual\":\"mean\"}).reset_index()\n",
    "\n",
    "# Compute the scaled interval score\n",
    "pred_int_df_grouped['int_95_score_scaled'] = pred_int_df_grouped['int_95_score']/pred_int_df_grouped['actual']\n",
    "pred_int_df_grouped['int_80_score_scaled'] = pred_int_df_grouped['int_80_score']/pred_int_df_grouped['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_80_score_scaled    0.506256\n",
       "int_95_score_scaled    1.175555\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of the scaled interval scores\n",
    "pred_int_df_grouped[['int_80_score_scaled', 'int_95_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Models with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform Bayesian optimization\n",
    "def optimize_lgbm_w_bayes(i, lag_n, train_df, val_df):\n",
    "    \"\"\"Function which takes in a time series index i, a lag embedding lag_n, and a train and validation\n",
    "    data frame and which returns the best model params found using bayesian optimization\"\"\"\n",
    "\n",
    "    # Subset the input train data into X and y data frames for the provided index i\n",
    "    y_train_bayes = train_df.query(\"ts_index==@i\").iloc[:,0:(lag_n+1)].dropna().iloc[:,0].copy()\n",
    "    X_train_bayes = train_df.query(\"ts_index==@i\").iloc[:,0:(lag_n+1)].dropna().iloc[:,1:].copy()\n",
    "    \n",
    "    # Get the validation data for the provided ts_index i\n",
    "    val_df_bayes = val_df.query(\"ts_index==@i\").copy()\n",
    "   \n",
    "    # Set up space of lgbm params to explore\n",
    "    bayes_param_ss = {\n",
    "    \"n_estimators\": (100, 1000),\n",
    "    \"max_depth\": (2, 25),\n",
    "    \"lambda_l1\": (0, 1),\n",
    "    \"lambda_l2\": (0, 1),\n",
    "    \"num_leaves\": (10, 150),\n",
    "    \"colsample_bytree\": (0.1, 1),\n",
    "    \"learning_rate\": (0.00001, 0.5)\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Define a function to compute validation set predictions\n",
    "    def val_predict(model, val_df):\n",
    "        \"\"\"Function takes in a trained model and validation data and returns normalized rmse for preds on the \n",
    "        validation data\"\"\"\n",
    "        \n",
    "        # Subset the validation data frame into y and X data frames\n",
    "        y_val_sub = val_df.iloc[:,0]\n",
    "        X_val_sub = val_df.iloc[:,1:(lag_n+1)]\n",
    "        # Compute the mean of the true y values\n",
    "        val_mean_sub = np.mean(y_val_sub)\n",
    "\n",
    "        # Make model predictions\n",
    "        val_preds_sub = model.predict(X_val_sub)\n",
    "\n",
    "        # Compute rmse on the predictions, and then divide by the mean to get nrmse\n",
    "        val_rmse_sub = mean_squared_error(y_val_sub, val_preds_sub, squared=False)\n",
    "        val_nrmse_sub = val_rmse_sub/val_mean_sub\n",
    "\n",
    "        # Return normalized rmse\n",
    "        return val_nrmse_sub\n",
    "    \n",
    "    \n",
    "    # Define function to perform the bayesian optimization\n",
    "    def lgbm_eval_for_bayes(n_estimators,\n",
    "                        max_depth,\n",
    "                        lambda_l1, \n",
    "                        lambda_l2,\n",
    "                        num_leaves,\n",
    "                        colsample_bytree,\n",
    "                        learning_rate\n",
    "                       ):\n",
    "        \"\"\"Function which takes in parameter values as inputs and returns a value to be maximized by the\n",
    "        Bayesian optimizer. In this case, we return -1*validation_nrmse as this allows us to minimize the\n",
    "        validation nrmse\"\"\"\n",
    "        \n",
    "        # Set the proper boosting type\n",
    "        params = {\"boosting_type\": \"goss\"\n",
    "                 }\n",
    "        \n",
    "        # Set the params dictionary to include all input params\n",
    "        # For n_estimators, max_depth, and num_leaves, round and cast as int - this is what the lgbm model requires\n",
    "        params[\"n_estimators\"] = int(round(n_estimators))\n",
    "        params[\"max_depth\"] = int(round(max_depth))\n",
    "        params[\"reg_alpha\"] = max(lambda_l1, 0)\n",
    "        params[\"reg_lambda\"] = max(lambda_l2, 0)\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params[\"colsample_bytree\"] = colsample_bytree\n",
    "        params[\"learning_rate\"] = learning_rate\n",
    "\n",
    "        # Create the model object, setting a constant random_state for reproducibility, and fit the model\n",
    "        mod = LGBMRegressor(**params, random_state=54321)  \n",
    "        mod.fit(X_train_bayes, y_train_bayes)\n",
    "\n",
    "        # Compute the performance on the validation data and multiple by -1\n",
    "        val_perf = -1*np.mean(val_predict(mod, val_df_bayes))\n",
    "\n",
    "        # Return the negative validation nrmse\n",
    "        return val_perf\n",
    "\n",
    "    # Create an optimizer object, again setting random_state\n",
    "    optimizer = BayesianOptimization(lgbm_eval_for_bayes,\n",
    "                                     bayes_param_ss,\n",
    "                                     random_state=54321)\n",
    "    # Run the optimizer with 5 random initialization points and 25 further iterations\n",
    "    optimizer.maximize(init_points=5, n_iter=25)\n",
    "    \n",
    "    # Return the best params found by the optimizer\n",
    "    return optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Models - Bayesian Optim:  50%|██████▌      | 2/4 [05:17<04:42, 141.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1897  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2078  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2213  \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2431  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2064  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1996  \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 0.1594  \u001b[0m | \u001b[0m 0.3429  \u001b[0m | \u001b[0m 0.03426 \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 829.8   \u001b[0m | \u001b[0m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2057  \u001b[0m | \u001b[0m 0.7862  \u001b[0m | \u001b[0m 0.2396  \u001b[0m | \u001b[0m 0.6049  \u001b[0m | \u001b[0m 0.3277  \u001b[0m | \u001b[0m 7.432   \u001b[0m | \u001b[0m 473.9   \u001b[0m | \u001b[0m 22.69   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2582  \u001b[0m | \u001b[0m 0.1863  \u001b[0m | \u001b[0m 0.781   \u001b[0m | \u001b[0m 0.478   \u001b[0m | \u001b[0m 0.4564  \u001b[0m | \u001b[0m 23.04   \u001b[0m | \u001b[0m 470.6   \u001b[0m | \u001b[0m 24.27   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2287  \u001b[0m | \u001b[0m 0.3771  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.3656  \u001b[0m | \u001b[0m 0.399   \u001b[0m | \u001b[0m 11.8    \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 20.04   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2174  \u001b[0m | \u001b[0m 0.8576  \u001b[0m | \u001b[0m 0.8254  \u001b[0m | \u001b[0m 0.2658  \u001b[0m | \u001b[0m 0.4602  \u001b[0m | \u001b[0m 19.25   \u001b[0m | \u001b[0m 895.1   \u001b[0m | \u001b[0m 35.37   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.1868  \u001b[0m | \u001b[95m 0.8954  \u001b[0m | \u001b[95m 0.8124  \u001b[0m | \u001b[95m 0.7678  \u001b[0m | \u001b[95m 0.01048 \u001b[0m | \u001b[95m 10.92   \u001b[0m | \u001b[95m 474.1   \u001b[0m | \u001b[95m 24.59   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2703  \u001b[0m | \u001b[0m 0.1508  \u001b[0m | \u001b[0m 0.1469  \u001b[0m | \u001b[0m 0.486   \u001b[0m | \u001b[0m 0.3686  \u001b[0m | \u001b[0m 14.24   \u001b[0m | \u001b[0m 471.9   \u001b[0m | \u001b[0m 26.13   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1951  \u001b[0m | \u001b[0m 0.8224  \u001b[0m | \u001b[0m 0.8251  \u001b[0m | \u001b[0m 0.926   \u001b[0m | \u001b[0m 0.1376  \u001b[0m | \u001b[0m 7.298   \u001b[0m | \u001b[0m 475.8   \u001b[0m | \u001b[0m 20.93   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.2087  \u001b[0m | \u001b[0m 0.9937  \u001b[0m | \u001b[0m 0.4362  \u001b[0m | \u001b[0m 0.3942  \u001b[0m | \u001b[0m 0.2205  \u001b[0m | \u001b[0m 9.231   \u001b[0m | \u001b[0m 476.1   \u001b[0m | \u001b[0m 18.98   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.192   \u001b[0m | \u001b[0m 0.6578  \u001b[0m | \u001b[0m 0.187   \u001b[0m | \u001b[0m 0.6576  \u001b[0m | \u001b[0m 0.2629  \u001b[0m | \u001b[0m 14.74   \u001b[0m | \u001b[0m 469.8   \u001b[0m | \u001b[0m 21.43   \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m-0.1835  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.7475  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.01396 \u001b[0m | \u001b[95m 15.63   \u001b[0m | \u001b[95m 471.3   \u001b[0m | \u001b[95m 20.66   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.2028  \u001b[0m | \u001b[0m 0.681   \u001b[0m | \u001b[0m 0.6616  \u001b[0m | \u001b[0m 0.4625  \u001b[0m | \u001b[0m 0.2758  \u001b[0m | \u001b[0m 11.58   \u001b[0m | \u001b[0m 479.1   \u001b[0m | \u001b[0m 26.3    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2037  \u001b[0m | \u001b[0m 0.9226  \u001b[0m | \u001b[0m 0.7913  \u001b[0m | \u001b[0m 0.07615 \u001b[0m | \u001b[0m 0.2525  \u001b[0m | \u001b[0m 18.4    \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 20.03   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2345  \u001b[0m | \u001b[0m 0.5607  \u001b[0m | \u001b[0m 0.441   \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 0.3939  \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 469.4   \u001b[0m | \u001b[0m 18.92   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2384  \u001b[0m | \u001b[0m 0.355   \u001b[0m | \u001b[0m 0.7135  \u001b[0m | \u001b[0m 0.1333  \u001b[0m | \u001b[0m 0.4469  \u001b[0m | \u001b[0m 5.091   \u001b[0m | \u001b[0m 476.3   \u001b[0m | \u001b[0m 22.1    \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.2035  \u001b[0m | \u001b[0m 0.6222  \u001b[0m | \u001b[0m 0.4823  \u001b[0m | \u001b[0m 0.2792  \u001b[0m | \u001b[0m 0.1363  \u001b[0m | \u001b[0m 10.93   \u001b[0m | \u001b[0m 476.9   \u001b[0m | \u001b[0m 26.34   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1849  \u001b[0m | \u001b[0m 0.8966  \u001b[0m | \u001b[0m 0.4975  \u001b[0m | \u001b[0m 0.1643  \u001b[0m | \u001b[0m 0.058   \u001b[0m | \u001b[0m 15.25   \u001b[0m | \u001b[0m 474.1   \u001b[0m | \u001b[0m 19.02   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1836  \u001b[0m | \u001b[0m 0.4321  \u001b[0m | \u001b[0m 0.03347 \u001b[0m | \u001b[0m 0.9627  \u001b[0m | \u001b[0m 0.1894  \u001b[0m | \u001b[0m 17.2    \u001b[0m | \u001b[0m 475.4   \u001b[0m | \u001b[0m 23.44   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1905  \u001b[0m | \u001b[0m 0.6447  \u001b[0m | \u001b[0m 0.8453  \u001b[0m | \u001b[0m 0.6332  \u001b[0m | \u001b[0m 0.06772 \u001b[0m | \u001b[0m 10.63   \u001b[0m | \u001b[0m 474.3   \u001b[0m | \u001b[0m 26.43   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.19    \u001b[0m | \u001b[0m 0.2632  \u001b[0m | \u001b[0m 0.1395  \u001b[0m | \u001b[0m 0.0201  \u001b[0m | \u001b[0m 0.06582 \u001b[0m | \u001b[0m 17.68   \u001b[0m | \u001b[0m 472.2   \u001b[0m | \u001b[0m 17.89   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.2133  \u001b[0m | \u001b[0m 0.38    \u001b[0m | \u001b[0m 0.3156  \u001b[0m | \u001b[0m 0.04886 \u001b[0m | \u001b[0m 0.3871  \u001b[0m | \u001b[0m 15.93   \u001b[0m | \u001b[0m 478.6   \u001b[0m | \u001b[0m 20.6    \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.2431  \u001b[0m | \u001b[0m 0.9545  \u001b[0m | \u001b[0m 0.5059  \u001b[0m | \u001b[0m 0.7229  \u001b[0m | \u001b[0m 0.4431  \u001b[0m | \u001b[0m 6.086   \u001b[0m | \u001b[0m 831.4   \u001b[0m | \u001b[0m 149.9   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.2648  \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 0.6585  \u001b[0m | \u001b[0m 0.9708  \u001b[0m | \u001b[0m 0.4843  \u001b[0m | \u001b[0m 9.582   \u001b[0m | \u001b[0m 472.7   \u001b[0m | \u001b[0m 28.0    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1844  \u001b[0m | \u001b[0m 0.7423  \u001b[0m | \u001b[0m 0.9472  \u001b[0m | \u001b[0m 0.7972  \u001b[0m | \u001b[0m 0.06285 \u001b[0m | \u001b[0m 18.89   \u001b[0m | \u001b[0m 473.1   \u001b[0m | \u001b[0m 16.7    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.2016  \u001b[0m | \u001b[0m 0.5014  \u001b[0m | \u001b[0m 0.6456  \u001b[0m | \u001b[0m 0.8737  \u001b[0m | \u001b[0m 0.1372  \u001b[0m | \u001b[0m 18.23   \u001b[0m | \u001b[0m 472.9   \u001b[0m | \u001b[0m 13.41   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Local Models - Bayesian Optim:  75%|██████████▌   | 3/4 [05:22<01:18, 78.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2058  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.6238  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 472.1   \u001b[0m | \u001b[0m 21.99   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2081  \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.05053 \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 2.954   \u001b[0m | \u001b[0m 827.3   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.234   \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.7367  \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 761.5   \u001b[0m | \u001b[0m 125.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2523  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 0.2079  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 962.3   \u001b[0m | \u001b[0m 62.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2069  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 897.5   \u001b[0m | \u001b[0m 35.06   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1813  \u001b[0m | \u001b[95m 0.1328  \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.3429  \u001b[0m | \u001b[95m 0.03426 \u001b[0m | \u001b[95m 3.006   \u001b[0m | \u001b[95m 829.8   \u001b[0m | \u001b[95m 148.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.196   \u001b[0m | \u001b[0m 0.6472  \u001b[0m | \u001b[0m 0.04427 \u001b[0m | \u001b[0m 0.4546  \u001b[0m | \u001b[0m 0.2197  \u001b[0m | \u001b[0m 2.505   \u001b[0m | \u001b[0m 828.3   \u001b[0m | \u001b[0m 146.7   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1962  \u001b[0m | \u001b[0m 0.6906  \u001b[0m | \u001b[0m 0.3284  \u001b[0m | \u001b[0m 0.2048  \u001b[0m | \u001b[0m 0.2505  \u001b[0m | \u001b[0m 4.017   \u001b[0m | \u001b[0m 834.7   \u001b[0m | \u001b[0m 146.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2365  \u001b[0m | \u001b[0m 0.3548  \u001b[0m | \u001b[0m 0.8135  \u001b[0m | \u001b[0m 0.5065  \u001b[0m | \u001b[0m 0.4409  \u001b[0m | \u001b[0m 3.499   \u001b[0m | \u001b[0m 830.0   \u001b[0m | \u001b[0m 143.2   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2162  \u001b[0m | \u001b[0m 0.6153  \u001b[0m | \u001b[0m 0.964   \u001b[0m | \u001b[0m 0.2043  \u001b[0m | \u001b[0m 0.3824  \u001b[0m | \u001b[0m 7.485   \u001b[0m | \u001b[0m 838.6   \u001b[0m | \u001b[0m 147.7   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1816  \u001b[0m | \u001b[0m 0.225   \u001b[0m | \u001b[0m 0.9094  \u001b[0m | \u001b[0m 0.07102 \u001b[0m | \u001b[0m 0.01027 \u001b[0m | \u001b[0m 7.201   \u001b[0m | \u001b[0m 833.4   \u001b[0m | \u001b[0m 149.4   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2243  \u001b[0m | \u001b[0m 0.2025  \u001b[0m | \u001b[0m 0.8666  \u001b[0m | \u001b[0m 0.1903  \u001b[0m | \u001b[0m 0.3913  \u001b[0m | \u001b[0m 5.745   \u001b[0m | \u001b[0m 830.3   \u001b[0m | \u001b[0m 147.3   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-0.1782  \u001b[0m | \u001b[95m 0.9414  \u001b[0m | \u001b[95m 0.8376  \u001b[0m | \u001b[95m 0.004513\u001b[0m | \u001b[95m 0.07853 \u001b[0m | \u001b[95m 5.527   \u001b[0m | \u001b[95m 832.1   \u001b[0m | \u001b[95m 149.5   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1887  \u001b[0m | \u001b[0m 0.9651  \u001b[0m | \u001b[0m 0.167   \u001b[0m | \u001b[0m 0.5785  \u001b[0m | \u001b[0m 0.1963  \u001b[0m | \u001b[0m 12.52   \u001b[0m | \u001b[0m 477.2   \u001b[0m | \u001b[0m 18.44   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2052  \u001b[0m | \u001b[0m 0.3203  \u001b[0m | \u001b[0m 0.142   \u001b[0m | \u001b[0m 0.5277  \u001b[0m | \u001b[0m 0.2388  \u001b[0m | \u001b[0m 15.26   \u001b[0m | \u001b[0m 476.6   \u001b[0m | \u001b[0m 18.58   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2257  \u001b[0m | \u001b[0m 0.9858  \u001b[0m | \u001b[0m 0.9163  \u001b[0m | \u001b[0m 0.9309  \u001b[0m | \u001b[0m 0.3574  \u001b[0m | \u001b[0m 13.78   \u001b[0m | \u001b[0m 475.7   \u001b[0m | \u001b[0m 21.94   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.2017  \u001b[0m | \u001b[0m 0.9399  \u001b[0m | \u001b[0m 0.2984  \u001b[0m | \u001b[0m 0.1673  \u001b[0m | \u001b[0m 0.2724  \u001b[0m | \u001b[0m 8.662   \u001b[0m | \u001b[0m 833.7   \u001b[0m | \u001b[0m 148.2   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2915  \u001b[0m | \u001b[0m 0.4989  \u001b[0m | \u001b[0m 0.1658  \u001b[0m | \u001b[0m 0.6908  \u001b[0m | \u001b[0m 0.4976  \u001b[0m | \u001b[0m 11.18   \u001b[0m | \u001b[0m 480.2   \u001b[0m | \u001b[0m 21.03   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.214   \u001b[0m | \u001b[0m 0.7969  \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 0.8363  \u001b[0m | \u001b[0m 0.3295  \u001b[0m | \u001b[0m 9.669   \u001b[0m | \u001b[0m 474.8   \u001b[0m | \u001b[0m 15.42   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1863  \u001b[0m | \u001b[0m 0.5192  \u001b[0m | \u001b[0m 0.1595  \u001b[0m | \u001b[0m 0.8201  \u001b[0m | \u001b[0m 0.1304  \u001b[0m | \u001b[0m 16.74   \u001b[0m | \u001b[0m 468.9   \u001b[0m | \u001b[0m 25.39   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.2663  \u001b[0m | \u001b[0m 0.9372  \u001b[0m | \u001b[0m 0.5743  \u001b[0m | \u001b[0m 0.2607  \u001b[0m | \u001b[0m 0.4664  \u001b[0m | \u001b[0m 17.07   \u001b[0m | \u001b[0m 467.5   \u001b[0m | \u001b[0m 23.06   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1815  \u001b[0m | \u001b[0m 0.3324  \u001b[0m | \u001b[0m 0.5674  \u001b[0m | \u001b[0m 0.3411  \u001b[0m | \u001b[0m 0.01824 \u001b[0m | \u001b[0m 2.645   \u001b[0m | \u001b[0m 832.6   \u001b[0m | \u001b[0m 149.3   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1858  \u001b[0m | \u001b[0m 0.6098  \u001b[0m | \u001b[0m 0.4088  \u001b[0m | \u001b[0m 0.2748  \u001b[0m | \u001b[0m 0.1032  \u001b[0m | \u001b[0m 17.53   \u001b[0m | \u001b[0m 471.8   \u001b[0m | \u001b[0m 26.53   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.2046  \u001b[0m | \u001b[0m 0.7482  \u001b[0m | \u001b[0m 0.6901  \u001b[0m | \u001b[0m 0.916   \u001b[0m | \u001b[0m 0.2831  \u001b[0m | \u001b[0m 17.15   \u001b[0m | \u001b[0m 474.7   \u001b[0m | \u001b[0m 27.44   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2563  \u001b[0m | \u001b[0m 0.346   \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 0.4711  \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 471.1   \u001b[0m | \u001b[0m 28.04   \u001b[0m |\n",
      "| \u001b[95m 26      \u001b[0m | \u001b[95m-0.1746  \u001b[0m | \u001b[95m 0.9879  \u001b[0m | \u001b[95m 0.4557  \u001b[0m | \u001b[95m 0.1368  \u001b[0m | \u001b[95m 0.05397 \u001b[0m | \u001b[95m 5.867   \u001b[0m | \u001b[95m 834.5   \u001b[0m | \u001b[95m 148.2   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.2368  \u001b[0m | \u001b[0m 0.9545  \u001b[0m | \u001b[0m 0.5059  \u001b[0m | \u001b[0m 0.7229  \u001b[0m | \u001b[0m 0.4431  \u001b[0m | \u001b[0m 6.086   \u001b[0m | \u001b[0m 831.4   \u001b[0m | \u001b[0m 149.9   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1787  \u001b[0m | \u001b[0m 0.5223  \u001b[0m | \u001b[0m 0.86    \u001b[0m | \u001b[0m 0.6945  \u001b[0m | \u001b[0m 0.01284 \u001b[0m | \u001b[0m 4.377   \u001b[0m | \u001b[0m 979.3   \u001b[0m | \u001b[0m 48.22   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.2015  \u001b[0m | \u001b[0m 0.43    \u001b[0m | \u001b[0m 0.5958  \u001b[0m | \u001b[0m 0.8619  \u001b[0m | \u001b[0m 0.2839  \u001b[0m | \u001b[0m 3.467   \u001b[0m | \u001b[0m 115.4   \u001b[0m | \u001b[0m 28.4    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1844  \u001b[0m | \u001b[0m 0.8956  \u001b[0m | \u001b[0m 0.5198  \u001b[0m | \u001b[0m 0.7148  \u001b[0m | \u001b[0m 0.1329  \u001b[0m | \u001b[0m 8.74    \u001b[0m | \u001b[0m 935.6   \u001b[0m | \u001b[0m 131.8   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Models - Bayesian Optim: 100%|█████████████| 4/4 [07:20<00:00, 110.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# In parallel, for all the time series in our list, \n",
    "# loop through and run the Bayesian optimzer. Save the params for each model to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Local Models - Bayesian Optim\", total=4)) as progress_bar:\n",
    "    local_bayes_results = Parallel(n_jobs=4)(delayed(optimize_lgbm_w_bayes)(i, \n",
    "                                                                            lag_n, \n",
    "                                                                            train_df_full,\n",
    "                                                                            val_df_full\n",
    "                                                                           ) for i in range(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to train a final model\n",
    "def train_best_lgbm_local(m, data, param_ls, lag_n):\n",
    "    \"\"\"Function which takes inputs: m, the ts index, data, the full training_validation data frame,\n",
    "    param_ls, the list of params from which to choose, and lag_n, the lag embedding of the data,\n",
    "    and which returns a fitted model\"\"\"\n",
    "    \n",
    "    # Subset the data to the appropriate ts index and lag and split into X and y data frames\n",
    "    y_train_sub = data.query(\"ts_index==@m\").iloc[:,0:(lag_n+1)].dropna().iloc[:,0].copy()\n",
    "    X_train_sub = data.query(\"ts_index==@m\").iloc[:,0:(lag_n+1)].dropna().iloc[:,1:].copy()\n",
    "    \n",
    "    # Extract the params for this model\n",
    "    params = param_ls[m-1]\n",
    "    # Round and cast to int the params which must be integers\n",
    "    params['n_estimators'] = int(round(params['n_estimators']))\n",
    "    params['num_leaves'] = int(round(params['num_leaves']))\n",
    "    params['max_depth'] = int(round(params['max_depth']))\n",
    "    \n",
    "    # Create and fit the model object\n",
    "    mod_sub = LGBMRegressor(boosting_type=\"goss\", **params, random_state=54321)\n",
    "    mod_sub.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Return the fitted model\n",
    "    return mod_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Models - Bayesian Optim: 100%|██████████████| 4/4 [00:15<00:00,  3.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# In parallel, lopo through the list of ts indexes, model params, etc., and train the best local model for each \n",
    "# ts in our data set. Save to a list\n",
    "with tqdm_joblib(tqdm(desc=\"Local Models - Bayesian Optim\", total=4)) as progress_bar:\n",
    "    final_local_bayes_models = Parallel(n_jobs=4)(delayed(train_best_lgbm_local)(i, \n",
    "                                                                                 train_val_df_full, \n",
    "                                                                                 local_bayes_results,\n",
    "                                                                                 lag_n\n",
    "                                                                                ) for i in range(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Models Bayes - Test Preds: 100%|████████████| 4/4 [00:00<00:00,  5.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# In parallel, loop through all of our trained models and test sets and compute prediction performance\n",
    "with tqdm_joblib(tqdm(desc=\"Local Models Bayes - Test Preds\", total=4)) as progress_bar:\n",
    "    test_results_bayes = Parallel(n_jobs=4)(delayed(predict_test_lgbm)(final_local_bayes_models[i], \n",
    "                                                                       i+1, \n",
    "                                                                       test_df_full, \n",
    "                                                                       lag_n) for i in range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test set performance list into a df\n",
    "test_results_bayes_df = pd.DataFrame(test_results_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add normalized metrics to the df\n",
    "test_results_bayes_df['nrmse'] = test_results_bayes_df['rmse']/test_results_bayes_df['mean']\n",
    "test_results_bayes_df['smae'] = test_results_bayes_df['mae']/test_results_bayes_df['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean     377.058594\n",
       "mae       25.299451\n",
       "rmse      37.795336\n",
       "nrmse      0.120738\n",
       "smae       0.081754\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the means of the normalized metrics\n",
    "test_results_bayes_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to save residuals\n",
    "bayes_mod_resiudal_dict = dict()\n",
    "\n",
    "# Loop through the ts indexes. For each\n",
    "for i in range(1, 5):\n",
    "    # Create the y and X data frames\n",
    "    y_train_sub = train_val_df_full.query(\"ts_index==@i\").iloc[:,0:(lag_n+1)].dropna().iloc[:,0].copy()\n",
    "    X_train_sub = train_val_df_full.query(\"ts_index==@i\").iloc[:,0:(lag_n+1)].dropna().iloc[:,1:].copy()\n",
    "    \n",
    "    # Predict on the X data frame\n",
    "    train_preds_sub = final_local_bayes_models[i-1].predict(X_train_sub)\n",
    "    \n",
    "    # Compute residuals and convery to list\n",
    "    res_sub = (y_train_sub - train_preds_sub).to_list()\n",
    "    \n",
    "    # Add that list to the residual dictionary\n",
    "    bayes_mod_resiudal_dict[i] = res_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for model performance\n",
    "bayes_mod_test_preds = dict()\n",
    "\n",
    "# Loop through the ts indexes\n",
    "for i in range(1,5):\n",
    "    # Create the X data frame to predict on \n",
    "    X_test_sub = test_df_full.query(\"ts_index==@i\").iloc[:,1:(lag_n+1)]\n",
    "    \n",
    "    # Compute the test predictions\n",
    "    test_pred_sub = final_local_bayes_models[i-1].predict(X_test_sub)\n",
    "    \n",
    "    # Save the predictions to the dictionary\n",
    "    bayes_mod_test_preds[i] = test_pred_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define n_boot, the number of bootstramp samples to use for PI computation\n",
    "n_boot = 1000\n",
    "\n",
    "# Create a data frame to save PIs to\n",
    "bayes_pred_int_df = pd.DataFrame()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)\n",
    "\n",
    "# Loop through the ts indexes in our list\n",
    "for i in range(1,5):\n",
    "    \n",
    "    # Grab the true data y for that index\n",
    "    y_test_sub = test_df_full.query(\"ts_index==@i\").iloc[:,0]\n",
    "    \n",
    "    # Create empty lists to save PIs to\n",
    "    percent_95_lo_ls = list()\n",
    "    percent_95_hi_ls = list()\n",
    "    percent_80_lo_ls = list()\n",
    "    percent_80_hi_ls = list()\n",
    "    \n",
    "    for j in range(1344):\n",
    "        # For each observation in the test set\n",
    "        # Extract the predicted value\n",
    "        pred = bayes_mod_test_preds[i][j]\n",
    "        # Compute a bootstramp sample from the appropriate residual list\n",
    "        resid_boot = np.random.choice(bayes_mod_resiudal_dict[i], size=n_boot, replace=True)\n",
    "        # Add the prediction to the bootstrapped residual sample\n",
    "        resid_preds = pred+resid_boot\n",
    "        \n",
    "        # From that, compute percentiles for the 95% and then 80% PIs and append those to lists\n",
    "        percent_95_lo = np.percentile(resid_preds, 2.5)\n",
    "        percent_95_hi = np.percentile(resid_preds, 97.5)\n",
    "        percent_95_lo_ls.append(percent_95_lo)\n",
    "        percent_95_hi_ls.append(percent_95_hi)\n",
    "        \n",
    "        percent_80_lo = np.percentile(resid_preds, 10)\n",
    "        percent_80_hi = np.percentile(resid_preds, 90)\n",
    "        percent_80_lo_ls.append(percent_80_lo)\n",
    "        percent_80_hi_ls.append(percent_80_hi)\n",
    "    \n",
    "    # Create a temp data frame which includes the ts_index, true values, and PI for each observation\n",
    "    pred_int_df_sub = pd.DataFrame({\"ts_index\": i,\n",
    "                                    \"actual\": y_test_sub,\n",
    "                                    \"pct_95_lo\": percent_95_lo_ls,\n",
    "                                    \"pct_95_hi\": percent_95_hi_ls,                                   \n",
    "                                    \"pct_80_lo\": percent_80_lo_ls,\n",
    "                                    \"pct_80_hi\": percent_80_hi_ls\n",
    "                                   })\n",
    "    \n",
    "    # Append that temp df to the full df\n",
    "    bayes_pred_int_df = bayes_pred_int_df.append(pred_int_df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the PI scores for all observations for both 80% and 95% PIs\n",
    "bayes_pred_int_df['int_80_score'] = interval_score(bayes_pred_int_df['actual'], \n",
    "                                                   bayes_pred_int_df['pct_80_lo'], \n",
    "                                                   bayes_pred_int_df['pct_80_hi'],\n",
    "                                                   0.8\n",
    "                                                  )\n",
    "\n",
    "bayes_pred_int_df['int_95_score'] = interval_score(bayes_pred_int_df['actual'], \n",
    "                                                   bayes_pred_int_df['pct_95_lo'], \n",
    "                                                   bayes_pred_int_df['pct_95_hi'],\n",
    "                                                   0.95\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index          2.500000\n",
       "actual          377.058594\n",
       "pct_95_lo       335.003617\n",
       "pct_95_hi       424.157675\n",
       "pct_80_lo       353.138723\n",
       "pct_80_hi       405.628392\n",
       "int_80_score    149.897297\n",
       "int_95_score    313.767610\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean PI scores\n",
    "bayes_pred_int_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each time series, compute the mean interval score and true mean\n",
    "bayes_pred_int_df_grouped = bayes_pred_int_df.groupby(\"ts_index\")\\\n",
    ".agg({\"int_95_score\":\"mean\", \"int_80_score\":\"mean\", \"actual\":\"mean\"}).reset_index()\n",
    "\n",
    "# Use the true mean to compute the scaled interval score\n",
    "bayes_pred_int_df_grouped['int_95_score_scaled'] = bayes_pred_int_df_grouped['int_95_score']/bayes_pred_int_df_grouped['actual']\n",
    "bayes_pred_int_df_grouped['int_80_score_scaled'] = bayes_pred_int_df_grouped['int_80_score']/bayes_pred_int_df_grouped['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_80_score_scaled    0.520346\n",
       "int_95_score_scaled    1.294142\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the per time series mean of the scaled interval score\n",
    "bayes_pred_int_df_grouped[['int_80_score_scaled', 'int_95_score_scaled']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
