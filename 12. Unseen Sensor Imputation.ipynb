{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75b74295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear workspace\n",
    "rm(list=ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab73cdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>2470878</td><td>132.0</td><td> 3978168</td><td>212.5</td><td> 3978168</td><td>212.5</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>4292266</td><td> 32.8</td><td>14865554</td><td>113.5</td><td>14865291</td><td>113.5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells & 2470878 & 132.0 &  3978168 & 212.5 &  3978168 & 212.5\\\\\n",
       "\tVcells & 4292266 &  32.8 & 14865554 & 113.5 & 14865291 & 113.5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells | 2470878 | 132.0 |  3978168 | 212.5 |  3978168 | 212.5 |\n",
       "| Vcells | 4292266 |  32.8 | 14865554 | 113.5 | 14865291 | 113.5 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb)  gc trigger (Mb)  max used (Mb) \n",
       "Ncells 2470878 132.0  3978168   212.5  3978168 212.5\n",
       "Vcells 4292266  32.8 14865554   113.5 14865291 113.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Garabage collect to help prevent memory issues\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dd7b19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install/load libraries\n",
    "library(tidyverse) # Sagemaker has\n",
    "install.packages(\"timetk\") # Sagemaker doesn't have\n",
    "library(timetk)\n",
    "library(lubridate) # Sagemaker has\n",
    "install.packages(\"ggridges\") # Sagemaker doesn't have\n",
    "library(ggridges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d6ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m35044\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m10\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (1): site_name\n",
      "\u001b[32mdbl\u001b[39m  (5): day_of_week, day_of_year, interval_of_day, avg_mph, total_volume\n",
      "\u001b[33mlgl\u001b[39m  (2): missing_speed, missing_volume\n",
      "\u001b[34mdttm\u001b[39m (1): timestamp\n",
      "\u001b[34mdate\u001b[39m (1): date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m35044\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m10\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (1): site_name\n",
      "\u001b[32mdbl\u001b[39m  (5): day_of_week, day_of_year, interval_of_day, avg_mph, total_volume\n",
      "\u001b[33mlgl\u001b[39m  (2): missing_speed, missing_volume\n",
      "\u001b[34mdttm\u001b[39m (1): timestamp\n",
      "\u001b[34mdate\u001b[39m (1): date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m35044\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m10\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (1): site_name\n",
      "\u001b[32mdbl\u001b[39m  (5): day_of_week, day_of_year, interval_of_day, avg_mph, total_volume\n",
      "\u001b[33mlgl\u001b[39m  (2): missing_speed, missing_volume\n",
      "\u001b[34mdttm\u001b[39m (1): timestamp\n",
      "\u001b[34mdate\u001b[39m (1): date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m35044\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m10\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (1): site_name\n",
      "\u001b[32mdbl\u001b[39m  (5): day_of_week, day_of_year, interval_of_day, avg_mph, total_volume\n",
      "\u001b[33mlgl\u001b[39m  (2): missing_speed, missing_volume\n",
      "\u001b[34mdttm\u001b[39m (1): timestamp\n",
      "\u001b[34mdate\u001b[39m (1): date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "# Read in all files from the Unseen Sensor - Intermediate directory \n",
    "# and create a list of data frames \n",
    "fnames <- list.files(\"Data/Unseen Sensor/Intermediate/\", pattern=\"*.csv\", full.names=TRUE)\n",
    "total_df_list <- lapply(fnames, read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3497bfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "4"
      ],
      "text/latex": [
       "4"
      ],
      "text/markdown": [
       "4"
      ],
      "text/plain": [
       "[1] 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity check the lengths of list\n",
    "length(total_df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2962c5",
   "metadata": {},
   "source": [
    "# Data Missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459236b",
   "metadata": {},
   "source": [
    "## Percent Missing per Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67c8e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percentage of missingness for each time series\n",
    "total_missing <- lapply(total_df_list, function(x) 100*sum(x$missing_volume)/nrow(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f7083fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.701974660426892"
      ],
      "text/latex": [
       "0.701974660426892"
      ],
      "text/markdown": [
       "0.701974660426892"
      ],
      "text/plain": [
       "[1] 0.7019747"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(unlist(total_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e15fa",
   "metadata": {},
   "source": [
    "# Impute Missing Value Using Temporal Medians Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e931567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all data frames are in proper chronological order\n",
    "total_df_list <- lapply(total_df_list, function(x) x %>% arrange(timestamp))                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352d89e",
   "metadata": {},
   "source": [
    "# Manual Seasonal Imputation Across Full Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fac4de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_seas_int <- function(df) {\n",
    "    # Based on the above results, it makes the most sense to proceed with the modified temporal medians\n",
    "    # approach for imputation. In this function, we take in a data frame, find the missing values based\n",
    "    # on a missing_volume boolean column, and impute them using the same modified temporal medians approach\n",
    "    \n",
    "    # Set volume where missing to NA\n",
    "    df <- df %>% mutate(total_volume=ifelse(missing_volume, NA, total_volume))\n",
    "    \n",
    "    # Create the list of indexes with missing volume\n",
    "    missing_vol_list <- which(df$missing_volume==TRUE)\n",
    "    \n",
    "    # Initialize an empty list for imputation\n",
    "    bf <- c()\n",
    "    \n",
    "    # For each index\n",
    "    for (ind in missing_vol_list) {\n",
    "        \n",
    "        # Grab the day of year and interval of day\n",
    "        doy <- df[ind, 4]$day_of_year\n",
    "        iod <- df[ind, 6]$interval_of_day\n",
    "        \n",
    "        # If the day of year is less than 15, grab the most recent 7 days\n",
    "        if (doy < 15) {\n",
    "            doy_list <- c(doy-7, doy-6, doy-5, doy-4, doy-3, doy-2, doy-1)\n",
    "        }\n",
    "        \n",
    "        # Else, grab up to the most recent 7 weeks with the same day of week\n",
    "        else {\n",
    "            doy_list <- c(doy-49, doy-42, doy-35, doy-28, doy-21, doy-14, doy-7) \n",
    "        }\n",
    "        \n",
    "        # Get the volume values corresponding to the proper day of year(s) and interval of day\n",
    "        bf_values <- na.omit((df %>% \n",
    "                              arrange(desc(timestamp)) %>% \n",
    "                              filter(day_of_year %in% doy_list) %>% \n",
    "                              filter(interval_of_day==iod))$total_volume)   \n",
    "        \n",
    "        n <- length(bf_values)\n",
    "        \n",
    "#         weights <- n:1/(sum(1:n))\n",
    "        \n",
    "#         bf_value <- round(weighted.mean(bf_values,\n",
    "#                                         weights,\n",
    "#                                         na.rm=T))\n",
    "\n",
    "        # Compute the median of those volumes\n",
    "        bf_value <- median(bf_values)\n",
    "        \n",
    "        # Append to list\n",
    "        bf <- c(bf, bf_value)\n",
    "    }    \n",
    "    \n",
    "    # Replace the missing volume values in the df with the imputed values\n",
    "    df$total_volume <- replace(df$total_volume, missing_vol_list, bf)\n",
    "    \n",
    "    # Return the df with imputed values\n",
    "    df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2c2743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute each df using the modified temporal medians method explored above\n",
    "total_df_list_int <- lapply(total_df_list, man_seas_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa5b43",
   "metadata": {},
   "source": [
    "### Explore Data Set Lengths to Look for Issues (Like Daylight Savings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "520dec6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>35044</li>\n",
       "\t<li>35044</li>\n",
       "\t<li>35044</li>\n",
       "\t<li>35044</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item 35044\n",
       "\\item 35044\n",
       "\\item 35044\n",
       "\\item 35044\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 35044\n",
       "2. 35044\n",
       "3. 35044\n",
       "4. 35044\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] 35044\n",
       "\n",
       "[[2]]\n",
       "[1] 35044\n",
       "\n",
       "[[3]]\n",
       "[1] 35044\n",
       "\n",
       "[[4]]\n",
       "[1] 35044\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length should be 35040 - lengths slightly above this indicate daylight savings is causing multiple entries \n",
    "# for one timestamp\n",
    "lapply(total_df_list_int, function(x) nrow(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a11511a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>95</li>\n",
       "\t<li>95</li>\n",
       "\t<li>95</li>\n",
       "\t<li>95</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item 95\n",
       "\\item 95\n",
       "\\item 95\n",
       "\\item 95\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 95\n",
       "2. 95\n",
       "3. 95\n",
       "4. 95\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] 95\n",
       "\n",
       "[[2]]\n",
       "[1] 95\n",
       "\n",
       "[[3]]\n",
       "[1] 95\n",
       "\n",
       "[[4]]\n",
       "[1] 95\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the max interval of day value - if there are none above 95, then we can simply groupby timestamp to\n",
    "# eliminate daylight savings issues \n",
    "# When doing so, we will avg the speed and take the max of the total volume for that timestamp - this is abritrary\n",
    "# and other methods could be used, but with so few data points, it is unlikely to matter\n",
    "lapply(total_df_list_int, function(x) max(x$interval_of_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8976b659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]\n",
       "[1] \"2019-10-27 01:14:00 UTC\" \"2019-10-27 01:29:00 UTC\"\n",
       "[3] \"2019-10-27 01:44:00 UTC\" \"2019-10-27 01:59:00 UTC\"\n",
       "\n",
       "[[2]]\n",
       "[1] \"2019-10-27 01:14:00 UTC\" \"2019-10-27 01:29:00 UTC\"\n",
       "[3] \"2019-10-27 01:44:00 UTC\" \"2019-10-27 01:59:00 UTC\"\n",
       "\n",
       "[[3]]\n",
       "[1] \"2019-10-27 01:14:00 UTC\" \"2019-10-27 01:29:00 UTC\"\n",
       "[3] \"2019-10-27 01:44:00 UTC\" \"2019-10-27 01:59:00 UTC\"\n",
       "\n",
       "[[4]]\n",
       "[1] \"2019-10-27 01:14:00 UTC\" \"2019-10-27 01:29:00 UTC\"\n",
       "[3] \"2019-10-27 01:44:00 UTC\" \"2019-10-27 01:59:00 UTC\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The timsteamps with issues indicate daylight savings is the likely culprit\n",
    "lapply(total_df_list_int, function(x) (x %>%  \n",
    "                                         group_by(timestamp) %>% \n",
    "                                         summarise(n=n()) %>% \n",
    "                                         ungroup() %>%\n",
    "                                         arrange(desc(n)) %>%\n",
    "                                         filter(n>1))$timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a44a7987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'site_name', 'day_of_week', 'date',\n",
      "'day_of_year', 'timestamp'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'site_name', 'day_of_week', 'date',\n",
      "'day_of_year', 'timestamp'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'site_name', 'day_of_week', 'date',\n",
      "'day_of_year', 'timestamp'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'site_name', 'day_of_week', 'date',\n",
      "'day_of_year', 'timestamp'. You can override using the `.groups` argument.\n"
     ]
    }
   ],
   "source": [
    "# For each data frame, deal with daylight savings issues by computing the max volume of the duplicate start times\n",
    "total_df_list_int <- lapply(total_df_list_int, \n",
    "                              function(x) x <- x %>% \n",
    "                                                group_by(site_name, \n",
    "                                                         day_of_week, \n",
    "                                                         date, \n",
    "                                                         day_of_year, \n",
    "                                                         timestamp, \n",
    "                                                         interval_of_day\n",
    "                                                        ) %>%\n",
    "                                                summarise(avg_mph=mean(avg_mph),\n",
    "                                                          total_volume=max(total_volume),\n",
    "                                                          missing_speed=max(missing_speed),\n",
    "                                                          missing_volume=max(missing_volume)\n",
    "                                                         ) %>%\n",
    "                                               ungroup() %>%\n",
    "                                               mutate(missing_speed=ifelse(missing_speed==1, TRUE, FALSE),\n",
    "                                                      missing_volume=ifelse(missing_volume==1, TRUE, FALSE)\n",
    "                                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22ec5da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>35040</li>\n",
       "\t<li>35040</li>\n",
       "\t<li>35040</li>\n",
       "\t<li>35040</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item 35040\n",
       "\\item 35040\n",
       "\\item 35040\n",
       "\\item 35040\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 35040\n",
       "2. 35040\n",
       "3. 35040\n",
       "4. 35040\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] 35040\n",
       "\n",
       "[[2]]\n",
       "[1] 35040\n",
       "\n",
       "[[3]]\n",
       "[1] 35040\n",
       "\n",
       "[[4]]\n",
       "[1] 35040\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check lengths again - if they are all 35040, we can write to file\n",
    "lapply(total_df_list_int, function(x) nrow(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9607a",
   "metadata": {},
   "source": [
    "### Write to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44924a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each sensor to a file in the Processed sub-folder of the Data directory\n",
    "for (i in 1:length(total_df_list_int)) {\n",
    "    write.csv(total_df_list_int[[i]], \n",
    "              str_replace_all(fnames[[i]], \"Intermediate\", \"Processed\"),\n",
    "              row.names=FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766846af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
